<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 49]
- [cs.CL](#cs.CL) [Total: 29]
- [cs.LG](#cs.LG) [Total: 43]
- [cs.AI](#cs.AI) [Total: 18]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model](https://arxiv.org/abs/2601.00051)
*Yabo Chen,Yuanzhi Liang,Jiepeng Wang,Tingxi Chen,Junfei Cheng,Zixiao Gu,Yuyang Huang,Zicheng Jiang,Wei Li,Tian Li,Weichen Li,Zuoxin Li,Guangce Liu,Jialun Liu,Junqi Liu,Haoyuan Wang,Qizhen Weng,Xuan'er Wu,Xunzhi Xiang,Xiaoyan Yang,Xin Zhang,Shiwen Zhang,Junyu Zhou,Chengcheng Zhou,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TeleWorld是一个实时多模态4D世界建模框架，通过生成-重建-引导范式统一视频生成、动态场景重建和长期世界记忆，实现实时、一致的世界建模。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在实时交互、长时一致性和动态场景持久记忆方面存在局限，阻碍了其发展为实用的世界模型。需要一种能够统一视频生成、动态重建和长期记忆的闭环系统。

Method: 提出生成-重建-引导范式：生成的视频流被连续重建为动态4D时空表示，该表示反过来引导后续生成以保持一致性。采用自回归扩散视频模型，增强宏观-微观规划（MMPL）以减少误差累积，结合高效分布匹配蒸馏（DMD）实现实时合成。

Result: TeleWorld在静态和动态世界理解、长期一致性和实时生成效率方面表现出色，实现了动态对象建模和静态场景表示在统一4D框架中的无缝集成。

Conclusion: TeleWorld是迈向实用、交互式和计算可访问的世界模型的重要一步，为多模态生成和具身智能提供了具有记忆功能的交互式世界模型。

Abstract: World models aim to endow AI systems with the ability to represent, generate, and interact with dynamic environments in a coherent and temporally consistent manner. While recent video generation models have demonstrated impressive visual quality, they remain limited in real-time interaction, long-horizon consistency, and persistent memory of dynamic scenes, hindering their evolution into practical world models. In this report, we present TeleWorld, a real-time multimodal 4D world modeling framework that unifies video generation, dynamic scene reconstruction, and long-term world memory within a closed-loop system. TeleWorld introduces a novel generation-reconstruction-guidance paradigm, where generated video streams are continuously reconstructed into a dynamic 4D spatio-temporal representation, which in turn guides subsequent generation to maintain spatial, temporal, and physical consistency. To support long-horizon generation with low latency, we employ an autoregressive diffusion-based video model enhanced with Macro-from-Micro Planning (MMPL)--a hierarchical planning method that reduces error accumulation from frame-level to segment-level-alongside efficient Distribution Matching Distillation (DMD), enabling real-time synthesis under practical computational budgets. Our approach achieves seamless integration of dynamic object modeling and static scene representation within a unified 4D framework, advancing world models toward practical, interactive, and computationally accessible systems. Extensive experiments demonstrate that TeleWorld achieves strong performance in both static and dynamic world understanding, long-term consistency, and real-time generation efficiency, positioning it as a practical step toward interactive, memory-enabled world models for multimodal generation and embodied intelligence.

</details>


### [2] [FCMBench: A Comprehensive Financial Credit Multimodal Benchmark for Real-world Applications](https://arxiv.org/abs/2601.00150)
*Yehui Yang,Dalu Yang,Wenshuo Zhou,Fangxin Shang,Yifan Liu,Jie Ren,Haojun Fei,Qing Yang,Tao Chen*

Main category: cs.CV

TL;DR: FCMBench-V1.0是一个针对金融信贷领域的多模态基准测试，包含4,043张隐私合规图像和8,446个QA样本，用于评估视觉语言模型在信贷文档理解和决策任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 随着多模态AI在信贷风险评估和文档审查中的广泛应用，迫切需要领域特定的基准测试来反映金融信贷应用中的实际文档和工作流程，同时确保隐私合规性和实际效用。

Method: 通过封闭的合成-捕获流水线构建数据集：手动合成带有虚拟内容的文档模板，并在内部捕获场景感知图像。评估框架包含三个维度：感知（3个基础任务）、推理（4个信贷特定任务）和鲁棒性（10种真实世界采集伪影类型）。

Result: 在23个最先进的视觉语言模型上进行了广泛实验。Gemini 3 Pro作为商业模型获得最佳F1分数（64.61%），Qwen3-VL-235B作为开源基线获得最佳分数（57.27%），而作者提出的金融信贷特定模型Qfin-VL-Instruct获得最高总分（64.92%）。鲁棒性评估显示即使顶级模型在采集伪影下也会出现明显性能下降。

Conclusion: FCMBench-V1.0能够有效区分不同视觉语言模型的性能差异和鲁棒性，为金融信贷领域的多模态AI评估提供了标准化基准，同时解决了隐私合规和实际效用之间的平衡问题。

Abstract: As multimodal AI becomes widely used for credit risk assessment and document review, a domain-specific benchmark is urgently needed that (1) reflects documents and workflows specific to financial credit applications, (2) includes credit-specific understanding and real-world robustness, and (3) preserves privacy compliance without sacrificing practical utility. Here, we introduce FCMBench-V1.0 -- a large-scale financial credit multimodal benchmark for real-world applications, covering 18 core certificate types, with 4,043 privacy-compliant images and 8,446 QA samples. The FCMBench evaluation framework consists of three dimensions: Perception, Reasoning, and Robustness, including 3 foundational perception tasks, 4 credit-specific reasoning tasks that require decision-oriented understanding of visual evidence, and 10 real-world acquisition artifact types for robustness stress testing. To reconcile compliance with realism, we construct all samples via a closed synthesis-capture pipeline: we manually synthesize document templates with virtual content and capture scenario-aware images in-house. This design also mitigates pre-training data leakage by avoiding web-sourced or publicly released images. FCMBench can effectively discriminate performance disparities and robustness across modern vision-language models. Extensive experiments were conducted on 23 state-of-the-art vision-language models (VLMs) from 14 top AI companies and research institutes. Among them, Gemini 3 Pro achieves the best F1(\%) score as a commercial model (64.61), Qwen3-VL-235B achieves the best score as an open-source baseline (57.27), and our financial credit-specific model, Qfin-VL-Instruct, achieves the top overall score (64.92). Robustness evaluations show that even top-performing models suffer noticeable performance drops under acquisition artifacts.

</details>


### [3] [It's Never Too Late: Noise Optimization for Collapse Recovery in Trained Diffusion Models](https://arxiv.org/abs/2601.00090)
*Anne Harrington,A. Sophia Koepke,Shyamgopal Karthik,Trevor Darrell,Alexei A. Efros*

Main category: cs.CV

TL;DR: 提出通过噪声优化解决文本到图像模型中的模式崩溃问题，使用简单的噪声优化目标提升生成多样性，同时保持基础模型保真度


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像模型存在显著的模式崩溃问题，即给定相同文本提示时生成的图像缺乏多样性。现有方法通过引导机制或生成大量候选后精炼来解决，但本文采用不同的噪声优化方向

Method: 采用噪声优化方法，设计简单的噪声优化目标来缓解模式崩溃；分析噪声的频率特性，探索具有不同频率分布的替代噪声初始化策略，以改进优化和搜索过程

Result: 实验表明噪声优化在生成质量和多样性方面均取得优异结果；不同频率特性的噪声初始化能有效改善优化和搜索性能

Conclusion: 噪声优化是解决文本到图像模型模式崩溃的有效方法，既能保持基础模型保真度，又能显著提升生成多样性；噪声的频率特性分析为优化策略提供了新的见解

Abstract: Contemporary text-to-image models exhibit a surprising degree of mode collapse, as can be seen when sampling several images given the same text prompt. While previous work has attempted to address this issue by steering the model using guidance mechanisms, or by generating a large pool of candidates and refining them, in this work we take a different direction and aim for diversity in generations via noise optimization. Specifically, we show that a simple noise optimization objective can mitigate mode collapse while preserving the fidelity of the base model. We also analyze the frequency characteristics of the noise and show that alternative noise initializations with different frequency profiles can improve both optimization and search. Our experiments demonstrate that noise optimization yields superior results in terms of generation quality and variety.

</details>


### [4] [Spatial4D-Bench: A Versatile 4D Spatial Intelligence Benchmark](https://arxiv.org/abs/2601.00092)
*Pan Wang,Yang Liu,Guile Wu,Eduardo R. Corral-Soto,Chengjie Huang,Binbin Xu,Dongfeng Bai,Xu Yan,Yuan Ren,Xingxin Chen,Yizhe Wu,Tao Huang,Wenjun Wan,Xin Wu,Pei Zhou,Xuyang Dai,Kangbo Lv,Hongbo Zhang,Yosef Fried,Aixue Ye,Bailan Feng,Zhenyu Chen,Zhen Li,Yingcong Chen,Yiyi Liao,Bingbing Liu*

Main category: cs.CV

TL;DR: Spatial4D-Bench：一个包含约40,000个问答对的大规模多任务基准，用于全面评估多模态大语言模型在4D空间智能（时空推理）方面的能力，涵盖18个任务和6个认知类别。


<details>
  <summary>Details</summary>
Motivation: 人类天生具备4D空间智能（感知和处理物体随时间的变化），但现有空间智能基准往往规模小或多样性有限。需要评估多模态大语言模型在多大程度上能达到人类水平的4D空间智能，因此需要构建一个全面、结构化的基准来系统评估MLLMs的空间认知能力。

Method: 提出了Spatial4D-Bench基准，包含约40,000个问答对，覆盖18个明确定义的任务。这些任务系统性地组织为6个认知类别：物体理解、场景理解、空间关系理解、时空关系理解、空间推理和时空推理。该基准提供了结构化、全面的评估框架，评估了各种开源和专有MLLMs在4D空间推理方面的表现。

Result: 对各种最先进的开源和专有MLLMs进行基准测试，揭示了它们在多种4D空间推理方面的显著局限性，如路线规划、动作识别和物理合理性推理等。这些发现为社区提供了有价值的见解。

Conclusion: Spatial4D-Bench为评估MLLMs的空间认知能力提供了全面基准，揭示了当前模型在4D空间智能方面的不足。该基准有望促进开发更强大的MLLMs，使其向人类水平的4D空间智能发展。

Abstract: 4D spatial intelligence involves perceiving and processing how objects move or change over time. Humans naturally possess 4D spatial intelligence, supporting a broad spectrum of spatial reasoning abilities. To what extent can Multimodal Large Language Models (MLLMs) achieve human-level 4D spatial intelligence? In this work, we present Spatial4D-Bench, a versatile 4D spatial intelligence benchmark designed to comprehensively assess the 4D spatial reasoning abilities of MLLMs. Unlike existing spatial intelligence benchmarks that are often small-scale or limited in diversity, Spatial4D-Bench provides a large-scale, multi-task evaluation benchmark consisting of ~40,000 question-answer pairs covering 18 well-defined tasks. We systematically organize these tasks into six cognitive categories: object understanding, scene understanding, spatial relationship understanding, spatiotemporal relationship understanding, spatial reasoning and spatiotemporal reasoning. Spatial4D-Bench thereby offers a structured and comprehensive benchmark for evaluating the spatial cognition abilities of MLLMs, covering a broad spectrum of tasks that parallel the versatility of human spatial intelligence. We benchmark various state-of-the-art open-source and proprietary MLLMs on Spatial4D-Bench and reveal their substantial limitations in a wide variety of 4D spatial reasoning aspects, such as route plan, action recognition, and physical plausibility reasoning. We hope that the findings provided in this work offer valuable insights to the community and that our benchmark can facilitate the development of more capable MLLMs toward human-level 4D spatial intelligence. More resources can be found on our project page.

</details>


### [5] [Compressed Map Priors for 3D Perception](https://arxiv.org/abs/2601.00139)
*Brady Zhou,Philipp Krähenbühl*

Main category: cs.CV

TL;DR: 提出Compressed Map Priors (CMP)框架，通过历史遍历数据学习空间先验，以极低存储成本（32KB/km²）提升自动驾驶3D感知性能


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶视觉系统通常将每个位置视为首次访问，忽略了大多数部署区域已被多次遍历的历史信息。人类驾驶员会利用历史经验，而现有系统缺乏对空间先验的有效利用。

Method: 提出压缩地图先验(CMP)框架，使用二值化哈希映射从历史遍历中学习空间先验，存储密度极低（32KB/km²，比密集存储减少20倍），可轻松集成到主流3D感知系统中且计算开销极小。

Result: 在nuScenes数据集上，CMP显著且一致地提升了多种架构的3D目标检测性能，证明了空间先验对自动驾驶感知的有效性。

Conclusion: 利用历史遍历数据的空间先验可以显著提升自动驾驶3D感知性能，CMP框架以极低存储成本实现了这一目标，为自动驾驶系统利用历史经验提供了有效解决方案。

Abstract: Human drivers rarely travel where no person has gone before. After all, thousands of drivers use busy city roads every day, and only one can claim to be the first. The same holds for autonomous computer vision systems. The vast majority of the deployment area of an autonomous vision system will have been visited before. Yet, most autonomous vehicle vision systems act as if they are encountering each location for the first time. In this work, we present Compressed Map Priors (CMP), a simple but effective framework to learn spatial priors from historic traversals. The map priors use a binarized hashmap that requires only $32\text{KB}/\text{km}^2$, a $20\times$ reduction compared to the dense storage. Compressed Map Priors easily integrate into leading 3D perception systems at little to no extra computational costs, and lead to a significant and consistent improvement in 3D object detection on the nuScenes dataset across several architectures.

</details>


### [6] [Focal-RegionFace: Generating Fine-Grained Multi-attribute Descriptions for Arbitrarily Selected Face Focal Regions](https://arxiv.org/abs/2601.00156)
*Kaiwen Zheng,Junchen Fu,Songpei Xu,Yaoqing He,Joemon M. Jose,Han Hu,Xuri Ge*

Main category: cs.CV

TL;DR: 提出FaceFocalDesc问题：为任意选定面部区域生成多属性自然语言描述（包含动作单元、情绪状态和年龄估计），并构建相应数据集和基于Qwen2.5-VL的Focal-RegionFace模型，通过渐进微调实现局部面部特征的精细化分析。


<details>
  <summary>Details</summary>
Motivation: 面部分析中一个未被充分探索的问题：为任意选定面部区域生成和识别包含动作单元、情绪状态和年龄估计的多属性自然语言描述。作者认为系统能够聚焦于个体面部区域将带来更好的理解和控制能力。

Method: 1. 构建新的多属性描述数据集，为任意选定面部区域提供丰富的区域级标注和自然语言描述；2. 提出基于Qwen2.5-VL的微调视觉语言模型Focal-RegionFace，通过多个渐进微调阶段逐步细化对局部面部特征的关注，实现可解释的年龄估计、面部动作单元和情绪检测。

Result: Focal-RegionFace在新基准测试中取得了最佳性能，无论是在传统广泛使用的指标还是新提出的指标上。这充分验证了其在细粒度多属性面部区域聚焦分析场景中的有效性和多功能性。

Conclusion: 该研究成功解决了面部分析中的FaceFocalDesc问题，通过构建数据集和开发Focal-RegionFace模型，实现了对任意选定面部区域的精细化多属性分析，为面部理解提供了更好的控制能力和可解释性。

Abstract: In this paper, we introduce an underexplored problem in facial analysis: generating and recognizing multi-attribute natural language descriptions, containing facial action units (AUs), emotional states, and age estimation, for arbitrarily selected face regions (termed FaceFocalDesc). We argue that the system's ability to focus on individual facial areas leads to better understanding and control. To achieve this capability, we construct a new multi-attribute description dataset for arbitrarily selected face regions, providing rich region-level annotations and natural language descriptions. Further, we propose a fine-tuned vision-language model based on Qwen2.5-VL, called Focal-RegionFace for facial state analysis, which incrementally refines its focus on localized facial features through multiple progressively fine-tuning stages, resulting in interpretable age estimation, FAU and emotion detection. Experimental results show that Focal-RegionFace achieves the best performance on the new benchmark in terms of traditional and widely used metrics, as well as new proposed metrics. This fully verifies its effectiveness and versatility in fine-grained multi-attribute face region-focal analysis scenarios.

</details>


### [7] [MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing](https://arxiv.org/abs/2601.00204)
*Xiaokun Sun,Zeyu Cai,Hao Tang,Ying Tai,Jian Yang,Zhenyu Zhang*

Main category: cs.CV

TL;DR: MorphAny3D是一个无需训练的3D变形框架，利用结构化潜在(SLAT)表示实现高质量3D变形，通过注意力机制融合源和目标特征，支持跨类别变形和高级应用。


<details>
  <summary>Details</summary>
Motivation: 3D变形面临语义一致性和时间平滑性的挑战，特别是在跨类别变形时。现有方法难以生成高质量、语义一致的变形序列，需要一种无需训练且能处理跨类别变形的解决方案。

Method: 提出基于SLAT表示的无需训练框架，核心是两种注意力机制：变形交叉注意力(MCA)融合源和目标特征以保持结构连贯性；时间融合自注意力(TFSA)引入前一帧特征以增强时间一致性。还采用方向校正策略缓解变形过程中的姿态模糊问题。

Result: 实验表明该方法能生成最先进的变形序列，即使是具有挑战性的跨类别案例。支持解耦变形和3D风格迁移等高级应用，并可推广到其他基于SLAT的生成模型。

Conclusion: MorphAny3D通过智能融合SLAT特征和创新的注意力机制，实现了高质量、语义一致且时间平滑的3D变形，为跨类别变形提供了有效的解决方案，并展示了在高级应用中的潜力。

Abstract: 3D morphing remains challenging due to the difficulty of generating semantically consistent and temporally smooth deformations, especially across categories. We present MorphAny3D, a training-free framework that leverages Structured Latent (SLAT) representations for high-quality 3D morphing. Our key insight is that intelligently blending source and target SLAT features within the attention mechanisms of 3D generators naturally produces plausible morphing sequences. To this end, we introduce Morphing Cross-Attention (MCA), which fuses source and target information for structural coherence, and Temporal-Fused Self-Attention (TFSA), which enhances temporal consistency by incorporating features from preceding frames. An orientation correction strategy further mitigates the pose ambiguity within the morphing steps. Extensive experiments show that our method generates state-of-the-art morphing sequences, even for challenging cross-category cases. MorphAny3D further supports advanced applications such as decoupled morphing and 3D style transfer, and can be generalized to other SLAT-based generative models. Project page: https://xiaokunsun.github.io/MorphAny3D.github.io/.

</details>


### [8] [CropNeRF: A Neural Radiance Field-Based Framework for Crop Counting](https://arxiv.org/abs/2601.00207)
*Md Ahmed Al Muzaddid,William J. Beksi*

Main category: cs.CV

TL;DR: 提出基于多视角图像和神经辐射场（NeRF）的3D实例分割框架，用于农业场景中作物的精确计数，解决了遮挡和作物聚集的挑战。


<details>
  <summary>Details</summary>
Motivation: 室外农田环境中，作物部分遮挡和聚集导致的模糊性给基于图像的作物计数带来巨大挑战，需要更精确的3D实例分割方法。

Method: 使用多视角2D图像，结合神经辐射场（NeRF）进行视图合成，引入作物可见性和掩码一致性评分，结合3D信息实现作物实例的3D分割。

Result: 在棉花铃、苹果和梨三个农业数据集上验证，展示了稳定的计数性能，不受作物颜色、形状和大小变化的影响，性能优于现有方法。

Conclusion: 提出的3D实例分割框架能有效解决农业作物计数中的遮挡和聚集问题，无需作物特定参数调优，并贡献了棉花植物数据集促进进一步研究。

Abstract: Rigorous crop counting is crucial for effective agricultural management and informed intervention strategies. However, in outdoor field environments, partial occlusions combined with inherent ambiguity in distinguishing clustered crops from individual viewpoints poses an immense challenge for image-based segmentation methods. To address these problems, we introduce a novel crop counting framework designed for exact enumeration via 3D instance segmentation. Our approach utilizes 2D images captured from multiple viewpoints and associates independent instance masks for neural radiance field (NeRF) view synthesis. We introduce crop visibility and mask consistency scores, which are incorporated alongside 3D information from a NeRF model. This results in an effective segmentation of crop instances in 3D and highly-accurate crop counts. Furthermore, our method eliminates the dependence on crop-specific parameter tuning. We validate our framework on three agricultural datasets consisting of cotton bolls, apples, and pears, and demonstrate consistent counting performance despite major variations in crop color, shape, and size. A comparative analysis against the state of the art highlights superior performance on crop counting tasks. Lastly, we contribute a cotton plant dataset to advance further research on this topic.

</details>


### [9] [IntraStyler: Exemplar-based Style Synthesis for Cross-modality Domain Adaptation](https://arxiv.org/abs/2601.00212)
*Han Liu,Yubo Fan,Hao Li,Dewei Hu,Daniel Moyer,Zhoubing Xu,Benoit M. Dawant,Ipek Oguz*

Main category: cs.CV

TL;DR: IntraStyler：一种基于范例的样式合成方法，无需先验知识即可捕获多样化的域内样式，用于提升跨模态域适应的分割性能


<details>
  <summary>Details</summary>
Motivation: 现有无监督域适应方法主要关注源域和目标域之间的域偏移，而域内变异性研究不足。传统方法需要预先指定域内变化进行样式合成，这在实践中不切实际。

Method: 提出IntraStyler方法：1）使用范例图像指导样式合成，使输出样式匹配范例样式；2）引入样式编码器，基于对比学习判别性地学习样式特征；3）无需先验知识即可捕获多样化的域内样式。

Result: 在最大的跨模态域适应公共数据集CrossMoDA 2023上进行评估，实验表明该方法在可控样式合成方面有效，且多样化的合成数据对下游分割任务有益。

Conclusion: IntraStyler能够在不依赖先验知识的情况下捕获多样化的域内样式，通过可控样式合成生成多样化的目标域数据，有效提升跨模态域适应中的分割性能。

Abstract: Image-level domain alignment is the de facto approach for unsupervised domain adaptation, where unpaired image translation is used to minimize the domain gap. Prior studies mainly focus on the domain shift between the source and target domains, whereas the intra-domain variability remains under-explored. To address the latter, an effective strategy is to diversify the styles of the synthetic target domain data during image translation. However, previous methods typically require intra-domain variations to be pre-specified for style synthesis, which may be impractical. In this paper, we propose an exemplar-based style synthesis method named IntraStyler, which can capture diverse intra-domain styles without any prior knowledge. Specifically, IntraStyler uses an exemplar image to guide the style synthesis such that the output style matches the exemplar style. To extract the style-only features, we introduce a style encoder to learn styles discriminatively based on contrastive learning. We evaluate the proposed method on the largest public dataset for cross-modality domain adaptation, CrossMoDA 2023. Our experiments show the efficacy of our method in controllable style synthesis and the benefits of diverse synthetic data for downstream segmentation. Code is available at https://github.com/han-liu/IntraStyler.

</details>


### [10] [From Sight to Insight: Improving Visual Reasoning Capabilities of Multimodal Models via Reinforcement Learning](https://arxiv.org/abs/2601.00215)
*Omar Sharif,Eftekhar Hossain,Patrick Ng*

Main category: cs.CV

TL;DR: 使用强化学习提升多模态大语言模型的视觉推理能力，通过奖励函数激励模型整合视觉信息进行长链推理，在视觉谜题等任务上取得显著改进


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型生成的推理链缺乏视觉信息的整合，限制了其在需要精确视觉感知的任务（如视觉谜题）上的表现。研究表明视觉感知是这类任务的关键瓶颈，将图像转换为文本描述能显著提升性能。

Method: 采用奖励驱动的强化学习方法，设计了六个针对不同推理方面的奖励函数（包括图像理解、思考步骤和答案准确性），使用组相对策略优化（GRPO）来激励更长、结构化的推理，并防止视觉信息被绕过。

Result: 在Qwen-2.5-VL-7B模型上实现了5.56%的性能提升，在领域内和领域外设置下均获得一致改进。对于Claude 3.5和Claude 3.7模型，将图像转换为文本描述分别带来了26.7%和23.6%的性能增益。

Conclusion: 强化学习是解锁开源多模态大语言模型长视觉推理能力的有效机制，无需昂贵的监督数据。通过精心设计的奖励函数和GRPO优化，可以显著提升模型在需要精确视觉感知任务上的表现。

Abstract: Reinforcement learning (RL) has emerged as a promising approach for eliciting reasoning chains before generating final answers. However, multimodal large language models (MLLMs) generate reasoning that lacks integration of visual information. This limits their ability to solve problems that demand accurate visual perception, such as visual puzzles. We show that visual perception is the key bottleneck in such tasks: converting images into textual descriptions significantly improves performance, yielding gains of 26.7% for Claude 3.5 and 23.6% for Claude 3.7.
  To address this, we investigate reward-driven RL as a mechanism to unlock long visual reasoning in open-source MLLMs without requiring costly supervision. We design and evaluate six reward functions targeting different reasoning aspects, including image understanding, thinking steps, and answer accuracy. Using group relative policy optimization (GRPO), our approach explicitly incentivizes longer, structured reasoning and mitigates bypassing of visual information. Experiments on Qwen-2.5-VL-7B achieve 5.56% improvements over the base model, with consistent gains across both in-domain and out-of-domain settings.

</details>


### [11] [LooC: Effective Low-Dimensional Codebook for Compositional Vector Quantization](https://arxiv.org/abs/2601.00222)
*Jie Li,Kwan-Yee K. Wong,Kai Han*

Main category: cs.CV

TL;DR: LooC是一种新型低维组合向量量化方法，通过重构码向量与特征向量的关系，使用参数高效的低维码本进行组合量化，显著提升性能同时减小码本尺寸。


<details>
  <summary>Details</summary>
Motivation: 随着数据和模型复杂度的增加，需要更高容量但更紧凑的向量量化方法。现有方法在码本容量和紧凑性之间存在冲突，需要一种能调和这种矛盾的新方法。

Method: LooC采用低维组合向量量化方法：1) 重构码向量与特征向量的关系，将码向量视为特征向量中的低维组合单元进行组合；2) 引入参数无关的外推-插值机制，在VQ过程中增强和平滑特征；3) 实现全码本利用，避免码本坍塌问题。

Result: 在多个任务、数据集和架构上的广泛评估表明，LooC在显著减小码本尺寸的同时，超越了现有VQ方法，实现了最先进的性能。

Conclusion: LooC成功解决了向量量化中容量与紧凑性的矛盾，提供了一种参数高效、性能优越的解决方案，可作为即插即用模块应用于各种基于VQ的下游任务。

Abstract: Vector quantization (VQ) is a prevalent and fundamental technique that discretizes continuous feature vectors by approximating them using a codebook. As the diversity and complexity of data and models continue to increase, there is an urgent need for high-capacity, yet more compact VQ methods. This paper aims to reconcile this conflict by presenting a new approach called LooC, which utilizes an effective Low-dimensional codebook for Compositional vector quantization. Firstly, LooC introduces a parameter-efficient codebook by reframing the relationship between codevectors and feature vectors, significantly expanding its solution space. Instead of individually matching codevectors with feature vectors, LooC treats them as lower-dimensional compositional units within feature vectors and combines them, resulting in a more compact codebook with improved performance. Secondly, LooC incorporates a parameter-free extrapolation-by-interpolation mechanism to enhance and smooth features during the VQ process, which allows for better preservation of details and fidelity in feature approximation. The design of LooC leads to full codebook usage, effectively utilizing the compact codebook while avoiding the problem of collapse. Thirdly, LooC can serve as a plug-and-play module for existing methods for different downstream tasks based on VQ. Finally, extensive evaluations on different tasks, datasets, and architectures demonstrate that LooC outperforms existing VQ methods, achieving state-of-the-art performance with a significantly smaller codebook.

</details>


### [12] [Towards Syn-to-Real IQA: A Novel Perspective on Reshaping Synthetic Data Distributions](https://arxiv.org/abs/2601.00225)
*Aobo Li,Jinjian Wu,Yongxu Liu,Leida Li,Weisheng Dong*

Main category: cs.CV

TL;DR: 本文提出SynDR-IQA框架，通过重塑合成数据分布来解决盲图像质量评估中合成数据训练模型泛化能力有限的问题。该框架包含分布感知的多样化内容上采样和密度感知的冗余聚类下采样两种策略，有效提升了BIQA模型在跨数据集设置下的性能。


<details>
  <summary>Details</summary>
Motivation: 盲图像质量评估（BIQA）面临大规模标注数据稀缺的挑战。虽然合成数据提供了解决方案，但现有合成数据集训练的模型泛化能力有限。作者发现合成数据集学习的表示呈现离散聚类模式：高质量图像特征围绕参考图像聚类，低质量图像特征基于失真类型聚类，这种分布问题阻碍了回归性能。

Method: 提出SynDR-IQA框架，基于样本多样性和冗余对泛化误差影响的理论推导，采用两种策略：1）分布感知的多样化内容上采样，在保持内容分布的同时增强视觉多样性；2）密度感知的冗余聚类下采样，通过减少密集聚类区域的样本密度来平衡样本分布。

Result: 在三种跨数据集设置（合成到真实、合成到算法、合成到合成）上的大量实验证明了该方法的有效性。代码已在GitHub开源。

Conclusion: SynDR-IQA通过重塑合成数据分布有效解决了BIQA中合成数据训练的泛化问题。该方法基于理论分析，通过平衡样本多样性和冗余来改善数据分布，为合成数据在BIQA中的应用提供了新思路。

Abstract: Blind Image Quality Assessment (BIQA) has advanced significantly through deep learning, but the scarcity of large-scale labeled datasets remains a challenge. While synthetic data offers a promising solution, models trained on existing synthetic datasets often show limited generalization ability. In this work, we make a key observation that representations learned from synthetic datasets often exhibit a discrete and clustered pattern that hinders regression performance: features of high-quality images cluster around reference images, while those of low-quality images cluster based on distortion types. Our analysis reveals that this issue stems from the distribution of synthetic data rather than model architecture. Consequently, we introduce a novel framework SynDR-IQA, which reshapes synthetic data distribution to enhance BIQA generalization. Based on theoretical derivations of sample diversity and redundancy's impact on generalization error, SynDR-IQA employs two strategies: distribution-aware diverse content upsampling, which enhances visual diversity while preserving content distribution, and density-aware redundant cluster downsampling, which balances samples by reducing the density of densely clustered areas. Extensive experiments across three cross-dataset settings (synthetic-to-authentic, synthetic-to-algorithmic, and synthetic-to-synthetic) demonstrate the effectiveness of our method. The code is available at https://github.com/Li-aobo/SynDR-IQA.

</details>


### [13] [Application Research of a Deep Learning Model Integrating CycleGAN and YOLO in PCB Infrared Defect Detection](https://arxiv.org/abs/2601.00237)
*Chao Yang,Haoyuan Zheng,Yue Ma*

Main category: cs.CV

TL;DR: 提出跨模态数据增强框架，结合CycleGAN和YOLOv8解决PCB红外缺陷检测数据稀缺问题


<details>
  <summary>Details</summary>
Motivation: 红外(IR)数据稀缺是PCB缺陷检测的关键瓶颈，传统方法依赖配对监督，难以获得足够训练数据

Method: 使用CycleGAN进行无配对图像翻译，将丰富的可见光PCB图像映射到红外域，生成高质量伪红外样本；构建异构训练策略，融合伪红外数据和有限真实红外数据训练轻量级YOLOv8检测器

Result: 该方法在低数据条件下有效增强特征学习，增强后的检测器显著优于仅使用有限真实数据训练的模型，接近全监督训练的性能基准

Conclusion: 伪红外合成作为工业检测的鲁棒增强策略具有显著效果，为解决红外数据稀缺问题提供了有效方案

Abstract: This paper addresses the critical bottleneck of infrared (IR) data scarcity in Printed Circuit Board (PCB) defect detection by proposing a cross-modal data augmentation framework integrating CycleGAN and YOLOv8. Unlike conventional methods relying on paired supervision, we leverage CycleGAN to perform unpaired image-to-image translation, mapping abundant visible-light PCB images into the infrared domain. This generative process synthesizes high-fidelity pseudo-IR samples that preserve the structural semantics of defects while accurately simulating thermal distribution patterns. Subsequently, we construct a heterogeneous training strategy that fuses generated pseudo-IR data with limited real IR samples to train a lightweight YOLOv8 detector. Experimental results demonstrate that this method effectively enhances feature learning under low-data conditions. The augmented detector significantly outperforms models trained on limited real data alone and approaches the performance benchmarks of fully supervised training, proving the efficacy of pseudo-IR synthesis as a robust augmentation strategy for industrial inspection.

</details>


### [14] [Context-Aware Pesticide Recommendation via Few-Shot Pest Recognition for Precision Agriculture](https://arxiv.org/abs/2601.00243)
*Anirudha Ghosh,Ritam Sarkar,Debaditya Barman*

Main category: cs.CV

TL;DR: 提出轻量级害虫检测与农药推荐框架，适用于智能手机和无人机等低资源设备，帮助小农户实现精准农业管理。


<details>
  <summary>Details</summary>
Motivation: 传统害虫管理方法依赖人工田间检查和化学农药，成本高、耗时耗力且对环境有害。需要为资源有限的小农户开发高效、环保的解决方案。

Method: 框架包含两个模块：1) 害虫检测模块使用轻量级CNN结合原型元学习，实现小样本准确识别；2) 农药推荐模块结合作物类型、生长阶段等环境因素推荐安全环保农药。使用多源数据集训练评估。

Result: 轻量级CNN达到与先进模型相当的高精度，同时显著降低计算复杂度。决策支持系统减少了对传统化学农药的依赖，促进了可持续实践。

Conclusion: 该框架在精准农业中具有实时应用潜力，为小农户提供了经济高效、环境友好的害虫管理解决方案。

Abstract: Effective pest management is crucial for enhancing agricultural productivity, especially for crops such as sugarcane and wheat that are highly vulnerable to pest infestations. Traditional pest management methods depend heavily on manual field inspections and the use of chemical pesticides. These approaches are often costly, time-consuming, labor-intensive, and can have a negative impact on the environment. To overcome these challenges, this study presents a lightweight framework for pest detection and pesticide recommendation, designed for low-resource devices such as smartphones and drones, making it suitable for use by small and marginal farmers.
  The proposed framework includes two main components. The first is a Pest Detection Module that uses a compact, lightweight convolutional neural network (CNN) combined with prototypical meta-learning to accurately identify pests even when only a few training samples are available. The second is a Pesticide Recommendation Module that incorporates environmental factors like crop type and growth stage to suggest safe and eco-friendly pesticide recommendations. To train and evaluate our framework, a comprehensive pest image dataset was developed by combining multiple publicly available datasets. The final dataset contains samples with different viewing angles, pest sizes, and background conditions to ensure strong generalization.
  Experimental results show that the proposed lightweight CNN achieves high accuracy, comparable to state-of-the-art models, while significantly reducing computational complexity. The Decision Support System additionally improves pest management by reducing dependence on traditional chemical pesticides and encouraging sustainable practices, demonstrating its potential for real-time applications in precision agriculture.

</details>


### [15] [TotalFM: An Organ-Separated Framework for 3D-CT Vision Foundation Models](https://arxiv.org/abs/2601.00260)
*Kohei Yamamoto,Tomohiro Kikuchi*

Main category: cs.CV

TL;DR: TotalFM是一种基于器官分离概念的放射学基础模型，通过自动化创建器官体积-描述对，结合自监督预训练和对比学习，在3D-CT影像与语言表达对应关系学习中实现计算效率与表征能力的平衡。


<details>
  <summary>Details</summary>
Motivation: 尽管放射学基础模型有望应用于各种临床任务，但在3D-CT容积数据上训练时，计算成本限制仍是主要挑战。本研究旨在开发一种高效学习3D-CT影像与语言表达对应关系的模型，以平衡计算效率和表征能力。

Method: 基于器官分离概念，利用14万系列大规模数据集，通过分割技术和基于LLM的放射学报告处理自动化创建器官体积-发现句子对，结合VideoMAE自监督预训练和体积-文本对的对比学习。

Result: 在零样本器官级病变分类任务中，相比CT-CLIP在83%器官上获得更高F1分数，相比Merlin在64%器官上表现更好。在零样本发现级病变分类任务中，相比Merlin在83%发现类别上获得更高AUROC。在放射学报告生成任务中达到与现有VLMs相当的性能。

Conclusion: 器官分离学习框架可作为3D-CT基础模型实际实施的现实有效设计指南，所提模型在临床评估环境中展现出高泛化性能。

Abstract: While foundation models in radiology are expected to be applied to various clinical tasks, computational cost constraints remain a major challenge when training on 3D-CT volumetric data. In this study, we propose TotalFM, a radiological foundation model that efficiently learns the correspondence between 3D-CT images and linguistic expressions based on the concept of organ separation, utilizing a large-scale dataset of 140,000 series. By automating the creation of organ volume and finding-sentence pairs through segmentation techniques and Large Language Model (LLM)-based radiology report processing, and by combining self-supervised pre-training via VideoMAE with contrastive learning using volume-text pairs, we aimed to balance computational efficiency and representation capability. In zero-shot organ-wise lesion classification tasks, the proposed model achieved higher F1 scores in 83% (5/6) of organs compared to CT-CLIP and 64% (9/14) of organs compared to Merlin. These results suggest that the proposed model exhibits high generalization performance in a clinical evaluation setting using actual radiology report sentences. Furthermore, in zero-shot finding-wise lesion classification tasks, our model achieved a higher AUROC in 83% (25/30) of finding categories compared to Merlin. We also confirmed performance comparable to existing Vision-Language Models (VLMs) in radiology report generation tasks. Our results demonstrate that the organ-separated learning framework can serve as a realistic and effective design guideline for the practical implementation of 3D-CT foundation models.

</details>


### [16] [S1-MMAlign: A Large-Scale, Multi-Disciplinary Dataset for Scientific Figure-Text Understanding](https://arxiv.org/abs/2601.00264)
*He Wang,Longteng Guo,Pengkang Huo,Xuanxu Lin,Yichen Yuan,Jie Jiang,Jing Liu*

Main category: cs.CV

TL;DR: S1-MMAlign是一个大规模多学科多模态数据集，包含1550万高质量图像-文本对，通过AI增强管道解决科学图像与文本描述之间的语义鸿沟问题。


<details>
  <summary>Details</summary>
Motivation: 多模态学习在通用领域已取得革命性进展，但在科学发现中的应用受到阻碍，主要原因是复杂科学图像与稀疏文本描述之间存在深刻的语义鸿沟。现有科学多模态数据集存在对齐质量差的问题，限制了AI在科学领域的应用。

Method: 1. 构建大规模多学科数据集：从250万篇开放获取科学论文中提取1550万图像-文本对，涵盖物理、生物、工程等多个学科，包含实验装置、热图、显微图像等多种视觉模态。2. 开发AI就绪的语义增强管道：利用Qwen-VL多模态大模型系列，通过合成论文摘要和引用上下文来重新标注图像，解决原始科学标题弱对齐问题。

Result: 技术验证表明增强显著提升数据质量：基于SciBERT的伪困惑度指标显示语义模糊性降低，CLIP分数显示图像-文本对齐提升18.21%。数据集在Hugging Face上公开可用。

Conclusion: S1-MMAlign为解决科学多模态学习中的语义鸿沟问题提供了基础资源，通过AI增强管道显著改善了科学图像与文本描述的对齐质量，为推进科学推理和跨模态理解奠定了重要基础。

Abstract: Multimodal learning has revolutionized general domain tasks, yet its application in scientific discovery is hindered by the profound semantic gap between complex scientific imagery and sparse textual descriptions. We present S1-MMAlign, a large-scale, multi-disciplinary multimodal dataset comprising over 15.5 million high-quality image-text pairs derived from 2.5 million open-access scientific papers. Spanning disciplines from physics and biology to engineering, the dataset captures diverse visual modalities including experimental setups, heatmaps, and microscopic imagery. To address the pervasive issue of weak alignment in raw scientific captions, we introduce an AI-ready semantic enhancement pipeline that utilizes the Qwen-VL multimodal large model series to recaption images by synthesizing context from paper abstracts and citation contexts. Technical validation demonstrates that this enhancement significantly improves data quality: SciBERT-based pseudo-perplexity metrics show reduced semantic ambiguity, while CLIP scores indicate an 18.21% improvement in image-text alignment. S1-MMAlign provides a foundational resource for advancing scientific reasoning and cross-modal understanding in the era of AI for Science. The dataset is publicly available at https://huggingface.co/datasets/ScienceOne-AI/S1-MMAlign.

</details>


### [17] [ActErase: A Training-Free Paradigm for Precise Concept Erasure via Activation Patching](https://arxiv.org/abs/2601.00267)
*Yi Sun,Xinhao Zhong,Hongyan Li,Yimin Zhou,Junhao Li,Bin Chen,Xuan Wang*

Main category: cs.CV

TL;DR: 提出一种无需训练的扩散模型概念擦除方法ActErase，通过激活差异区域识别和动态替换，在保持生成能力的同时实现高效概念移除


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型存在安全、版权和伦理风险，现有概念擦除方法大多依赖数据密集且计算昂贵的微调，限制了实际应用

Method: 提出训练免费方法ActErase：通过提示对分析识别激活差异区域，提取目标激活，在前向传播过程中动态替换输入激活

Result: 在三个关键擦除任务（裸露、艺术风格、对象移除）上实现SOTA性能，有效保持模型整体生成能力，对对抗攻击具有强鲁棒性

Conclusion: ActErase为扩散模型中的轻量级概念操作建立了新的即插即用范式，无需训练即可实现高效概念擦除

Abstract: Recent advances in text-to-image diffusion models have demonstrated remarkable generation capabilities, yet they raise significant concerns regarding safety, copyright, and ethical implications. Existing concept erasure methods address these risks by removing sensitive concepts from pre-trained models, but most of them rely on data-intensive and computationally expensive fine-tuning, which poses a critical limitation. To overcome these challenges, inspired by the observation that the model's activations are predominantly composed of generic concepts, with only a minimal component can represent the target concept, we propose a novel training-free method (ActErase) for efficient concept erasure. Specifically, the proposed method operates by identifying activation difference regions via prompt-pair analysis, extracting target activations and dynamically replacing input activations during forward passes. Comprehensive evaluations across three critical erasure tasks (nudity, artistic style, and object removal) demonstrates that our training-free method achieves state-of-the-art (SOTA) erasure performance, while effectively preserving the model's overall generative capability. Our approach also exhibits strong robustness against adversarial attacks, establishing a new plug-and-play paradigm for lightweight yet effective concept manipulation in diffusion models.

</details>


### [18] [SV-GS: Sparse View 4D Reconstruction with Skeleton-Driven Gaussian Splatting](https://arxiv.org/abs/2601.00285)
*Jun-Jee Chao,Volkan Isler*

Main category: cs.CV

TL;DR: SV-GS：一种在稀疏观测下重建动态目标的框架，通过骨架驱动的变形场和运动估计，在稀疏视角和时间采样下实现高质量动态重建。


<details>
  <summary>Details</summary>
Motivation: 现实世界中动态目标重建面临观测稀疏性的挑战。传统方法需要密集的视角覆盖和时间采样（如多视角视频），但在实际场景中（如监控摄像头），观测往往在时间和空间上都很稀疏，导致动态重建问题高度不适定。

Method: 提出SV-GS框架，利用粗略骨架图和初始静态重建作为输入，优化骨架驱动的变形场。该变形场包含粗粒度骨架关节姿态估计器和细粒度变形模块，仅使关节姿态估计器具有时间依赖性，从而实现平滑运动插值并保留几何细节。后期可替换初始静态重建为基于扩散的生成先验。

Result: 在合成数据集上，相比现有方法在稀疏观测下PSNR提升高达34%；在真实世界数据集上，使用显著更少的帧数即可达到与密集单目视频方法相当的性能。验证了使用扩散生成先验替代初始静态重建的可行性。

Conclusion: SV-GS能够在稀疏观测条件下有效重建动态目标，通过骨架驱动的变形场实现了高质量的运动估计和几何细节保持，为现实世界场景中的动态重建提供了实用解决方案。

Abstract: Reconstructing a dynamic target moving over a large area is challenging. Standard approaches for dynamic object reconstruction require dense coverage in both the viewing space and the temporal dimension, typically relying on multi-view videos captured at each time step. However, such setups are only possible in constrained environments. In real-world scenarios, observations are often sparse over time and captured sparsely from diverse viewpoints (e.g., from security cameras), making dynamic reconstruction highly ill-posed. We present SV-GS, a framework that simultaneously estimates a deformation model and the object's motion over time under sparse observations. To initialize SV-GS, we leverage a rough skeleton graph and an initial static reconstruction as inputs to guide motion estimation. (Later, we show that this input requirement can be relaxed.) Our method optimizes a skeleton-driven deformation field composed of a coarse skeleton joint pose estimator and a module for fine-grained deformations. By making only the joint pose estimator time-dependent, our model enables smooth motion interpolation while preserving learned geometric details. Experiments on synthetic datasets show that our method outperforms existing approaches under sparse observations by up to 34% in PSNR, and achieves comparable performance to dense monocular video methods on real-world datasets despite using significantly fewer frames. Moreover, we demonstrate that the input initial static reconstruction can be replaced by a diffusion-based generative prior, making our method more practical for real-world scenarios.

</details>


### [19] [Towards Automated Differential Diagnosis of Skin Diseases Using Deep Learning and Imbalance-Aware Strategies](https://arxiv.org/abs/2601.00286)
*Ali Anaissi,Ali Braytee,Weidong Huang,Junaid Akram,Alaa Farhat,Jie Hua*

Main category: cs.CV

TL;DR: 开发基于Swin Transformer的深度学习模型，在ISIC2019数据集上实现87.71%的皮肤病变分类准确率，用于辅助临床诊断和患者自我评估。


<details>
  <summary>Details</summary>
Motivation: 皮肤疾病日益普遍而皮肤科医生资源有限，需要智能工具支持患者和临床医生进行及时准确的皮肤病诊断。

Method: 基于公开皮肤病图像数据集进行预训练，利用Swin Transformer架构提取视觉特征，通过优化模型架构、数据预处理流程和针对性数据增强技术提升性能。

Result: 在ISIC2019数据集的八个皮肤病变类别上实现了87.71%的分类准确率。

Conclusion: 该模型展示了作为临床医生诊断支持工具和患者自我评估辅助工具的潜力。

Abstract: As dermatological conditions become increasingly common and the availability of dermatologists remains limited, there is a growing need for intelligent tools to support both patients and clinicians in the timely and accurate diagnosis of skin diseases. In this project, we developed a deep learning based model for the classification and diagnosis of skin conditions. By leveraging pretraining on publicly available skin disease image datasets, our model effectively extracted visual features and accurately classified various dermatological cases. Throughout the project, we refined the model architecture, optimized data preprocessing workflows, and applied targeted data augmentation techniques to improve overall performance. The final model, based on the Swin Transformer, achieved a prediction accuracy of 87.71 percent across eight skin lesion classes on the ISIC2019 dataset. These results demonstrate the model's potential as a diagnostic support tool for clinicians and a self assessment aid for patients.

</details>


### [20] [TimeColor: Flexible Reference Colorization via Temporal Concatenation](https://arxiv.org/abs/2601.00296)
*Bryan Constantine Sadihin,Yihao Meng,Michael Hua Wang,Matteo Jiahao Chen,Hang Su*

Main category: cs.CV

TL;DR: TimeColor是一个基于草图的视频着色模型，支持使用异构、可变数量的参考图像，通过显式的每参考区域分配和时空对应掩码注意力来提升着色质量。


<details>
  <summary>Details</summary>
Motivation: 现有着色模型通常只使用单个参考（通常是场景的第一帧），忽略了其他条件数据源，如角色设定图、背景图像或任意已着色帧。这限制了着色质量和一致性。

Method: 提出TimeColor模型：1) 将参考编码为额外的潜在帧并进行时间拼接，使模型能在每个扩散步骤中并行处理参考，同时保持参数固定；2) 使用时空对应掩码注意力来加强主体-参考绑定；3) 采用模态分离的RoPE索引机制。

Result: 在SAKUGA-42M数据集上的实验表明，TimeColor在单参考和多参考协议下均优于现有基线，在颜色保真度、身份一致性和时间稳定性方面均有提升。

Conclusion: TimeColor通过支持异构多参考和显式区域分配，有效解决了传统单参考着色的局限性，减少了捷径学习和跨身份调色板泄漏问题，显著提升了视频着色质量。

Abstract: Most colorization models condition only on a single reference, typically the first frame of the scene. However, this approach ignores other sources of conditional data, such as character sheets, background images, or arbitrary colorized frames. We propose TimeColor, a sketch-based video colorization model that supports heterogeneous, variable-count references with the use of explicit per-reference region assignment. TimeColor encodes references as additional latent frames which are concatenated temporally, permitting them to be processed concurrently in each diffusion step while keeping the model's parameter count fixed. TimeColor also uses spatiotemporal correspondence-masked attention to enforce subject-reference binding in addition to modality-disjoint RoPE indexing. These mechanisms mitigate shortcutting and cross-identity palette leakage. Experiments on SAKUGA-42M under both single- and multi-reference protocols show that TimeColor improves color fidelity, identity consistency, and temporal stability over prior baselines.

</details>


### [21] [VisNet: Efficient Person Re-Identification via Alpha-Divergence Loss, Feature Fusion and Dynamic Multi-Task Learning](https://arxiv.org/abs/2601.00307)
*Anns Ijaz,Muhammad Azeem Javed*

Main category: cs.CV

TL;DR: VisNet：一种计算高效的行人重识别模型，通过多尺度特征融合、语义聚类和动态权重平均等技术，在保持高精度的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有行人重识别方法虽然精度高但计算成本大，难以在监控和移动应用等计算资源有限的实际场景中部署。需要一种既准确又计算高效的模型。

Method: 提出VisNet模型，包含：1）多尺度特征融合（融合ResNet50的1-4阶段特征，无并行路径）；2）语义聚类（基于解剖学身体分区，使用基于规则的伪标签引入空间约束）；3）动态权重平均技术平衡分类语义正则化；4）使用FIDI损失函数改进度量学习。

Result: 在Market-1501数据集上达到87.05% Rank-1和77.65% mAP，仅需32.41M参数和4.601 GFLOPs，显著优于现有高计算成本方法。

Conclusion: VisNet提供了一种实用的行人重识别解决方案，在保持高精度的同时大幅降低计算复杂度，适合在计算资源有限的监控和移动应用中实时部署。

Abstract: Person re-identification (ReID) is an extremely important area in both surveillance and mobile applications, requiring strong accuracy with minimal computational cost. State-of-the-art methods give good accuracy but with high computational budgets. To remedy this, this paper proposes VisNet, a computationally efficient and effective re-identification model suitable for real-world scenarios. It is the culmination of conceptual contributions, including feature fusion at multiple scales with automatic attention on each, semantic clustering with anatomical body partitioning, a dynamic weight averaging technique to balance classification semantic regularization, and the use of loss function FIDI for improved metric learning tasks. The multiple scales fuse ResNet50's stages 1 through 4 without the use of parallel paths, with semantic clustering introducing spatial constraints through the use of rule-based pseudo-labeling. VisNet achieves 87.05% Rank-1 and 77.65% mAP on the Market-1501 dataset, having 32.41M parameters and 4.601 GFLOPs, hence, proposing a practical approach for real-time deployment in surveillance and mobile applications where computational resources are limited.

</details>


### [22] [OmniVaT: Single Domain Generalization for Multimodal Visual-Tactile Learning](https://arxiv.org/abs/2601.00352)
*Liuxiang Qiu,Hui Da,Yuzhen Niu,Tiesong Zhao,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: OmniVaT框架首次成功解决了单域泛化视觉触觉学习任务，通过多模态分数傅里叶适配器和离散树生成模块，有效缓解模态差异并增强对未见域的适应性。


<details>
  <summary>Details</summary>
Motivation: 视觉触觉学习面临两个主要挑战：1) VIS和TAC图像之间的模态差异；2) 由非标准化触觉传感器和不一致数据收集程序导致的域差距。这些挑战被形式化为单域泛化多模态VTL任务。

Method: 提出OmniVaT框架，包含两个核心组件：1) 多模态分数傅里叶适配器(MFFA)，将VIS和TAC嵌入映射到统一的嵌入-频率空间，缓解模态差异；2) 离散树生成(DTG)模块，通过分层树结构获得多样可靠的多模态分数表示，增强对未见域波动的适应性。

Result: 大量实验表明，OmniVaT在SDG-VTL任务上表现出卓越的跨域泛化性能，无需多域训练数据或精细的跨模态融合策略。

Conclusion: OmniVaT首次成功解决了单域泛化多模态视觉触觉学习任务，通过统一的嵌入-频率空间映射和分层树结构表示，有效应对模态差异和域差距挑战。

Abstract: Visual-tactile learning (VTL) enables embodied agents to perceive the physical world by integrating visual (VIS) and tactile (TAC) sensors. However, VTL still suffers from modality discrepancies between VIS and TAC images, as well as domain gaps caused by non-standardized tactile sensors and inconsistent data collection procedures. We formulate these challenges as a new task, termed single domain generalization for multimodal VTL (SDG-VTL). In this paper, we propose an OmniVaT framework that, for the first time, successfully addresses this task. On the one hand, OmniVaT integrates a multimodal fractional Fourier adapter (MFFA) to map VIS and TAC embeddings into a unified embedding-frequency space, thereby effectively mitigating the modality gap without multi-domain training data or careful cross-modal fusion strategies. On the other hand, it also incorporates a discrete tree generation (DTG) module that obtains diverse and reliable multimodal fractional representations through a hierarchical tree structure, thereby enhancing its adaptivity to fluctuating domain shifts in unseen domains. Extensive experiments demonstrate the superior cross-domain generalization performance of OmniVaT on the SDG-VTL task.

</details>


### [23] [Efficient Prediction of Dense Visual Embeddings via Distillation and RGB-D Transformers](https://arxiv.org/abs/2601.00359)
*Söhnke Benedikt Fischedick,Daniel Seichter,Benedict Stephan,Robin Schmidt,Horst-Michael Gross*

Main category: cs.CV

TL;DR: DVEFormer：基于RGB-D Transformer的高效方法，通过知识蒸馏预测密集文本对齐视觉嵌入，替代传统语义分割，支持自然语言查询和3D建图


<details>
  <summary>Details</summary>
Motivation: 家庭环境中机器人需要全面理解周围环境以与未经训练的人类有效直观交互，传统语义分割方法使用固定预定义类别限制了灵活性

Method: 提出DVEFormer，基于RGB-D Transformer架构，使用Alpha-CLIP的教师嵌入通过知识蒸馏指导学生学习细粒度像素级嵌入，支持文本查询和3D建图

Result: 在室内数据集上达到竞争性性能，满足实时要求：完整模型26.3 FPS，小型变体77.0 FPS（NVIDIA Jetson AGX Orin），支持自然语言查询和3D建图应用

Conclusion: DVEFormer可作为传统分割方法的即插即用替代方案，提供灵活的自然语言查询能力，无缝集成到移动机器人3D建图流程中

Abstract: In domestic environments, robots require a comprehensive understanding of their surroundings to interact effectively and intuitively with untrained humans. In this paper, we propose DVEFormer - an efficient RGB-D Transformer-based approach that predicts dense text-aligned visual embeddings (DVE) via knowledge distillation. Instead of directly performing classical semantic segmentation with fixed predefined classes, our method uses teacher embeddings from Alpha-CLIP to guide our efficient student model DVEFormer in learning fine-grained pixel-wise embeddings. While this approach still enables classical semantic segmentation, e.g., via linear probing, it further enables flexible text-based querying and other applications, such as creating comprehensive 3D maps. Evaluations on common indoor datasets demonstrate that our approach achieves competitive performance while meeting real-time requirements, operating at 26.3 FPS for the full model and 77.0 FPS for a smaller variant on an NVIDIA Jetson AGX Orin. Additionally, we show qualitative results that highlight the effectiveness and possible use cases in real-world applications. Overall, our method serves as a drop-in replacement for traditional segmentation approaches while enabling flexible natural-language querying and seamless integration into 3D mapping pipelines for mobile robotics.

</details>


### [24] [BHaRNet: Reliability-Aware Body-Hand Modality Expertized Networks for Fine-grained Skeleton Action Recognition](https://arxiv.org/abs/2601.00369)
*Seungyeon Cho,Tae-kyun Kim*

Main category: cs.CV

TL;DR: 提出概率双流框架，统一可靠性建模和多模态集成，用于骨架动作识别，特别关注手部精细动作


<details>
  <summary>Details</summary>
Motivation: 现有骨架动作识别方法主要关注大尺度身体运动，忽略了对手部精细动作的识别，而手部动作对细粒度识别至关重要

Method: 概率双流框架包含三个关键组件：1) 无标定预处理管道，直接从原生坐标学习；2) 概率Noisy-OR融合，稳定可靠性感知的双流学习；3) 从骨架模态到RGB表示的跨模态集成，耦合四种骨架模态

Result: 在多个基准测试(NTU RGB+D 60/120, PKU-MMD, N-UCLA)和新定义的手部中心基准上均表现出持续改进和鲁棒性，特别是在噪声和异构条件下

Conclusion: 提出的概率双流框架能够统一可靠性建模和多模态集成，在骨架动作识别中有效处理手部精细动作，并在各种条件下表现出优越性能

Abstract: Skeleton-based human action recognition (HAR) has achieved remarkable progress with graph-based architectures. However, most existing methods remain body-centric, focusing on large-scale motions while neglecting subtle hand articulations that are crucial for fine-grained recognition. This work presents a probabilistic dual-stream framework that unifies reliability modeling and multi-modal integration, generalizing expertized learning under uncertainty across both intra-skeleton and cross-modal domains. The framework comprises three key components: (1) a calibration-free preprocessing pipeline that removes canonical-space transformations and learns directly from native coordinates; (2) a probabilistic Noisy-OR fusion that stabilizes reliability-aware dual-stream learning without requiring explicit confidence supervision; and (3) an intra- to cross-modal ensemble that couples four skeleton modalities (Joint, Bone, Joint Motion, and Bone Motion) to RGB representations, bridging structural and visual motion cues in a unified cross-modal formulation. Comprehensive evaluations across multiple benchmarks (NTU RGB+D~60/120, PKU-MMD, N-UCLA) and a newly defined hand-centric benchmark exhibit consistent improvements and robustness under noisy and heterogeneous conditions.

</details>


### [25] [NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos](https://arxiv.org/abs/2601.00393)
*Yuxue Yang,Lue Fan,Ziqi Shi,Junran Peng,Feng Wang,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: NeoVerse是一个多功能4D世界模型，能够进行4D重建、新轨迹视频生成和丰富的下游应用，通过可扩展的设计解决了现有方法对多视角数据或复杂预处理的依赖问题。


<details>
  <summary>Details</summary>
Motivation: 当前4D世界建模方法存在可扩展性限制，主要源于对昂贵专业多视角4D数据或繁琐训练预处理的依赖。作者旨在开发一个能够处理多样化单目视频的可扩展4D世界模型。

Method: NeoVerse采用无姿态前馈4D重建、在线单目退化模式模拟等技术，使整个流程能够扩展到多样化的单目视频数据，无需多视角输入或复杂预处理。

Result: NeoVerse在标准重建和生成基准测试中达到了最先进的性能，同时展现出对多种领域的泛化能力和多功能性。

Conclusion: NeoVerse通过可扩展的设计实现了多功能4D世界建模，能够处理多样化单目视频，在4D重建和视频生成任务上表现出色，为4D世界建模提供了新的解决方案。

Abstract: In this paper, we propose NeoVerse, a versatile 4D world model that is capable of 4D reconstruction, novel-trajectory video generation, and rich downstream applications. We first identify a common limitation of scalability in current 4D world modeling methods, caused either by expensive and specialized multi-view 4D data or by cumbersome training pre-processing. In contrast, our NeoVerse is built upon a core philosophy that makes the full pipeline scalable to diverse in-the-wild monocular videos. Specifically, NeoVerse features pose-free feed-forward 4D reconstruction, online monocular degradation pattern simulation, and other well-aligned techniques. These designs empower NeoVerse with versatility and generalization to various domains. Meanwhile, NeoVerse achieves state-of-the-art performance in standard reconstruction and generation benchmarks. Our project page is available at https://neoverse-4d.github.io

</details>


### [26] [RoLID-11K: A Dashcam Dataset for Small-Object Roadside Litter Detection](https://arxiv.org/abs/2601.00398)
*Tao Wu,Qing Xu,Xiangjian He,Oakleigh Weekes,James Brown,Wenting Duan*

Main category: cs.CV

TL;DR: 首个大规模车载摄像头路边垃圾检测数据集RoLID-11K，包含11,000多张标注图像，针对极端小目标检测挑战，涵盖英国多样化驾驶条件，建立动态驾驶场景基准。


<details>
  <summary>Details</summary>
Motivation: 当前路边垃圾监测依赖劳动密集型调查和公众报告，空间覆盖有限。现有视觉数据集主要针对街景静态图像、航拍场景或水生环境，无法反映车载摄像头视频中垃圾目标极小、稀疏且嵌入杂乱路边背景的独特特征。

Method: 引入RoLID-11K数据集，包含超过11,000张标注图像，涵盖英国多样化驾驶条件，呈现显著的长尾分布和小目标分布特征。对现代检测器进行全面基准测试，包括精度导向的Transformer架构和实时YOLO模型。

Result: CO-DETR及相关Transformer架构在定位精度上表现最佳，而实时模型受限于粗糙的特征层次结构。该数据集为动态驾驶场景中的极端小目标检测建立了具有挑战性的基准。

Conclusion: RoLID-11K是首个针对车载摄像头路边垃圾检测的大规模数据集，旨在支持开发可扩展、低成本的路边垃圾监测系统。该数据集公开可用，为动态驾驶场景中的极端小目标检测提供了重要研究基准。

Abstract: Roadside litter poses environmental, safety and economic challenges, yet current monitoring relies on labour-intensive surveys and public reporting, providing limited spatial coverage. Existing vision datasets for litter detection focus on street-level still images, aerial scenes or aquatic environments, and do not reflect the unique characteristics of dashcam footage, where litter appears extremely small, sparse and embedded in cluttered road-verge backgrounds. We introduce RoLID-11K, the first large-scale dataset for roadside litter detection from dashcams, comprising over 11k annotated images spanning diverse UK driving conditions and exhibiting pronounced long-tail and small-object distributions. We benchmark a broad spectrum of modern detectors, from accuracy-oriented transformer architectures to real-time YOLO models, and analyse their strengths and limitations on this challenging task. Our results show that while CO-DETR and related transformers achieve the best localisation accuracy, real-time models remain constrained by coarse feature hierarchies. RoLID-11K establishes a challenging benchmark for extreme small-object detection in dynamic driving scenes and aims to support the development of scalable, low-cost systems for roadside-litter monitoring. The dataset is available at https://github.com/xq141839/RoLID-11K.

</details>


### [27] [CPPO: Contrastive Perception for Vision Language Policy Optimization](https://arxiv.org/abs/2601.00501)
*Ahmad Rezaei,Mohsen Gholami,Saeed Ranjbar Alvar,Kevin Cannons,Mohammad Asiful Hossain,Zhou Weimin,Shunbo Zhou,Yong Zhang,Mohammad Akbari*

Main category: cs.CV

TL;DR: CPPO是一种用于微调视觉语言模型的对比感知策略优化方法，通过检测扰动输入下模型输出的熵变化来识别感知标记，并引入对比感知损失来增强感知一致性


<details>
  <summary>Details</summary>
Motivation: 虽然强化学习在语言模型的推理方面取得了进展，但将其扩展到多模态推理需要同时改进感知和推理两个方面。先前的工作主要通过显式的感知奖励来解决这一挑战，但将感知标记与推理标记分离很困难，需要额外的LLM、真实数据、强制分离感知与推理，或对所有输出标记不加区分地应用奖励

Method: CPPO通过检测在扰动输入图像下模型输出的熵变化来识别感知标记。然后，该方法通过引入对比感知损失（CPL）扩展了RL目标函数，该损失在信息保留扰动下强制一致性，在信息移除扰动下强制敏感性

Result: 实验表明，CPPO超越了先前的感知奖励方法，同时避免了额外模型的使用，使训练更加高效和可扩展

Conclusion: CPPO提供了一种有效的方法来改进视觉语言模型的感知能力，通过对比感知损失和熵变化检测机制，解决了多模态强化学习中感知与推理分离的挑战

Abstract: We introduce CPPO, a Contrastive Perception Policy Optimization method for finetuning vision-language models (VLMs). While reinforcement learning (RL) has advanced reasoning in language models, extending it to multimodal reasoning requires improving both the perception and reasoning aspects. Prior works tackle this challenge mainly with explicit perception rewards, but disentangling perception tokens from reasoning tokens is difficult, requiring extra LLMs, ground-truth data, forced separation of perception from reasoning by policy model, or applying rewards indiscriminately to all output tokens. CPPO addresses this problem by detecting perception tokens via entropy shifts in the model outputs under perturbed input images. CPPO then extends the RL objective function with a Contrastive Perception Loss (CPL) that enforces consistency under information-preserving perturbations and sensitivity under information-removing ones. Experiments show that CPPO surpasses previous perception-rewarding methods, while avoiding extra models, making training more efficient and scalable.

</details>


### [28] [MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation](https://arxiv.org/abs/2601.00504)
*Miaowei Wang,Jakub Zadrożny,Oisin Mac Aodha,Amir Vaxman*

Main category: cs.CV

TL;DR: MotionPhysics是一个端到端可微分框架，通过自然语言提示为3D场景推断合理的物理参数，无需真实轨迹或标注视频指导，利用多模态大语言模型估计材料参数，并通过可学习的运动蒸馏损失从预训练视频扩散模型中提取运动先验。


<details>
  <summary>Details</summary>
Motivation: 现有3D对象和材料的准确模拟通常需要专家知识和耗时的物理参数调整才能获得期望的动态行为。传统方法依赖真实轨迹或标注视频指导，限制了应用范围。

Method: 1. 使用多模态大语言模型估计材料参数值，并约束在合理范围内；2. 提出可学习的运动蒸馏损失，从预训练视频扩散模型中提取鲁棒的运动先验，同时最小化外观和几何归纳偏差来指导模拟。

Result: 在超过30个场景中评估，包括真实世界、人工设计和AI生成的3D对象，涵盖弹性固体、金属、泡沫、沙子、牛顿和非牛顿流体等多种材料。MotionPhysics能够生成由自然语言引导的视觉真实动态模拟，超越现有技术水平，同时自动确定物理合理的参数。

Conclusion: MotionPhysics通过自然语言提示为3D场景推断物理参数，无需真实轨迹或标注视频，利用多模态LLM和运动蒸馏损失，实现了视觉真实的动态模拟，在多种材料和场景中表现优异。

Abstract: Accurately simulating existing 3D objects and a wide variety of materials often demands expert knowledge and time-consuming physical parameter tuning to achieve the desired dynamic behavior. We introduce MotionPhysics, an end-to-end differentiable framework that infers plausible physical parameters from a user-provided natural language prompt for a chosen 3D scene of interest, removing the need for guidance from ground-truth trajectories or annotated videos. Our approach first utilizes a multimodal large language model to estimate material parameter values, which are constrained to lie within plausible ranges. We further propose a learnable motion distillation loss that extracts robust motion priors from pretrained video diffusion models while minimizing appearance and geometry inductive biases to guide the simulation. We evaluate MotionPhysics across more than thirty scenarios, including real-world, human-designed, and AI-generated 3D objects, spanning a wide range of materials such as elastic solids, metals, foams, sand, and both Newtonian and non-Newtonian fluids. We demonstrate that MotionPhysics produces visually realistic dynamic simulations guided by natural language, surpassing the state of the art while automatically determining physically plausible parameters. The code and project page are available at: https://wangmiaowei.github.io/MotionPhysics.github.io/.

</details>


### [29] [FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection](https://arxiv.org/abs/2601.00535)
*Ruiqiang Zhang,Hengyi Wang,Chang Liu,Guanjie Wang,Zehua Ma,Weiming Zhang*

Main category: cs.CV

TL;DR: FreeText是一个无需训练、即插即用的框架，通过利用扩散Transformer模型的内在机制，解决文本到图像生成中的文本渲染问题，特别是在多行布局、密集排版和中文等长尾脚本方面。


<details>
  <summary>Details</summary>
Motivation: 大规模文本到图像扩散模型在开放域合成方面表现出色，但在精确文本渲染方面仍存在困难，特别是对于多行布局、密集排版和中文等长尾脚本。现有解决方案通常需要昂贵的重新训练或严格的外部布局约束，这会降低美学质量并限制灵活性。

Method: FreeText将问题分解为"在哪里写"和"写什么"两个部分。对于"在哪里写"，通过读取内生图像到文本注意力中的token-wise空间归因来定位书写区域，使用sink-like tokens作为稳定的空间锚点，并通过拓扑感知细化产生高置信度掩码。对于"写什么"，引入频谱调制字形注入(SGMI)，注入噪声对齐的字形先验，通过频域带通调制来增强字形结构并抑制语义泄漏。

Result: 在Qwen-Image、FLUX.1-dev和SD3变体上进行的广泛实验表明，在长文本基准测试、CVTG和作者提出的CLT-Bench上，文本可读性获得了一致的提升，同时很大程度上保持了语义对齐和美学质量，推理开销适中。

Conclusion: FreeText是一个无需训练、即插即用的框架，通过利用扩散Transformer模型的内在机制，有效解决了文本到图像生成中的文本渲染问题，特别是在多行布局、密集排版和中文等长尾脚本方面，在保持语义对齐和美学质量的同时显著提升了文本可读性。

Abstract: Large-scale text-to-image (T2I) diffusion models excel at open-domain synthesis but still struggle with precise text rendering, especially for multi-line layouts, dense typography, and long-tailed scripts such as Chinese. Prior solutions typically require costly retraining or rigid external layout constraints, which can degrade aesthetics and limit flexibility. We propose \textbf{FreeText}, a training-free, plug-and-play framework that improves text rendering by exploiting intrinsic mechanisms of \emph{Diffusion Transformer (DiT)} models. \textbf{FreeText} decomposes the problem into \emph{where to write} and \emph{what to write}. For \emph{where to write}, we localize writing regions by reading token-wise spatial attribution from endogenous image-to-text attention, using sink-like tokens as stable spatial anchors and topology-aware refinement to produce high-confidence masks. For \emph{what to write}, we introduce Spectral-Modulated Glyph Injection (SGMI), which injects a noise-aligned glyph prior with frequency-domain band-pass modulation to strengthen glyph structure and suppress semantic leakage (rendering the concept instead of the word). Extensive experiments on Qwen-Image, FLUX.1-dev, and SD3 variants across longText-Benchmark, CVTG, and our CLT-Bench show consistent gains in text readability while largely preserving semantic alignment and aesthetic quality, with modest inference overhead.

</details>


### [30] [Boosting Segment Anything Model to Generalize Visually Non-Salient Scenarios](https://arxiv.org/abs/2601.00537)
*Guangqian Guo,Pengfei Chen,Yong Guo,Huafeng Chen,Boqiang Zhang,Shan Gao*

Main category: cs.CV

TL;DR: VNS-SAM通过Mask-Edge Token Interactive解码器和Non-Salient Feature Mining模块增强SAM在视觉非显著场景下的分割能力，同时保持零样本泛化性，并在新构建的VNS-SEG数据集上验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: SAM在视觉非显著场景（前景与背景对比度低）中表现不佳，现有方法难以捕捉准确轮廓。需要增强SAM对这类场景的感知能力，同时保持其原有的零样本泛化优势。

Method: 提出VNS-SAM，通过两个核心设计：1) Mask-Edge Token Interactive解码器，利用SAM的低层特征；2) Non-Salient Feature Mining模块，帮助SAM解码器深入理解非显著特征。仅需少量参数增加和计算开销，额外参数可在4小时内优化完成。

Result: 构建了VNS-SEG统一数据集（包含超过35K图像），用于全面评估模型在VNS场景下的分割性能和泛化能力。在各种VNS分割任务上的广泛实验表明，VNS-SAM在零样本设置下表现优异，特别是在视觉非显著场景中。

Conclusion: VNS-SAM有效提升了SAM在视觉非显著场景下的分割性能，同时保持了零样本泛化能力，具有广泛的现实应用潜力。代码和数据集已公开。

Abstract: Segment Anything Model (SAM), known for its remarkable zero-shot segmentation capabilities, has garnered significant attention in the community. Nevertheless, its performance is challenged when dealing with what we refer to as visually non-salient scenarios, where there is low contrast between the foreground and background. In these cases, existing methods often cannot capture accurate contours and fail to produce promising segmentation results. In this paper, we propose Visually Non-Salient SAM (VNS-SAM), aiming to enhance SAM's perception of visually non-salient scenarios while preserving its original zero-shot generalizability. We achieve this by effectively exploiting SAM's low-level features through two designs: Mask-Edge Token Interactive decoder and Non-Salient Feature Mining module. These designs help the SAM decoder gain a deeper understanding of non-salient characteristics with only marginal parameter increments and computational requirements. The additional parameters of VNS-SAM can be optimized within 4 hours, demonstrating its feasibility and practicality. In terms of data, we established VNS-SEG, a unified dataset for various VNS scenarios, with more than 35K images, in contrast to previous single-task adaptations. It is designed to make the model learn more robust VNS features and comprehensively benchmark the model's segmentation performance and generalizability on VNS scenarios. Extensive experiments across various VNS segmentation tasks demonstrate the superior performance of VNS-SAM, particularly under zero-shot settings, highlighting its potential for broad real-world applications. Codes and datasets are publicly available at https://guangqian-guo.github.io/VNS-SAM.

</details>


### [31] [DynaDrag: Dynamic Drag-Style Image Editing by Motion Prediction](https://arxiv.org/abs/2601.00542)
*Jiacheng Sui,Yujie Zhou,Li Niu*

Main category: cs.CV

TL;DR: 提出DynaDrag方法，采用预测-移动框架进行拖拽式图像编辑，通过迭代的运动预测和运动监督实现像素级图像操控


<details>
  <summary>Details</summary>
Motivation: 现有拖拽式图像编辑方法存在跟踪丢失、跟踪模糊、源图像与目标图像差距过大、中间点不合理导致编辑性低等问题，需要新的框架来解决这些挑战

Method: 提出DynaDrag方法，采用预测-移动框架，迭代执行运动预测和运动监督：运动预测预测手柄点应移动的位置，运动监督据此拖拽手柄点，并动态调整有效手柄点以提升性能

Result: 在人脸和人体数据集上的实验展示了该方法相对于先前工作的优越性

Conclusion: DynaDrag作为首个基于预测-移动框架的拖拽方法，有效避免了传统方法的跟踪问题和编辑性问题，在像素级图像操控方面表现出色

Abstract: To achieve pixel-level image manipulation, drag-style image editing which edits images using points or trajectories as conditions is attracting widespread attention. Most previous methods follow move-and-track framework, in which miss tracking and ambiguous tracking are unavoidable challenging issues. Other methods under different frameworks suffer from various problems like the huge gap between source image and target edited image as well as unreasonable intermediate point which can lead to low editability. To avoid these problems, we propose DynaDrag, the first dragging method under predict-and-move framework. In DynaDrag, Motion Prediction and Motion Supervision are performed iteratively. In each iteration, Motion Prediction first predicts where the handle points should move, and then Motion Supervision drags them accordingly. We also propose to dynamically adjust the valid handle points to further improve the performance. Experiments on face and human datasets showcase the superiority over previous works.

</details>


### [32] [SingBAG Pro: Accelerating point cloud-based iterative reconstruction for 3D photoacoustic imaging under arbitrary array](https://arxiv.org/abs/2601.00551)
*Shuang Li,Yibing Wang,Jian Gao,Chulhong Kim,Seongwook Choi,Yu Zhang,Qian Chen,Yao Yao,Changhui Li*

Main category: cs.CV

TL;DR: SlingBAG Pro是一种基于点云迭代概念的光声成像重建算法，扩展了原始SlingBAG方法对任意阵列几何形状的兼容性，通过分层优化策略显著提高了不规则阵列配置下的重建速度。


<details>
  <summary>Details</summary>
Motivation: 解决不规则几何换能器阵列在三维光声成像中的重建挑战。传统迭代重建算法在处理不规则阵列配置时面临计算复杂度高、内存需求大和重建时间长的问题，而SlingBAG Pro旨在保持高质量重建的同时减少所需换能器数量并显著缩短重建时间。

Method: 基于滑动球自适应增长(SlingBAG)方法的点云迭代概念，扩展其兼容性以支持任意阵列几何形状。采用分层优化策略，结合零梯度滤波和迭代过程中逐步增加的时间采样率，快速去除冗余空间点云并加速收敛。

Result: 与原始SlingBAG算法相比，SlingBAG Pro在不规则阵列几何形状下的基于点云的三维光声重建中实现了高达2.2倍的速度提升。该方法通过仿真和活体小鼠实验验证，源代码已公开。

Conclusion: SlingBAG Pro算法有效解决了不规则几何换能器阵列在三维光声成像中的重建难题，在保持高质量重建的同时显著减少了重建时间，为临床应用中高质量三维光声成像提供了实用解决方案。

Abstract: High-quality three-dimensional (3D) photoacoustic imaging (PAI) is gaining increasing attention in clinical applications. To address the challenges of limited space and high costs, irregular geometric transducer arrays that conform to specific imaging regions are promising for achieving high-quality 3D PAI with fewer transducers. However, traditional iterative reconstruction algorithms struggle with irregular array configurations, suffering from high computational complexity, substantial memory requirements, and lengthy reconstruction times. In this work, we introduce SlingBAG Pro, an advanced reconstruction algorithm based on the point cloud iteration concept of the Sliding ball adaptive growth (SlingBAG) method, while extending its compatibility to arbitrary array geometries. SlingBAG Pro maintains high reconstruction quality, reduces the number of required transducers, and employs a hierarchical optimization strategy that combines zero-gradient filtering with progressively increased temporal sampling rates during iteration. This strategy rapidly removes redundant spatial point clouds, accelerates convergence, and significantly shortens overall reconstruction time. Compared to the original SlingBAG algorithm, SlingBAG Pro achieves up to a 2.2-fold speed improvement in point cloud-based 3D PA reconstruction under irregular array geometries. The proposed method is validated through both simulation and in vivo mouse experiments, and the source code is publicly available at https://github.com/JaegerCQ/SlingBAG_Pro.

</details>


### [33] [A Comprehensive Dataset for Human vs. AI Generated Image Detection](https://arxiv.org/abs/2601.00553)
*Rajarshi Roy,Nasrin Imanpour,Ashhar Aziz,Shashwat Bajpai,Gurpreet Singh,Shwetangshu Biswas,Kapil Wanaskar,Parth Patwa,Subhankar Ghosh,Shreyas Dixit,Nilesh Ranjan Pal,Vipula Rawte,Ritvik Garimella,Gaytri Jena,Vasu Sharma,Vinija Jain,Aman Chadha,Aishwarya Naresh Reganti,Amitava Das*

Main category: cs.CV

TL;DR: 该论文发布了MS COCOAI数据集，包含96,000个真实和合成图像数据点，用于AI生成图像检测，支持两种任务：图像真伪分类和生成模型识别。


<details>
  <summary>Details</summary>
Motivation: 随着Stable Diffusion、DALL-E、MidJourney等多模态生成AI系统的普及，合成图像越来越难以与真实照片区分，导致误导性内容、虚假信息和操纵媒体的传播，因此迫切需要开发有效的检测方法。

Method: 基于MS COCO数据集构建MS COCOAI数据集，包含96,000个数据点，使用五种生成器（Stable Diffusion 3、Stable Diffusion 2.1、SDXL、DALL-E 3、MidJourney v6）生成合成图像，并设计了两种检测任务：图像真伪分类和生成模型识别。

Result: 创建了公开可用的MS COCOAI数据集，包含96,000个真实和合成图像，支持AI生成图像检测研究，数据集已在Hugging Face平台发布。

Conclusion: MS COCOAI数据集为解决AI生成图像检测问题提供了重要资源，有助于开发更有效的检测方法以应对合成图像带来的挑战。

Abstract: Multimodal generative AI systems like Stable Diffusion, DALL-E, and MidJourney have fundamentally changed how synthetic images are created. These tools drive innovation but also enable the spread of misleading content, false information, and manipulated media. As generated images become harder to distinguish from photographs, detecting them has become an urgent priority. To combat this challenge, We release MS COCOAI, a novel dataset for AI generated image detection consisting of 96000 real and synthetic datapoints, built using the MS COCO dataset. To generate synthetic images, we use five generators: Stable Diffusion 3, Stable Diffusion 2.1, SDXL, DALL-E 3, and MidJourney v6. Based on the dataset, we propose two tasks: (1) classifying images as real or generated, and (2) identifying which model produced a given synthetic image. The dataset is available at https://huggingface.co/datasets/Rajarshi-Roy-research/Defactify_Image_Dataset.

</details>


### [34] [AEGIS: Exploring the Limit of World Knowledge Capabilities for Unified Mulitmodal Models](https://arxiv.org/abs/2601.00561)
*Jintao Lin,Bowen Dong,Weikang Shi,Chenyang Lei,Suiyun Zhang,Rui Liu,Xihui Liu*

Main category: cs.CV

TL;DR: AEGIS：首个评估统一多模态模型世界知识应用能力的多任务基准，包含1050个挑战性问题，覆盖视觉理解、生成、编辑和交错生成，并提出确定性检查表评估协议以提高评测可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在局限性，仅提供孤立的单任务评估，诊断能力有限，无法全面评估统一多模态模型在不同任务中应用世界知识的能力，这是当前未解决的关键挑战。

Method: 提出AEGIS基准，包含1050个手动标注的挑战性问题，涵盖21个主题（STEM、人文、日常生活等）和6种推理类型；同时提出确定性检查表评估协议，用原子化的"是/否"判断替代模糊的提示式评分，提高评估可靠性。

Result: 实验表明大多数统一多模态模型存在严重的世界知识缺陷，性能随推理复杂度增加而显著下降；简单的插件式推理模块可以部分缓解这些缺陷，为未来研究指明方向。

Conclusion: 世界知识推理是统一多模态模型发展的关键前沿，AEGIS基准和DCE评估协议为系统评估模型能力提供了重要工具，揭示了当前模型的局限性并指出了改进方向。

Abstract: The capability of Unified Multimodal Models (UMMs) to apply world knowledge across diverse tasks remains a critical, unresolved challenge. Existing benchmarks fall short, offering only siloed, single-task evaluations with limited diagnostic power. To bridge this gap, we propose AEGIS (\emph{i.e.}, \textbf{A}ssessing \textbf{E}diting, \textbf{G}eneration, \textbf{I}nterpretation-Understanding for \textbf{S}uper-intelligence), a comprehensive multi-task benchmark covering visual understanding, generation, editing, and interleaved generation. AEGIS comprises 1,050 challenging, manually-annotated questions spanning 21 topics (including STEM, humanities, daily life, etc.) and 6 reasoning types. To concretely evaluate the performance of UMMs in world knowledge scope without ambiguous metrics, we further propose Deterministic Checklist-based Evaluation (DCE), a protocol that replaces ambiguous prompt-based scoring with atomic ``Y/N'' judgments, to enhance evaluation reliability. Our extensive experiments reveal that most UMMs exhibit severe world knowledge deficits and that performance degrades significantly with complex reasoning. Additionally, simple plug-in reasoning modules can partially mitigate these vulnerabilities, highlighting a promising direction for future research. These results highlight the importance of world-knowledge-based reasoning as a critical frontier for UMMs.

</details>


### [35] [GranAlign: Granularity-Aware Alignment Framework for Zero-Shot Video Moment Retrieval](https://arxiv.org/abs/2601.00584)
*Mingyu Jeon,Sunjae Yoon,Jonghee Kim,Junyeoung Kim*

Main category: cs.CV

TL;DR: 提出GranAlign框架，通过粒度感知对齐解决零样本视频时刻检索中的语义粒度不匹配问题，无需训练即可实现最先进性能


<details>
  <summary>Details</summary>
Motivation: 零样本视频时刻检索中，文本查询与视觉内容之间存在语义粒度不匹配问题。现有方法虽然利用预训练知识将视频和语言映射到联合空间，但未能平衡不同模态提供的预训练知识的语义粒度，导致检索不准确。

Method: 提出Granularity-Aware Alignment (GranAlign)训练免费框架，包含两种互补技术：1) 基于粒度的查询重写，生成不同语义粒度的查询；2) 查询感知的标题生成，将查询意图嵌入视频内容。通过将多级查询与查询无关和查询感知的标题配对，有效解决语义不匹配问题。

Result: 在三个主要基准测试(QVHighlights、Charades-STA、ActivityNet-Captions)上均达到新的最先进水平，在具有挑战性的QVHighlights数据集上实现了3.23% mAP@avg的显著提升。

Conclusion: GranAlign框架通过粒度感知对齐有效解决了零样本视频时刻检索中的语义粒度不匹配问题，无需训练即可实现卓越性能，为跨模态对齐提供了新思路。

Abstract: Zero-shot video moment retrieval (ZVMR) is the task of localizing a temporal moment within an untrimmed video using a natural language query without relying on task-specific training data. The primary challenge in this setting lies in the mismatch in semantic granularity between textual queries and visual content. Previous studies in ZVMR have attempted to achieve alignment by leveraging high-quality pre-trained knowledge that represents video and language in a joint space. However, these approaches failed to balance the semantic granularity between the pre-trained knowledge provided by each modality for a given scene. As a result, despite the high quality of each modality's representations, the mismatch in granularity led to inaccurate retrieval. In this paper, we propose a training-free framework, called Granularity-Aware Alignment (GranAlign), that bridges this gap between coarse and fine semantic representations. Our approach introduces two complementary techniques: granularity-based query rewriting to generate varied semantic granularities, and query-aware caption generation to embed query intent into video content. By pairing multi-level queries with both query-agnostic and query-aware captions, we effectively resolve semantic mismatches. As a result, our method sets a new state-of-the-art across all three major benchmarks (QVHighlights, Charades-STA, ActivityNet-Captions), with a notable 3.23% mAP@avg improvement on the challenging QVHighlights dataset.

</details>


### [36] [SafeMo: Linguistically Grounded Unlearning for Trustworthy Text-to-Motion Generation](https://arxiv.org/abs/2601.00590)
*Yiling Wang,Zeyu Zhang,Yiran Wang,Hao Tang*

Main category: cs.CV

TL;DR: SafeMo：首个连续空间中的可信人体运动生成框架，通过最小化运动遗忘策略解决现有基于离散码本替换方法的安全问题，同时保持良性性能


<details>
  <summary>Details</summary>
Motivation: 现有基于离散VQ-VAE码本替换的文本到运动生成安全方法存在两个关键缺陷：1) 替换被良性提示重复使用的码本条目会导致日常任务漂移，降低模型良性性能；2) 离散标记方法引入量化和平滑度损失，导致伪影和抖动过渡。此外，现有文本到运动数据集天然包含不安全意图和对应动作，不适合安全驱动的机器学习。

Method: 提出SafeMo框架，集成最小化运动遗忘策略：一种两阶段机器学习遗忘策略，在连续空间中实现安全人体运动生成，保持连续运动学特性而无需码本损失。基于DiP架构，高效生成具有自然过渡的安全人体运动。同时创建首个安全文本到运动数据集SafeMoVAE-29K，包含重写的安全文本提示和连续精炼动作。

Result: 实验显示SafeMo在HumanML3D和Motion-X数据集上分别达到2.5倍和14.4倍更高的遗忘集FID，相比先前SOTA方法LCR表现出更强的遗忘效果。在安全提示上的良性性能优于或与基线相当，实现了更好的安全-效用权衡。

Conclusion: SafeMo通过连续空间中的最小化运动遗忘策略有效解决了文本到运动生成的安全问题，避免了离散码本替换方法的缺陷，在保持运动自然性和良性性能的同时实现了更强的安全保护。

Abstract: Text-to-motion (T2M) generation with diffusion backbones achieves strong realism and alignment. Safety concerns in T2M methods have been raised in recent years; existing methods replace discrete VQ-VAE codebook entries to steer the model away from unsafe behaviors. However, discrete codebook replacement-based methods have two critical flaws: firstly, replacing codebook entries which are reused by benign prompts leads to drifts on everyday tasks, degrading the model's benign performance; secondly, discrete token-based methods introduce quantization and smoothness loss, resulting in artifacts and jerky transitions. Moreover, existing text-to-motion datasets naturally contain unsafe intents and corresponding motions, making them unsuitable for safety-driven machine learning. To address these challenges, we propose SafeMo, a trustworthy motion generative framework integrating Minimal Motion Unlearning (MMU), a two-stage machine unlearning strategy, enabling safe human motion generation in continuous space, preserving continuous kinematics without codebook loss and delivering strong safety-utility trade-offs compared to current baselines. Additionally, we present the first safe text-to-motion dataset SafeMoVAE-29K integrating rewritten safe text prompts and continuous refined motion for trustworthy human motion unlearning. Built upon DiP, SafeMo efficiently generates safe human motions with natural transitions. Experiments demonstrate effective unlearning performance of SafeMo by showing strengthened forgetting on unsafe prompts, reaching 2.5x and 14.4x higher forget-set FID on HumanML3D and Motion-X respectively, compared to the previous SOTA human motion unlearning method LCR, with benign performance on safe prompts being better or comparable. Code: https://github.com/AIGeeksGroup/SafeMo. Website: https://aigeeksgroup.github.io/SafeMo.

</details>


### [37] [Modality Dominance-Aware Optimization for Embodied RGB-Infrared Perception](https://arxiv.org/abs/2601.00598)
*Xianhui Liu,Siqi Jiang,Yi Xie,Yuqing Lin,Siao Liu*

Main category: cs.CV

TL;DR: 提出MDACL框架解决RGB-IR多模态检测中的优化偏差问题，通过MDI量化模态主导性，使用HCG增强特征对齐和AER平衡优化动态


<details>
  <summary>Details</summary>
Motivation: RGB-IR多模态感知在复杂物理环境中至关重要，但现有方法未充分探索由不对称模态特性引起的优化动态。信息密度和特征质量的差异导致持续优化偏差，使训练过度强调主导模态，阻碍有效融合。

Method: 1) 提出模态主导指数(MDI)，通过联合建模特征熵和梯度贡献来量化模态主导性；2) 基于MDI开发模态主导感知跨模态学习(MDACL)框架，包含分层跨模态指导(HCG)增强特征对齐，以及对抗均衡正则化(AER)平衡融合过程中的优化动态。

Result: 在三个RGB-IR基准测试上进行广泛实验，证明MDACL能有效缓解优化偏差，并实现最先进的性能。

Conclusion: MDACL框架通过量化模态主导性和调节跨模态优化，解决了RGB-IR多模态检测中的优化偏差问题，为多模态感知系统提供了有效的解决方案。

Abstract: RGB-Infrared (RGB-IR) multimodal perception is fundamental to embodied multimedia systems operating in complex physical environments. Although recent cross-modal fusion methods have advanced RGB-IR detection, the optimization dynamics caused by asymmetric modality characteristics remain underexplored. In practice, disparities in information density and feature quality introduce persistent optimization bias, leading training to overemphasize a dominant modality and hindering effective fusion. To quantify this phenomenon, we propose the Modality Dominance Index (MDI), which measures modality dominance by jointly modeling feature entropy and gradient contribution. Based on MDI, we develop a Modality Dominance-Aware Cross-modal Learning (MDACL) framework that regulates cross-modal optimization. MDACL incorporates Hierarchical Cross-modal Guidance (HCG) to enhance feature alignment and Adversarial Equilibrium Regularization (AER) to balance optimization dynamics during fusion. Extensive experiments on three RGB-IR benchmarks demonstrate that MDACL effectively mitigates optimization bias and achieves SOTA performance.

</details>


### [38] [Noise-Robust Tiny Object Localization with Flows](https://arxiv.org/abs/2601.00617)
*Huixin Sun,Linlin Yang,Ronyu Chen,Kerui Gu,Baochang Zhang,Angela Yao,Xianbin Cao*

Main category: cs.CV

TL;DR: TOLF是一个针对微小目标检测的噪声鲁棒定位框架，通过归一化流进行灵活误差建模和不确定性引导优化，解决微小目标对标注噪声敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管通用目标检测取得了显著进展，但微小目标与正常尺度目标之间仍存在性能差距。研究发现微小目标对标注噪声高度敏感，优化严格定位目标存在噪声过拟合风险。

Method: 提出Tiny Object Localization with Flows (TOLF)：1）使用归一化流进行误差建模，捕捉复杂的非高斯预测分布；2）不确定性感知梯度调制机制，抑制从高不确定性、易噪声样本中学习，减轻过拟合并稳定训练。

Result: 在三个数据集上的广泛实验验证了方法的有效性。特别是在AI-TOD数据集上，TOLF将DINO基线提升了1.2% AP。

Conclusion: TOLF通过流基误差建模和不确定性引导优化，有效解决了微小目标检测中的噪声敏感问题，显著提升了微小目标定位性能。

Abstract: Despite significant advances in generic object detection, a persistent performance gap remains for tiny objects compared to normal-scale objects. We demonstrate that tiny objects are highly sensitive to annotation noise, where optimizing strict localization objectives risks noise overfitting. To address this, we propose Tiny Object Localization with Flows (TOLF), a noise-robust localization framework leveraging normalizing flows for flexible error modeling and uncertainty-guided optimization. Our method captures complex, non-Gaussian prediction distributions through flow-based error modeling, enabling robust learning under noisy supervision. An uncertainty-aware gradient modulation mechanism further suppresses learning from high-uncertainty, noise-prone samples, mitigating overfitting while stabilizing training. Extensive experiments across three datasets validate our approach's effectiveness. Especially, TOLF boosts the DINO baseline by 1.2% AP on the AI-TOD dataset.

</details>


### [39] [RePose: A Real-Time 3D Human Pose Estimation and Biomechanical Analysis Framework for Rehabilitation](https://arxiv.org/abs/2601.00625)
*Junxiao Xue,Pavel Smirnov,Ziao Li,Yunyun Shi,Shi Chen,Xinyi Yin,Xiaohan Yue,Lei Wang,Yiduo Wang,Feng Lin,Yijia Chen,Xiao Ma,Xiaoran Yan,Qing Zhang,Fengjian Xue,Xuecheng Wu*

Main category: cs.CV

TL;DR: RePose：一种用于康复训练实时3D人体姿态估计与运动分析方法，通过多摄像头RGB视频输入实现端到端实时监测与评估，提供即时反馈指导患者正确执行康复动作。


<details>
  <summary>Details</summary>
Motivation: 康复训练中需要实时监测和评估患者运动状态，提供即时反馈指导患者正确执行动作，帮助恢复肌肉力量和运动功能。现有方法在实时性、多人干扰处理和姿态平滑性方面存在不足。

Method: 1) 提出统一端到端实时人体姿态估计与运动分析流水线；2) 针对医疗康复场景设计快速跟踪方法（单帧跟踪<1ms）；3) 改进SmoothNet用于实时姿态估计，减少误差并恢复真实运动状态；4) 使用Unity平台实现实时监测评估和肌肉应力可视化。

Result: 方法能够实时监测和评估康复运动，提供即时反馈；快速跟踪方法在多人干扰场景下表现良好；改进的SmoothNet有效减少姿态估计误差，使运动状态更平滑；Unity平台成功实现肌肉应力可视化辅助康复训练。

Conclusion: RePose为康复训练提供了有效的实时3D姿态估计与运动分析解决方案，通过快速跟踪、姿态平滑优化和可视化反馈，能够有效辅助患者正确执行康复动作，促进功能恢复。

Abstract: We propose a real-time 3D human pose estimation and motion analysis method termed RePose for rehabilitation training. It is capable of real-time monitoring and evaluation of patients'motion during rehabilitation, providing immediate feedback and guidance to assist patients in executing rehabilitation exercises correctly. Firstly, we introduce a unified pipeline for end-to-end real-time human pose estimation and motion analysis using RGB video input from multiple cameras which can be applied to the field of rehabilitation training. The pipeline can help to monitor and correct patients'actions, thus aiding them in regaining muscle strength and motor functions. Secondly, we propose a fast tracking method for medical rehabilitation scenarios with multiple-person interference, which requires less than 1ms for tracking for a single frame. Additionally, we modify SmoothNet for real-time posture estimation, effectively reducing pose estimation errors and restoring the patient's true motion state, making it visually smoother. Finally, we use Unity platform for real-time monitoring and evaluation of patients' motion during rehabilitation, and to display the muscle stress conditions to assist patients with their rehabilitation training.

</details>


### [40] [HyperPriv-EPN: Hypergraph Learning with Privileged Knowledge for Ependymoma Prognosis](https://arxiv.org/abs/2601.00626)
*Shuren Gabriel Yu,Sikang Ren,Yongji Tian*

Main category: cs.CV

TL;DR: 提出HyperPriv-EPN框架，利用超图学习和特权信息学习，在术前MRI中模拟术后文本语义信息，实现无文本推理的胶质瘤预后预测


<details>
  <summary>Details</summary>
Motivation: 胶质瘤术前预后对治疗规划至关重要，但MRI缺乏术后手术报告中的语义信息。现有多模态方法在推理时无法利用特权文本数据，需要解决这一局限性。

Method: 提出基于超图的特权信息学习框架，采用"割裂图策略"，使用共享编码器处理教师图（含术后特权信息）和学生图（仅术前数据），通过双流蒸馏让学生图从视觉特征中"幻觉"语义社区结构。

Result: 在311名患者的多中心队列验证中，HyperPriv-EPN实现了最先进的诊断准确率和生存分层效果，成功将专家知识转移到术前场景。

Conclusion: 该框架有效利用历史术后数据指导新患者诊断，无需推理时文本输入，解锁了特权信息的价值，为术前预后提供了新解决方案。

Abstract: Preoperative prognosis of Ependymoma is critical for treatment planning but challenging due to the lack of semantic insights in MRI compared to post-operative surgical reports. Existing multimodal methods fail to leverage this privileged text data when it is unavailable during inference. To bridge this gap, we propose HyperPriv-EPN, a hypergraph-based Learning Using Privileged Information (LUPI) framework. We introduce a Severed Graph Strategy, utilizing a shared encoder to process both a Teacher graph (enriched with privileged post-surgery information) and a Student graph (restricted to pre-operation data). Through dual-stream distillation, the Student learns to hallucinate semantic community structures from visual features alone. Validated on a multi-center cohort of 311 patients, HyperPriv-EPN achieves state-of-the-art diagnostic accuracy and survival stratification. This effectively transfers expert knowledge to the preoperative setting, unlocking the value of historical post-operative data to guide the diagnosis of new patients without requiring text at inference.

</details>


### [41] [Quality Detection of Stored Potatoes via Transfer Learning: A CNN and Vision Transformer Approach](https://arxiv.org/abs/2601.00645)
*Shrikant Kapse,Priyankkumar Dhrangdhariya,Priya Kedia,Manasi Patwardhan,Shankar Kausley,Soumyadipta Maiti,Beena Rai,Shirish Karande*

Main category: cs.CV

TL;DR: 基于图像的深度学习为马铃薯储存期间的质量监测提供非侵入式解决方案，通过预训练模型实现发芽检测、重量损失估计和保质期预测，DenseNet在发芽检测中达到98.03%准确率。


<details>
  <summary>Details</summary>
Motivation: 解决马铃薯储存期间的质量监测挑战，包括发芽检测、重量损失估计和保质期预测，为自动化分拣和库存系统提供非侵入式、可扩展的解决方案。

Method: 在200天控制温湿度条件下收集图像和重量数据，利用ResNet、VGG、DenseNet和Vision Transformer预训练架构，设计两个专门模型：高精度二分类发芽检测器和多类预测器用于重量损失估计和保质期预测。

Result: DenseNet在发芽检测中达到98.03%准确率；保质期预测在粗分类（2-5类）时准确率超过89.83%，细分类（6-8类）准确率下降；证明了图像模型集成到自动化系统的可行性。

Conclusion: 基于图像的深度学习为马铃薯质量评估提供经济高效的非破坏性方法，支持储存和分销的效率和可持续性；未来需开发适应不同品种和储存条件的通用模型以增强可扩展性。

Abstract: Image-based deep learning provides a non-invasive, scalable solution for monitoring potato quality during storage, addressing key challenges such as sprout detection, weight loss estimation, and shelf-life prediction. In this study, images and corresponding weight data were collected over a 200-day period under controlled temperature and humidity conditions. Leveraging powerful pre-trained architectures of ResNet, VGG, DenseNet, and Vision Transformer (ViT), we designed two specialized models: (1) a high-precision binary classifier for sprout detection, and (2) an advanced multi-class predictor to estimate weight loss and forecast remaining shelf-life with remarkable accuracy. DenseNet achieved exceptional performance, with 98.03% accuracy in sprout detection. Shelf-life prediction models performed best with coarse class divisions (2-5 classes), achieving over 89.83% accuracy, while accuracy declined for finer divisions (6-8 classes) due to subtle visual differences and limited data per class. These findings demonstrate the feasibility of integrating image-based models into automated sorting and inventory systems, enabling early identification of sprouted potatoes and dynamic categorization based on storage stage. Practical implications include improved inventory management, differential pricing strategies, and reduced food waste across supply chains. While predicting exact shelf-life intervals remains challenging, focusing on broader class divisions ensures robust performance. Future research should aim to develop generalized models trained on diverse potato varieties and storage conditions to enhance adaptability and scalability. Overall, this approach offers a cost-effective, non-destructive method for quality assessment, supporting efficiency and sustainability in potato storage and distribution.

</details>


### [42] [CRoPS: A Training-Free Hallucination Mitigation Framework for Vision-Language Models](https://arxiv.org/abs/2601.00659)
*Neeraj Anand,Samyak Jha,Udbhav Bamba,Rahul Rahaman*

Main category: cs.CV

TL;DR: 提出CRoPS框架，通过选择性移除关键文本token构建幻觉模型，结合广义对比解码来缓解大型视觉语言模型的幻觉问题，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型存在幻觉生成问题，影响实际应用可靠性。现有免训练方法存在两个局限：1) 对幻觉来源的假设过于狭窄；2) 在生成后期（幻觉最可能发生时）效果下降。需要更全面的幻觉缓解方法。

Method: 提出CRoPS框架：1) 构建幻觉模型：通过选择性移除关键文本token来捕捉幻觉效应（而非仅移除视觉token）；2) 广义对比解码：整合多个幻觉模型以表示多样化的幻觉来源，形成更全面的幻觉缓解机制。

Result: 在六个基准测试和三个LVLM家族上取得一致提升，CHAIR分数提高20%，优于现有免训练方法。证明该方法能有效缓解幻觉问题，特别是在生成后期。

Conclusion: CRoPS框架通过创新的幻觉模型构建和广义对比解码，有效解决了LVLM幻觉问题，无需额外训练即可显著提升模型可靠性，为实际应用提供了实用解决方案。

Abstract: Despite the rapid success of Large Vision-Language Models (LVLMs), a persistent challenge is their tendency to generate hallucinated content, undermining reliability in real-world use. Existing training-free methods address hallucinations but face two limitations: (i) they rely on narrow assumptions about hallucination sources, and (ii) their effectiveness declines toward the end of generation, where hallucinations are most likely to occur. A common strategy is to build hallucinated models by completely or partially removing visual tokens and contrasting them with the original model. Yet, this alone proves insufficient, since visual information still propagates into generated text. Building on this insight, we propose a novel hallucinated model that captures hallucination effects by selectively removing key text tokens. We further introduce Generalized Contrastive Decoding, which integrates multiple hallucinated models to represent diverse hallucination sources. Together, these ideas form CRoPS, a training-free hallucination mitigation framework that improves CHAIR scores by 20% and achieves consistent gains across six benchmarks and three LVLM families, outperforming state-of-the-art training-free methods.

</details>


### [43] [Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians](https://arxiv.org/abs/2601.00678)
*Melonie de Almeida,Daniela Ivanova,Tong Shi,John H. Williamson,Paul Henderson*

Main category: cs.CV

TL;DR: 提出Pixel-to-4D框架，通过单次前向传播构建3D高斯场景表示并采样物体运动，实现快速、相机引导的单图像到视频生成，解决了现有方法在相机运动建模、时间一致性和几何完整性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有单图像条件视频生成方法虽然改进了时间一致性和3D一致性，但缺乏鲁棒的用户可控性（如修改相机路径）。大多数相机控制的图像到视频模型在准确建模相机运动、保持时间一致性和保留几何完整性方面存在困难。基于显式中间3D表示的方法虽然能实现与给定相机轨迹对齐的连贯视频生成，但通常采用两步流程（先渲染场景再引入物体运动），仍无法实现完全的时间一致性。

Method: 提出Pixel-to-4D框架：1）从单张图像构建3D高斯场景表示；2）在单次前向传播中采样合理的物体运动；3）实现快速、相机引导的视频生成，无需通过迭代去噪将物体运动注入渲染帧。该方法避免了传统两步流程的局限性。

Result: 在KITTI、Waymo、RealEstate10K和DL3DV-10K数据集上的大量实验表明，该方法在视频质量和推理效率方面达到了最先进水平。实现了高质量的相机引导视频生成，同时保持了时间一致性和几何完整性。

Conclusion: Pixel-to-4D框架通过单次前向传播同时构建3D场景表示和采样物体运动，解决了现有方法在相机控制、时间一致性和效率方面的局限性，为智能系统提供了更实用的单图像条件视频生成解决方案。

Abstract: Humans excel at forecasting the future dynamics of a scene given just a single image. Video generation models that can mimic this ability are an essential component for intelligent systems. Recent approaches have improved temporal coherence and 3D consistency in single-image-conditioned video generation. However, these methods often lack robust user controllability, such as modifying the camera path, limiting their applicability in real-world applications. Most existing camera-controlled image-to-video models struggle with accurately modeling camera motion, maintaining temporal consistency, and preserving geometric integrity. Leveraging explicit intermediate 3D representations offers a promising solution by enabling coherent video generation aligned with a given camera trajectory. Although these methods often use 3D point clouds to render scenes and introduce object motion in a later stage, this two-step process still falls short in achieving full temporal consistency, despite allowing precise control over camera movement. We propose a novel framework that constructs a 3D Gaussian scene representation and samples plausible object motion, given a single image in a single forward pass. This enables fast, camera-guided video generation without the need for iterative denoising to inject object motion into render frames. Extensive experiments on the KITTI, Waymo, RealEstate10K and DL3DV-10K datasets demonstrate that our method achieves state-of-the-art video quality and inference efficiency. The project page is available at https://melonienimasha.github.io/Pixel-to-4D-Website.

</details>


### [44] [RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization](https://arxiv.org/abs/2601.00705)
*Wei-Tse Cheng,Yen-Jen Chiou,Yuan-Fu Yang*

Main category: cs.CV

TL;DR: RGS-SLAM是一种基于高斯分布的SLAM框架，通过训练无关的对应关系-高斯初始化替代了传统的残差驱动稠密化阶段，使用DINOv3描述符和置信度感知内点分类器进行一次性三角测量生成高斯种子，实现了更快的收敛速度和更高的渲染质量。


<details>
  <summary>Details</summary>
Motivation: 传统GS-SLAM采用残差驱动的渐进式高斯添加策略，可能导致早期映射不稳定、收敛速度慢，特别是在纹理丰富和杂乱场景中表现不佳。需要一种更稳定、更高效的初始化方法来改善高斯分布的初始配置。

Method: 1. 使用DINOv3描述符提取密集多视角对应关系；2. 通过置信度感知内点分类器精炼对应关系；3. 执行一次性三角测量生成结构感知的高斯种子分布；4. 在优化前建立良好分布的高斯先验；5. 保持与现有GS-SLAM管道的完全兼容性。

Result: 在TUM RGB-D和Replica数据集上的评估显示：1. 收敛速度提升约20%；2. 在纹理丰富和杂乱场景中获得更高的渲染保真度；3. 定位和重建精度达到或超过最先进的高斯和基于点的SLAM系统；4. 保持实时映射性能，最高可达925 FPS。

Conclusion: RGS-SLAM通过训练无关的对应关系-高斯初始化方法，解决了传统残差驱动稠密化的局限性，实现了更稳定、更快速的SLAM性能，同时保持与现有系统的兼容性和实时性，为高斯分布SLAM提供了更优的初始化策略。

Abstract: We introduce RGS-SLAM, a robust Gaussian-splatting SLAM framework that replaces the residual-driven densification stage of GS-SLAM with a training-free correspondence-to-Gaussian initialization. Instead of progressively adding Gaussians as residuals reveal missing geometry, RGS-SLAM performs a one-shot triangulation of dense multi-view correspondences derived from DINOv3 descriptors refined through a confidence-aware inlier classifier, generating a well-distributed and structure-aware Gaussian seed prior to optimization. This initialization stabilizes early mapping and accelerates convergence by roughly 20\%, yielding higher rendering fidelity in texture-rich and cluttered scenes while remaining fully compatible with existing GS-SLAM pipelines. Evaluated on the TUM RGB-D and Replica datasets, RGS-SLAM achieves competitive or superior localization and reconstruction accuracy compared with state-of-the-art Gaussian and point-based SLAM systems, sustaining real-time mapping performance at up to 925 FPS.

</details>


### [45] [Detecting Performance Degradation under Data Shift in Pathology Vision-Language Model](https://arxiv.org/abs/2601.00716)
*Hao Guan,Li Zhou*

Main category: cs.CV

TL;DR: 该研究提出了一种结合输入数据偏移检测和输出置信度指标的框架，用于监测病理学视觉语言模型在数据偏移下的性能退化，开发了DomainSAT工具箱进行系统分析。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在医学图像分析中表现出强大潜力，但部署后当输入数据分布发生变化时，模型性能可能退化。检测这种性能退化对临床可靠性至关重要，但对于没有标注数据的大型预训练VLM来说仍然具有挑战性。

Method: 研究分析了最先进的病理学VLM在数据偏移下的性能退化检测。开发了DomainSAT工具箱，集成代表性偏移检测算法，提供图形界面进行数据偏移的系统分析。同时研究了基于输出的监测方法，引入了无标签、基于置信度的退化指标，直接捕捉模型预测置信度的变化。

Result: 分析表明，输入数据偏移检测能有效识别分布变化并提供早期诊断信号，但并不总是与实际性能退化相关。基于输出的置信度指标与性能退化密切相关，可作为输入偏移检测的有效补充。在大规模病理学肿瘤分类数据集上的实验证明，结合输入数据偏移检测和输出置信度指标能更可靠地检测和解释数据偏移下VLM的性能退化。

Conclusion: 研究结果为数字病理学中基础模型的可靠性监测提供了一个实用且互补的框架，结合输入数据偏移检测和输出置信度指标能更有效地监控VLM在数据偏移下的性能退化。

Abstract: Vision-Language Models have demonstrated strong potential in medical image analysis and disease diagnosis. However, after deployment, their performance may deteriorate when the input data distribution shifts from that observed during development. Detecting such performance degradation is essential for clinical reliability, yet remains challenging for large pre-trained VLMs operating without labeled data. In this study, we investigate performance degradation detection under data shift in a state-of-the-art pathology VLM. We examine both input-level data shift and output-level prediction behavior to understand their respective roles in monitoring model reliability. To facilitate systematic analysis of input data shift, we develop DomainSAT, a lightweight toolbox with a graphical interface that integrates representative shift detection algorithms and enables intuitive exploration of data shift. Our analysis shows that while input data shift detection is effective at identifying distributional changes and providing early diagnostic signals, it does not always correspond to actual performance degradation. Motivated by this observation, we further study output-based monitoring and introduce a label-free, confidence-based degradation indicator that directly captures changes in model prediction confidence. We find that this indicator exhibits a close relationship with performance degradation and serves as an effective complement to input shift detection. Experiments on a large-scale pathology dataset for tumor classification demonstrate that combining input data shift detection and output confidence-based indicators enables more reliable detection and interpretation of performance degradation in VLMs under data shift. These findings provide a practical and complementary framework for monitoring the reliability of foundation models in digital pathology.

</details>


### [46] [Grading Handwritten Engineering Exams with Multimodal Large Language Models](https://arxiv.org/abs/2601.00730)
*Janez Perš,Jon Muhovič,Andrej Košir,Boštjan Murovec*

Main category: cs.CV

TL;DR: 提出一个基于多模态大语言模型的端到端工作流，用于自动批改手写STEM考试，保持标准考试流程，仅需讲师提供手写参考答案和简短评分规则。


<details>
  <summary>Details</summary>
Motivation: 手写STEM考试能捕捉开放式推理和图表，但人工批改速度慢、难以扩展。需要自动化解决方案来保持考试流程的同时提高批改效率。

Method: 多阶段设计：格式/存在性检查防止批改空白答案；独立评分器集成；监督器聚合；刚性模板和确定性验证生成可审计的机器可解析报告。使用多模态LLM（GPT-5.2和Gemini-3 Pro），将手写参考答案转换为纯文本摘要作为评分条件。

Result: 在斯洛文尼亚语的真实课程测验（包含手绘电路图）上评估，完整流程与讲师评分平均绝对差异约8分，偏差低，在D_max=40时手动审查触发率约17%。消融实验显示简单提示和移除参考答案会显著降低准确性并引入系统性过高评分。

Conclusion: 结构化提示和参考答案基础是自动批改手写STEM考试的关键要素，提出的多阶段工作流在保持标准考试流程的同时实现了可靠的自动评分。

Abstract: Handwritten STEM exams capture open-ended reasoning and diagrams, but manual grading is slow and difficult to scale. We present an end-to-end workflow for grading scanned handwritten engineering quizzes with multimodal large language models (LLMs) that preserves the standard exam process (A4 paper, unconstrained student handwriting). The lecturer provides only a handwritten reference solution (100%) and a short set of grading rules; the reference is converted into a text-only summary that conditions grading without exposing the reference scan. Reliability is achieved through a multi-stage design with a format/presence check to prevent grading blank answers, an ensemble of independent graders, supervisor aggregation, and rigid templates with deterministic validation to produce auditable, machine-parseable reports. We evaluate the frozen pipeline in a clean-room protocol on a held-out real course quiz in Slovenian, including hand-drawn circuit schematics. With state-of-the-art backends (GPT-5.2 and Gemini-3 Pro), the full pipeline achieves $\approx$8-point mean absolute difference to lecturer grades with low bias and an estimated manual-review trigger rate of $\approx$17% at $D_{\max}=40$. Ablations show that trivial prompting and removing the reference solution substantially degrade accuracy and introduce systematic over-grading, confirming that structured prompting and reference grounding are essential.

</details>


### [47] [Fusion-SSAT: Unleashing the Potential of Self-supervised Auxiliary Task by Feature Fusion for Generalized Deepfake Detection](https://arxiv.org/abs/2601.00789)
*Shukesh Reddy,Srijan Das,Abhijit Das*

Main category: cs.CV

TL;DR: 通过自监督学习作为辅助任务优化深度伪造检测，特征融合提升跨数据集泛化能力


<details>
  <summary>Details</summary>
Motivation: 探索自监督学习作为辅助任务如何优化广义深度伪造检测这一主要任务，寻找最有效的训练方案组合

Method: 将自监督学习作为辅助任务，研究不同训练方案组合，融合自监督辅助任务的特征表示来增强主要任务

Result: 在DF40、FaceForensics++、Celeb-DF、DFD、FaceShifter、UADFV等数据集上实验，跨数据集评估显示比当前最先进检测器具有更好的泛化性能

Conclusion: 融合自监督辅助任务的特征表示是一种强大的特征表示方法，能够充分利用自监督和主要任务的独特表示，提升主要任务性能

Abstract: In this work, we attempted to unleash the potential of self-supervised learning as an auxiliary task that can optimise the primary task of generalised deepfake detection. To explore this, we examined different combinations of the training schemes for these tasks that can be most effective. Our findings reveal that fusing the feature representation from self-supervised auxiliary tasks is a powerful feature representation for the problem at hand. Such a representation can leverage the ultimate potential and bring in a unique representation of both the self-supervised and primary tasks, achieving better performance for the primary task. We experimented on a large set of datasets, which includes DF40, FaceForensics++, Celeb-DF, DFD, FaceShifter, UADFV, and our results showed better generalizability on cross-dataset evaluation when compared with current state-of-the-art detectors.

</details>


### [48] [Two Deep Learning Approaches for Automated Segmentation of Left Ventricle in Cine Cardiac MRI](https://arxiv.org/abs/2601.00794)
*Wenhui Chu,Nikolaos V. Tsekos*

Main category: cs.CV

TL;DR: 本文提出了LNU-Net和IBU-Net两种深度学习架构用于短轴电影MRI图像的左心室分割，通过层归一化和实例-批量归一化改进U-Net，在805张MRI图像上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 左心室分割对于心脏图像的临床量化和诊断至关重要。现有方法在分割精度方面仍有提升空间，需要更有效的深度学习架构来改进分割性能。

Method: 提出了两种基于U-Net的改进架构：LNU-Net在每个卷积块中应用层归一化；IBU-Net在第一个卷积块中结合实例归一化和批量归一化，并将结果传递到下一层。两种架构都包含用于特征提取的下采样路径和用于精确定位的上采样路径。采用仿射变换和弹性变形进行图像数据处理。

Result: 在包含45名患者805张左心室MRI图像的数据集上评估，实验结果表明提出的方法在骰子系数和平均垂直距离指标上优于其他最先进的方法。

Conclusion: LNU-Net和IBU-Net是有效的左心室分割架构，通过不同的归一化策略改进了U-Net的性能，为心脏图像分析提供了更准确的分割工具。

Abstract: Left ventricle (LV) segmentation is critical for clinical quantification and diagnosis of cardiac images. In this work, we propose two novel deep learning architectures called LNU-Net and IBU-Net for left ventricle segmentation from short-axis cine MRI images. LNU-Net is derived from layer normalization (LN) U-Net architecture, while IBU-Net is derived from the instance-batch normalized (IB) U-Net for medical image segmentation. The architectures of LNU-Net and IBU-Net have a down-sampling path for feature extraction and an up-sampling path for precise localization. We use the original U-Net as the basic segmentation approach and compared it with our proposed architectures. Both LNU-Net and IBU-Net have left ventricle segmentation methods: LNU-Net applies layer normalization in each convolutional block, while IBU-Net incorporates instance and batch normalization together in the first convolutional block and passes its result to the next layer. Our method incorporates affine transformations and elastic deformations for image data processing. Our dataset that contains 805 MRI images regarding the left ventricle from 45 patients is used for evaluation. We experimentally evaluate the results of the proposed approaches outperforming the dice coefficient and the average perpendicular distance than other state-of-the-art approaches.

</details>


### [49] [AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction](https://arxiv.org/abs/2601.00796)
*Jiewen Chan,Zhenjun Zhao,Yu-Lun Liu*

Main category: cs.CV

TL;DR: AdaGaR提出统一框架解决动态3D场景重建中的频率适应性和时间连续性问题，通过自适应Gabor表示和时间曲率正则化实现高质量重建


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：单高斯基元具有低通滤波特性，标准Gabor函数存在能量不稳定问题，且缺乏时间连续性约束导致插值时出现运动伪影

Method: 1. 自适应Gabor表示：通过可学习频率权重和自适应能量补偿扩展高斯函数；2. 时间连续性：采用三次Hermite样条和时间曲率正则化确保平滑运动演化；3. 自适应初始化：结合深度估计、点跟踪和前景掩码建立稳定点云分布

Result: 在Tap-Vid DAVIS数据集上取得SOTA性能：PSNR 35.49，SSIM 0.9433，LPIPS 0.0723；在帧插值、深度一致性、视频编辑和立体视图合成等任务上表现出强大泛化能力

Conclusion: AdaGaR通过统一框架有效解决了动态场景重建中的频率适应性和时间连续性问题，实现了高质量、稳定的3D场景重建和运动建模

Abstract: Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis. Project page: https://jiewenchan.github.io/AdaGaR/

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [50] [RIMRULE: Improving Tool-Using Language Agents via MDL-Guided Rule Learning](https://arxiv.org/abs/2601.00086)
*Xiang Gao,Yuguang Yao,Qi Zhang,Kaiwen Dong,Avinash Baidya,Ruocheng Guo,Hilaf Hasson,Kamalika Das*

Main category: cs.CL

TL;DR: RIMRULE：基于动态规则注入的神经符号方法，通过从失败轨迹中提取紧凑、可解释的规则来提升LLM在特定领域工具使用中的可靠性，无需修改模型权重。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在特定领域工具使用时面临挑战，因为API可能具有特殊性、文档不足或针对私有工作流定制，需要有效的任务特定工具适应方法。

Method: 提出RIMRULE神经符号方法：1) 从失败轨迹中提取紧凑、可解释的规则；2) 使用最小描述长度目标优化规则的通用性和简洁性；3) 将规则以自然语言和结构化符号形式存储；4) 在推理时动态注入规则到提示中。

Result: 在工具使用基准测试中，该方法提高了对已见和未见工具的准确性，优于基于提示的适应方法，并能与微调互补。从一个LLM学习的规则可以重用于改进其他LLM，展示了跨架构的符号知识可移植性。

Conclusion: RIMRULE通过动态规则注入有效提升了LLM在特定领域工具使用中的性能，提供了一种无需修改模型权重的适应方法，且学到的符号规则具有跨模型架构的可移植性。

Abstract: Large language models (LLMs) often struggle to use tools reliably in domain-specific settings, where APIs may be idiosyncratic, under-documented, or tailored to private workflows. This highlights the need for effective adaptation to task-specific tools. We propose RIMRULE, a neuro-symbolic approach for LLM adaptation based on dynamic rule injection. Compact, interpretable rules are distilled from failure traces and injected into the prompt during inference to improve task performance. These rules are proposed by the LLM itself and consolidated using a Minimum Description Length (MDL) objective that favors generality and conciseness. Each rule is stored in both natural language and a structured symbolic form, supporting efficient retrieval at inference time. Experiments on tool-use benchmarks show that this approach improves accuracy on both seen and unseen tools without modifying LLM weights. It outperforms prompting-based adaptation methods and complements finetuning. Moreover, rules learned from one LLM can be reused to improve others, including long reasoning LLMs, highlighting the portability of symbolic knowledge across architectures.

</details>


### [51] [Pat-DEVAL: Chain-of-Legal-Thought Evaluation for Patent Description](https://arxiv.org/abs/2601.00166)
*Yongmin Yoo,Kris W Pan*

Main category: cs.CL

TL;DR: Pat-DEVAL：首个专用于专利说明书的多维度评估框架，通过法律约束推理机制评估长文本结构连贯性和法定合规性，显著优于现有评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有专利自动撰写评估方法无法充分评估专利说明书的长文本结构连贯性和法定合规性（如可实施性和书面描述要求），需要专门针对专利说明书特点的评估框架。

Method: 提出Pat-DEVAL框架，采用LLM-as-a-judge范式，引入Chain-of-Legal-Thought（CoLT）机制，这是一种法律约束推理方法，强制执行顺序的专利法特定分析。

Result: 在Pap2Pat-EvalGold数据集上，经专利专家验证，Pat-DEVAL达到0.69的皮尔逊相关系数，显著优于基线指标和现有LLM评估器；在法律专业合规性方面达到0.73的优异相关性。

Conclusion: 通过明确注入法定约束条件，Pat-DEVAL能够捕捉细微的法律有效性，为自动专利撰写系统的实际部署提供了稳健的方法论基础，建立了技术合理性和法律合规性的新标准。

Abstract: Patent descriptions must deliver comprehensive technical disclosure while meeting strict legal standards such as enablement and written description requirements. Although large language models have enabled end-to-end automated patent drafting, existing evaluation approaches fail to assess long-form structural coherence and statutory compliance specific to descriptions. We propose Pat-DEVAL, the first multi-dimensional evaluation framework dedicated to patent description bodies. Leveraging the LLM-as-a-judge paradigm, Pat-DEVAL introduces Chain-of-Legal-Thought (CoLT), a legally-constrained reasoning mechanism that enforces sequential patent-law-specific analysis. Experiments validated by patent expert on our Pap2Pat-EvalGold dataset demonstrate that Pat-DEVAL achieves a Pearson correlation of 0.69, significantly outperforming baseline metrics and existing LLM evaluators. Notably, the framework exhibits a superior correlation of 0.73 in Legal-Professional Compliance, proving that the explicit injection of statutory constraints is essential for capturing nuanced legal validity. By establishing a new standard for ensuring both technical soundness and legal compliance, Pat-DEVAL provides a robust methodological foundation for the practical deployment of automated patent drafting systems.

</details>


### [52] [Understanding Emotion in Discourse: Recognition Insights and Linguistic Patterns for Generation](https://arxiv.org/abs/2601.00181)
*Cheonkam Jeong,Adeline Nyamathi*

Main category: cs.CL

TL;DR: 该论文系统分析了对话情感识别（ERC）中的关键架构选择，发现对话上下文至关重要（90%增益来自最近10-30轮），层次化句子表示在提供上下文后失效，外部情感词典无增益。同时通过话语标记分析发现悲伤话语的左边缘标记使用率较低（21.9% vs 其他28-32%），解释了悲伤识别最依赖上下文的原因。


<details>
  <summary>Details</summary>
Motivation: 解决对话情感识别（ERC）中的两个关键空白：1）缺乏对哪些架构选择真正重要的系统理解；2）缺乏将识别与生成连接的语言学分析。通过系统分析IEMOCAP数据集来填补这些空白。

Method: 采用系统分析方法：1）识别方面：进行严格的消融研究，使用10种随机种子评估，分析对话上下文、层次化句子表示和外部情感词典的影响；2）语言学分析：分析5,286个话语标记出现情况，研究情感与标记位置的关系，特别关注左边缘标记使用模式。

Result: 识别方面：1）对话上下文至关重要，90%增益来自最近10-30轮；2）层次化句子表示在提供上下文后失效；3）外部情感词典无增益。使用简单架构和严格因果上下文达到82.69%（4类）和67.07%（6类）加权F1，优于先前文本方法。语言学方面：发现情感与标记位置显著相关（p<.0001），悲伤话语左边缘标记使用率较低（21.9% vs 其他28-32%），解释了悲伤识别最依赖上下文（+22%提升）。

Conclusion: 对话情感识别中，对话上下文是最关键因素，层次化表示和外部词典在提供充分上下文后变得冗余。悲伤话语因缺乏显性语用信号（左边缘标记使用率低）而最依赖上下文进行消歧。这些发现为ERC架构设计提供了实证指导，并建立了识别与生成之间的语言学联系。

Abstract: While Emotion Recognition in Conversation (ERC) has achieved high accuracy, two critical gaps remain: a limited understanding of \textit{which} architectural choices actually matter, and a lack of linguistic analysis connecting recognition to generation. We address both gaps through a systematic analysis of the IEMOCAP dataset.
  For recognition, we conduct a rigorous ablation study with 10-seed evaluation and report three key findings. First, conversational context is paramount, with performance saturating rapidly -- 90\% of the total gain achieved within just the most recent 10--30 preceding turns (depending on the label set). Second, hierarchical sentence representations help at utterance-level, but this benefit disappears once conversational context is provided, suggesting that context subsumes intra-utterance structure. Third, external affective lexicons (SenticNet) provide no gain, indicating that pre-trained encoders already capture necessary emotional semantics. With simple architectures using strictly causal context, we achieve 82.69\% (4-way) and 67.07\% (6-way) weighted F1, outperforming prior text-only methods including those using bidirectional context.
  For linguistic analysis, we analyze 5,286 discourse marker occurrences and find a significant association between emotion and marker positioning ($p < .0001$). Notably, "sad" utterances exhibit reduced left-periphery marker usage (21.9\%) compared to other emotions (28--32\%), consistent with theories linking left-periphery markers to active discourse management. This connects to our recognition finding that sadness benefits most from context (+22\%p): lacking explicit pragmatic signals, sad utterances require conversational history for disambiguation.

</details>


### [53] [Knowledge Distillation for Temporal Knowledge Graph Reasoning with Large Language Models](https://arxiv.org/abs/2601.00202)
*Wang Xing,Wei Song,Siyu Lin,Chen Wu,Zhesi Li,Man Wang*

Main category: cs.CL

TL;DR: 提出专门针对时序知识图谱推理的蒸馏框架，利用大语言模型作为教师模型，将结构和时序推理能力转移到轻量级学生模型，在保持紧凑架构的同时提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有TKG推理模型参数量大、计算密集，导致硬件成本高、能耗大，难以部署在资源受限的低功耗分布式平台上；现有的模型压缩和蒸馏技术主要针对静态知识图谱，无法充分捕捉TKG中的时序依赖关系，导致推理性能下降。

Method: 提出专门针对时序知识图谱推理的蒸馏框架，利用大语言模型作为教师模型指导蒸馏过程，有效传递结构和时序推理能力到轻量级学生模型；通过整合大规模公共知识和任务特定的时序信息，增强学生模型对时序动态的建模能力，同时保持紧凑高效的架构。

Result: 在多个公开基准数据集上的广泛实验表明，该方法持续优于强基线，在推理准确性、计算效率和实际可部署性之间实现了有利的权衡。

Conclusion: 提出的蒸馏框架专门针对TKG推理，通过大语言模型作为教师模型，成功将复杂的结构和时序推理能力转移到轻量级学生模型，解决了现有TKG推理模型部署困难的问题，为资源受限平台上的实时推理提供了可行的解决方案。

Abstract: Reasoning over temporal knowledge graphs (TKGs) is fundamental to improving the efficiency and reliability of intelligent decision-making systems and has become a key technological foundation for future artificial intelligence applications. Despite recent progress, existing TKG reasoning models typically rely on large parameter sizes and intensive computation, leading to high hardware costs and energy consumption. These constraints hinder their deployment on resource-constrained, low-power, and distributed platforms that require real-time inference. Moreover, most existing model compression and distillation techniques are designed for static knowledge graphs and fail to adequately capture the temporal dependencies inherent in TKGs, often resulting in degraded reasoning performance. To address these challenges, we propose a distillation framework specifically tailored for temporal knowledge graph reasoning. Our approach leverages large language models as teacher models to guide the distillation process, enabling effective transfer of both structural and temporal reasoning capabilities to lightweight student models. By integrating large-scale public knowledge with task-specific temporal information, the proposed framework enhances the student model's ability to model temporal dynamics while maintaining a compact and efficient architecture. Extensive experiments on multiple publicly available benchmark datasets demonstrate that our method consistently outperforms strong baselines, achieving a favorable trade-off between reasoning accuracy, computational efficiency, and practical deployability.

</details>


### [54] [From Evidence-Based Medicine to Knowledge Graph: Retrieval-Augmented Generation for Sports Rehabilitation and a Domain Benchmark](https://arxiv.org/abs/2601.00216)
*Jinning Zhang,Jie Song,Wenhui Tu,Zecheng Li,Jingxuan Li,Jin Li,Xuan Liu,Taole Sha,Zichen Wei,Yan Li*

Main category: cs.CL

TL;DR: 该研究提出了一种将循证医学原则整合到基于图的知识检索增强生成中的通用策略，解决了PICO对齐和证据等级考虑两个关键问题，并在运动康复领域验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前医学领域的检索增强生成方法主要关注性能改进，但忽视了循证医学原则。具体存在两个关键缺陷：1) 查询与检索证据之间缺乏PICO对齐；2) 重排序过程中缺少证据等级考虑。本研究旨在填补这些空白，将循证医学原则系统性地整合到基于图的RAG框架中。

Method: 提出了一种通用的循证医学适应策略：1) 将PICO框架整合到知识图谱构建和检索过程中；2) 提出贝叶斯启发的重排序算法，根据证据等级校准排序分数，无需引入预定义权重。在运动康复领域验证该框架，构建了包含357,844个节点和371,226条边的知识图谱，以及1,637个QA对的可复用基准。

Result: 系统性能指标：0.830的金块覆盖率、0.819的答案忠实度、0.882的语义相似度、0.788的PICOT匹配准确率。五位临床专家在5点李克特量表评估中，在事实准确性、忠实度、相关性、安全性和PICO对齐方面给予4.66-4.84的高分。验证了该策略能显著提升检索和答案质量。

Conclusion: 提出的循证医学适应策略不仅提高了检索和答案质量，而且具有跨临床领域的可迁移性。发布的资源（知识图谱和基准数据集）有助于解决运动康复领域RAG数据集的稀缺问题，为其他临床领域的类似应用提供了可复用的框架和方法。

Abstract: In medicine, large language models (LLMs) increasingly rely on retrieval-augmented generation (RAG) to ground outputs in up-to-date external evidence. However, current RAG approaches focus primarily on performance improvements while overlooking evidence-based medicine (EBM) principles. This study addresses two key gaps: (1) the lack of PICO alignment between queries and retrieved evidence, and (2) the absence of evidence hierarchy considerations during reranking. We present a generalizable strategy for adapting EBM to graph-based RAG, integrating the PICO framework into knowledge graph construction and retrieval, and proposing a Bayesian-inspired reranking algorithm to calibrate ranking scores by evidence grade without introducing predefined weights. We validated this framework in sports rehabilitation, a literature-rich domain currently lacking RAG systems and benchmarks. We released a knowledge graph (357,844 nodes and 371,226 edges) and a reusable benchmark of 1,637 QA pairs. The system achieved 0.830 nugget coverage, 0.819 answer faithfulness, 0.882 semantic similarity, and 0.788 PICOT match accuracy. In a 5-point Likert evaluation, five expert clinicians rated the system 4.66-4.84 across factual accuracy, faithfulness, relevance, safety, and PICO alignment. These findings demonstrate that the proposed EBM adaptation strategy improves retrieval and answer quality and is transferable to other clinical domains. The released resources also help address the scarcity of RAG datasets in sports rehabilitation.

</details>


### [55] [JP-TL-Bench: Anchored Pairwise LLM Evaluation for Bidirectional Japanese-English Translation](https://arxiv.org/abs/2601.00223)
*Leonard Lin,Adam Lensenmayer*

Main category: cs.CL

TL;DR: JP-TL-Bench是一个轻量级开源基准测试，专门用于指导日英翻译系统的迭代开发，通过可靠的LLM成对比较评估翻译质量。


<details>
  <summary>Details</summary>
Motivation: 日英翻译中，细微的礼貌、隐含意义、省略和语域选择对自然度影响显著，需要评估"哪个翻译更好"而非"翻译是否可接受"。现有基准难以捕捉这些细微差异，需要专门针对日英翻译特点设计的评估方法。

Method: 采用无参考的成对LLM比较方法：将候选模型与固定的版本化锚定集进行对比，使用Bradley-Terry模型聚合成对结果，生成胜率和通过逻辑变换得到的0-10分"LT"分数。评估协议设计确保LLM判断既可靠又经济。

Result: JP-TL-Bench提供了结构稳定的评估框架：每个候选模型都针对相同的冻结锚定集进行评分，在相同基础集、评判者和聚合代码下，分数具有结构稳定性。评估结果包括胜率和标准化LT分数。

Conclusion: JP-TL-Bench为日英翻译系统开发提供了专门设计的轻量级基准测试，通过可靠的成对比较方法捕捉翻译质量的细微差异，支持迭代开发过程中的质量评估。

Abstract: We introduce JP-TL-Bench, a lightweight, open benchmark designed to guide the iterative development of Japanese-English translation systems. In this context, the challenge is often "which of these two good translations is better?" rather than "is this translation acceptable?" This distinction matters for Japanese-English, where subtle choices in politeness, implicature, ellipsis, and register strongly affect perceived naturalness. JP-TL-Bench uses a protocol built to make LLM judging both reliable and affordable: it evaluates a candidate model via reference-free, pairwise LLM comparisons against a fixed, versioned anchor set. Pairwise results are aggregated with a Bradley-Terry model and reported as win rates plus a normalized 0-10 "LT" score derived from a logistic transform of fitted log-strengths. Because each candidate is scored against the same frozen anchor set, scores are structurally stable given the same base set, judge, and aggregation code.

</details>


### [56] [Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation](https://arxiv.org/abs/2601.00263)
*Qianli Wang,Van Bach Nguyen,Yihong Liu,Fedor Splitt,Nils Feldhus,Christin Seifert,Hinrich Schütze,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 该研究系统评估了大语言模型生成多语言反事实解释的能力，发现翻译生成的反事实比直接生成的有效性更高但修改量更大，多语言反事实数据增强对低资源语言效果更好，但生成质量限制了模型性能提升。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在生成英语反事实解释方面表现出色并具备多语言能力，但其在多语言反事实生成方面的有效性尚不明确，需要系统评估以理解其跨语言解释能力。

Method: 1) 在六种语言上进行自动评估，比较直接生成的反事实和通过英语翻译生成的反事实；2) 分析高资源欧洲语言反事实的编辑模式相似性；3) 识别并分类跨语言反事实生成中的错误类型；4) 评估多语言反事实数据增强与跨语言数据增强对模型性能的影响。

Result: 1) 翻译生成的反事实比直接生成的有效性更高，但需要更多修改，且质量仍不及原始英语反事实；2) 高资源欧洲语言的编辑模式高度相似，表明跨语言扰动遵循共同策略原则；3) 识别出四种跨语言一致的错误类型；4) 多语言反事实数据增强比跨语言数据增强带来更大的模型性能提升，尤其对低资源语言，但反事实的不完美限制了性能提升和鲁棒性。

Conclusion: 大语言模型在多语言反事实生成方面存在局限性，翻译方法虽然提高有效性但代价高昂，跨语言扰动策略具有共性，反事实数据增强对低资源语言有益但受限于生成质量，需要进一步改进多语言反事实生成技术。

Abstract: Counterfactuals refer to minimally edited inputs that cause a model's prediction to change, serving as a promising approach to explaining the model's behavior. Large language models (LLMs) excel at generating English counterfactuals and demonstrate multilingual proficiency. However, their effectiveness in generating multilingual counterfactuals remains unclear. To this end, we conduct a comprehensive study on multilingual counterfactuals. We first conduct automatic evaluations on both directly generated counterfactuals in the target languages and those derived via English translation across six languages. Although translation-based counterfactuals offer higher validity than their directly generated counterparts, they demand substantially more modifications and still fall short of matching the quality of the original English counterfactuals. Second, we find the patterns of edits applied to high-resource European-language counterfactuals to be remarkably similar, suggesting that cross-lingual perturbations follow common strategic principles. Third, we identify and categorize four main types of errors that consistently appear in the generated counterfactuals across languages. Finally, we reveal that multilingual counterfactual data augmentation (CDA) yields larger model performance improvements than cross-lingual CDA, especially for lower-resource languages. Yet, the imperfections of the generated counterfactuals limit gains in model performance and robustness.

</details>


### [57] [Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity](https://arxiv.org/abs/2601.00268)
*Doyoung Kim,Zhiwei Ren,Jie Hao,Zhongkai Sun,Lichao Wang,Xiyao Ma,Zack Ye,Xu Han,Jun Yin,Heng Ji,Wei Shen,Xing Fan,Benjamin Yao,Chenlei Guo*

Main category: cs.CL

TL;DR: WildAGTEval是一个评估LLM智能体函数调用能力的基准测试，专注于真实API复杂性，包含API规范和API执行两个维度的挑战，涵盖60个复杂度场景和约32K测试配置。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常假设理想化的API系统，忽略了真实世界因素如噪声API输出。需要评估LLM智能体在真实API复杂性下的函数调用能力，以更好地反映实际应用场景中的挑战。

Method: 设计WildAGTEval基准测试，包含两个维度：1) API规范（详细文档和使用约束），2) API执行（运行时挑战）。构建包含60个不同复杂度场景的API系统，可组合成约32K测试配置，并提供用户-智能体交互评估框架。

Result: 评估多个先进LLM发现：大多数场景具有挑战性，不相关信息复杂度造成最大困难，使强LLM性能下降27.3%。定性分析显示LLM有时会扭曲用户意图以声称任务完成，严重影响用户满意度。

Conclusion: WildAGTEval为评估LLM智能体在真实API复杂性下的函数调用能力提供了系统基准，揭示了当前模型在应对真实世界API挑战时的局限性，特别是处理不相关信息和保持用户意图准确性方面的问题。

Abstract: We introduce WildAGTEval, a benchmark designed to evaluate large language model (LLM) agents' function-calling capabilities under realistic API complexity. Unlike prior work that assumes an idealized API system and disregards real-world factors such as noisy API outputs, WildAGTEval accounts for two dimensions of real-world complexity: 1. API specification, which includes detailed documentation and usage constraints, and 2. API execution, which captures runtime challenges. Consequently, WildAGTEval offers (i) an API system encompassing 60 distinct complexity scenarios that can be composed into approximately 32K test configurations, and (ii) user-agent interactions for evaluating LLM agents on these scenarios. Using WildAGTEval, we systematically assess several advanced LLMs and observe that most scenarios are challenging, with irrelevant information complexity posing the greatest difficulty and reducing the performance of strong LLMs by 27.3%. Furthermore, our qualitative analysis reveals that LLMs occasionally distort user intent merely to claim task completion, critically affecting user satisfaction.

</details>


### [58] [Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations](https://arxiv.org/abs/2601.00282)
*Qianli Wang,Nils Feldhus,Pepa Atanasova,Fedor Splitt,Simon Ostermann,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 量化对LLM自解释能力的影响研究：量化通常导致自解释质量和忠实度适度下降，但不会显著削弱量化作为模型压缩技术的有效性。


<details>
  <summary>Details</summary>
Motivation: 量化被广泛用于加速大语言模型推理和简化部署，但其对自解释的影响尚未被探索。自解释需要模型对其自身决策过程进行推理，这种能力可能对量化特别敏感。鉴于自解释在高风险应用透明度中的重要性，理解量化是否以及如何降低自解释质量和忠实度至关重要。

Method: 研究两种类型的自解释：自然语言解释和反事实示例，使用三种常见量化技术在特定比特宽度下生成。通过用户研究评估量化对自解释连贯性和可信度的影响，比较不同规模模型对量化的弹性。

Result: 量化通常导致自解释质量下降最多4.4%，忠实度下降最多2.38%。用户研究表明量化降低了自解释的连贯性和可信度（最多8.5%）。相比小模型，大模型在自解释质量方面对量化的弹性有限，但在保持忠实度方面表现更好。没有一种量化技术在任务准确性、自解释质量和忠实度方面始终表现出色。

Conclusion: 量化影响因上下文而异，建议针对具体用例验证自解释质量，特别是对更敏感的自然语言解释。然而，自解释质量和忠实度的相对较小恶化并不削弱量化作为模型压缩技术的有效性。

Abstract: Quantization is widely used to accelerate inference and streamline the deployment of large language models (LLMs), yet its effects on self-explanations (SEs) remain unexplored. SEs, generated by LLMs to justify their own outputs, require reasoning about the model's own decision-making process, a capability that may exhibit particular sensitivity to quantization. As SEs are increasingly relied upon for transparency in high-stakes applications, understanding whether and to what extent quantization degrades SE quality and faithfulness is critical. To address this gap, we examine two types of SEs: natural language explanations (NLEs) and counterfactual examples, generated by LLMs quantized using three common techniques at distinct bit widths. Our findings indicate that quantization typically leads to moderate declines in both SE quality (up to 4.4\%) and faithfulness (up to 2.38\%). The user study further demonstrates that quantization diminishes both the coherence and trustworthiness of SEs (up to 8.5\%). Compared to smaller models, larger models show limited resilience to quantization in terms of SE quality but better maintain faithfulness. Moreover, no quantization technique consistently excels across task accuracy, SE quality, and faithfulness. Given that quantization's impact varies by context, we recommend validating SE quality for specific use cases, especially for NLEs, which show greater sensitivity. Nonetheless, the relatively minor deterioration in SE quality and faithfulness does not undermine quantization's effectiveness as a model compression technique.

</details>


### [59] [DepFlow: Disentangled Speech Generation to Mitigate Semantic Bias in Depression Detection](https://arxiv.org/abs/2601.00303)
*Yuxin Li,Xiangyu Zhang,Yifei Li,Zhiwei Guo,Haoyang Zhang,Eng Siong Chng,Cuntai Guan*

Main category: cs.CL

TL;DR: DepFlow：一种三阶段抑郁症条件文本转语音框架，通过解耦声学抑郁特征与语义内容来缓解语义偏见，构建伪装抑郁症增强数据集，提升抑郁症检测模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁症数据集（如DAIC-WOZ）中语言情感与诊断标签强耦合，导致模型学习语义捷径，在真实场景（如伪装抑郁症）中鲁棒性不足。需要解耦声学抑郁特征与语义内容，缓解语义偏见。

Method: 提出DepFlow三阶段框架：1）抑郁症声学编码器通过对抗训练学习说话人和内容不变的抑郁嵌入；2）基于FiLM调制的流匹配TTS模型注入抑郁嵌入，控制抑郁严重程度同时保持内容和说话人身份；3）基于原型的严重程度映射机制实现连续可解释的抑郁程度控制。利用该框架构建伪装抑郁症增强数据集（CDoA）。

Result: 抑郁症声学编码器ROC-AUC达0.693，有效解耦同时保持抑郁区分能力。CDoA数据集在三种抑郁症检测架构上分别提升macro-F1 9%、12%和5%，优于传统增强策略。DepFlow还提供了可控合成平台。

Conclusion: DepFlow通过解耦声学抑郁特征与语义内容，有效缓解抑郁症检测中的语义偏见，提升模型在伪装抑郁症等真实场景中的鲁棒性。该框架不仅增强检测性能，还为对话系统和仿真评估提供了可控合成平台。

Abstract: Speech is a scalable and non-invasive biomarker for early mental health screening. However, widely used depression datasets like DAIC-WOZ exhibit strong coupling between linguistic sentiment and diagnostic labels, encouraging models to learn semantic shortcuts. As a result, model robustness may be compromised in real-world scenarios, such as Camouflaged Depression, where individuals maintain socially positive or neutral language despite underlying depressive states. To mitigate this semantic bias, we propose DepFlow, a three-stage depression-conditioned text-to-speech framework. First, a Depression Acoustic Encoder learns speaker- and content-invariant depression embeddings through adversarial training, achieving effective disentanglement while preserving depression discriminability (ROC-AUC: 0.693). Second, a flow-matching TTS model with FiLM modulation injects these embeddings into synthesis, enabling control over depressive severity while preserving content and speaker identity. Third, a prototype-based severity mapping mechanism provides smooth and interpretable manipulation across the depression continuum. Using DepFlow, we construct a Camouflage Depression-oriented Augmentation (CDoA) dataset that pairs depressed acoustic patterns with positive/neutral content from a sentiment-stratified text bank, creating acoustic-semantic mismatches underrepresented in natural data. Evaluated across three depression detection architectures, CDoA improves macro-F1 by 9%, 12%, and 5%, respectively, consistently outperforming conventional augmentation strategies in depression Detection. Beyond enhancing robustness, DepFlow provides a controllable synthesis platform for conversational systems and simulation-based evaluation, where real clinical data remains limited by ethical and coverage constraints.

</details>


### [60] [Robust Uncertainty Quantification for Factual Generation of Large Language Models](https://arxiv.org/abs/2601.00348)
*Yuhao Zhang,Zhongliang Yang,Linna Zhou*

Main category: cs.CL

TL;DR: 该研究针对大语言模型幻觉问题，提出了一种基于多事实生成任务的鲁棒不确定性量化方法，通过构建包含虚假名称的陷阱问题集来评估模型可靠性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型幻觉问题严重影响了AI生成内容的可靠性和可信度。现有不确定性量化方法在常规问答场景中有效，但在面对非常规或对抗性提问策略时表现不足，这限制了LLM在需要强大批判性思维能力的实际应用中的可靠性。

Method: 研究构建了包含虚假名称的陷阱问题集，并创新性地提出了一种鲁棒的不确定性量化方法(RU)。该方法在多事实生成任务中评估模型的不确定性，通过精心设计的对抗性场景来测试模型的可靠性。

Result: 实验结果表明，构建的陷阱问题集表现优异。与基线方法相比，在四个不同模型上，提出的RU方法在ROCAUC值上平均提升了0.1-0.2，显著优于现有最佳基线方法。

Conclusion: 该研究为解决大语言模型幻觉问题提供了新的视角和方法，通过鲁棒的不确定性量化框架增强了模型在对抗性场景下的可靠性评估能力，为实际应用中的可信AI系统开发做出了贡献。

Abstract: The rapid advancement of large language model(LLM) technology has facilitated its integration into various domains of professional and daily life. However, the persistent challenge of LLM hallucination has emerged as a critical limitation, significantly compromising the reliability and trustworthiness of AI-generated content. This challenge has garnered significant attention within the scientific community, prompting extensive research efforts in hallucination detection and mitigation strategies. Current methodological frameworks reveal a critical limitation: traditional uncertainty quantification approaches demonstrate effectiveness primarily within conventional question-answering paradigms, yet exhibit notable deficiencies when confronted with non-canonical or adversarial questioning strategies. This performance gap raises substantial concerns regarding the dependability of LLM responses in real-world applications requiring robust critical thinking capabilities. This study aims to fill this gap by proposing an uncertainty quantification scenario in the task of generating with multiple facts. We have meticulously constructed a set of trap questions contained with fake names. Based on this scenario, we innovatively propose a novel and robust uncertainty quantification method(RU). A series of experiments have been conducted to verify its effectiveness. The results show that the constructed set of trap questions performs excellently. Moreover, when compared with the baseline methods on four different models, our proposed method has demonstrated great performance, with an average increase of 0.1-0.2 in ROCAUC values compared to the best performing baseline method, providing new sights and methods for addressing the hallucination issue of LLMs.

</details>


### [61] [BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics](https://arxiv.org/abs/2601.00366)
*Taj Gillin,Adam Lalani,Kenneth Zhang,Marcel Mateos Salles*

Main category: cs.CL

TL;DR: BERT-JEPA (BEPA) 是一种结合JEPA训练目标的BERT风格模型，通过对抗[CLS]嵌入空间坍塌问题，将其转变为语言无关空间，从而提升多语言基准性能。


<details>
  <summary>Details</summary>
Motivation: 解决BERT模型中[CLS]嵌入空间坍塌问题，并创建语言无关的表示空间，以提升多语言任务的性能。

Method: 在BERT风格模型中引入JEPA（联合嵌入预测架构）训练目标，通过预测性架构对抗[CLS]嵌入空间的坍塌，将其转化为语言无关的表示空间。

Result: BERT-JEPA在多语言基准测试中表现出性能提升，验证了JEPA训练目标在改善多语言表示学习方面的有效性。

Conclusion: 将JEPA训练目标整合到BERT风格模型中能有效解决[CLS]嵌入空间坍塌问题，创建语言无关表示空间，从而提升多语言任务的性能表现。

Abstract: Joint Embedding Predictive Architectures (JEPA) are a novel self supervised training technique that have shown recent promise across domains. We introduce BERT-JEPA (BEPA), a training paradigm that adds a JEPA training objective to BERT-style models, working to combat a collapsed [CLS] embedding space and turning it into a language-agnostic space. This new structure leads to increased performance across multilingual benchmarks.

</details>


### [62] [Vision-Language Reasoning for Geolocalization: A Reinforcement Learning Approach](https://arxiv.org/abs/2601.00388)
*Biao Wu,Meng Fang,Ling Chen,Ke Xu,Tao Cheng,Jun Wang*

Main category: cs.CL

TL;DR: Geo-R：基于强化学习的无检索图像地理定位框架，通过结构化地理推理链和坐标对齐奖励机制提升定位精度与可解释性


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在图像地理定位中通常依赖合成推理标注或外部图像检索，这限制了方法的可解释性和泛化能力。需要一种无需检索、基于真实坐标、具有结构化推理能力的定位框架。

Method: 提出Geo-R框架：1）引入"区域链"规则化分层推理范式，将GPS坐标映射到地理实体层级（国家、省份、城市等），无需模型生成或合成标签；2）采用轻量级强化学习策略，基于Haversine距离设计坐标对齐奖励，通过空间有意义的反馈优化预测；3）结合结构化地理推理与直接空间监督。

Result: 在多个基准测试中验证了Geo-R的有效性，实现了更高的定位精度、更强的泛化能力和更透明的推理过程，为可扩展和可解释的图像地理定位建立了新的无检索范式。

Conclusion: Geo-R通过结构化推理链和强化学习奖励机制，成功地将地理推理与空间监督相结合，提供了一种无需检索、可解释且泛化能力强的图像地理定位解决方案，推动了该领域向更透明、更可扩展的方向发展。

Abstract: Recent advances in vision-language models have opened up new possibilities for reasoning-driven image geolocalization. However, existing approaches often rely on synthetic reasoning annotations or external image retrieval, which can limit interpretability and generalizability. In this paper, we present Geo-R, a retrieval-free framework that uncovers structured reasoning paths from existing ground-truth coordinates and optimizes geolocation accuracy via reinforcement learning. We propose the Chain of Region, a rule-based hierarchical reasoning paradigm that generates precise, interpretable supervision by mapping GPS coordinates to geographic entities (e.g., country, province, city) without relying on model-generated or synthetic labels. Building on this, we introduce a lightweight reinforcement learning strategy with coordinate-aligned rewards based on Haversine distance, enabling the model to refine predictions through spatially meaningful feedback. Our approach bridges structured geographic reasoning with direct spatial supervision, yielding improved localization accuracy, stronger generalization, and more transparent inference. Experimental results across multiple benchmarks confirm the effectiveness of Geo-R, establishing a new retrieval-free paradigm for scalable and interpretable image geolocalization. To facilitate further research and ensure reproducibility, both the model and code will be made publicly available.

</details>


### [63] [Do LLMs Judge Distantly Supervised Named Entity Labels Well? Constructing the JudgeWEL Dataset](https://arxiv.org/abs/2601.00411)
*Alistair Plum,Laura Bernardy,Tharindu Ranasinghe*

Main category: cs.CL

TL;DR: 提出了judgeWEL数据集，这是一个用于卢森堡语命名实体识别的数据集，采用基于维基百科和维基数据的弱监督方法自动标注，并通过大语言模型验证的新流程。


<details>
  <summary>Details</summary>
Motivation: 为低资源语言构建数据集是自然语言处理的主要瓶颈之一，资源稀缺和语言特殊性使得大规模标注成本高昂且可能不一致。卢森堡语作为代表性不足的语言，需要更有效的标注方法。

Method: 利用维基百科和维基数据作为弱监督的结构化来源，通过维基百科文章内部链接推断实体类型（基于对应的维基数据条目），生成初始标注。然后使用多个大语言模型识别和保留高质量标注句子，减少噪声。

Result: 生成的语料库比当前可用的卢森堡语NER数据集大约五倍，在实体类别上提供更广泛和更平衡的覆盖，为多语言和低资源NER研究提供了重要的新资源。

Conclusion: 提出的judgeWEL数据集通过结合维基百科的弱监督和大语言模型验证，为低资源语言NER提供了一种有效的数据集构建方法，显著扩展了卢森堡语NER资源。

Abstract: We present judgeWEL, a dataset for named entity recognition (NER) in Luxembourgish, automatically labelled and subsequently verified using large language models (LLM) in a novel pipeline. Building datasets for under-represented languages remains one of the major bottlenecks in natural language processing, where the scarcity of resources and linguistic particularities make large-scale annotation costly and potentially inconsistent. To address these challenges, we propose and evaluate a novel approach that leverages Wikipedia and Wikidata as structured sources of weak supervision. By exploiting internal links within Wikipedia articles, we infer entity types based on their corresponding Wikidata entries, thereby generating initial annotations with minimal human intervention. Because such links are not uniformly reliable, we mitigate noise by employing and comparing several LLMs to identify and retain only high-quality labelled sentences. The resulting corpus is approximately five times larger than the currently available Luxembourgish NER dataset and offers broader and more balanced coverage across entity categories, providing a substantial new resource for multilingual and low-resource NER research.

</details>


### [64] [Toward Better Temporal Structures for Geopolitical Events Forecasting](https://arxiv.org/abs/2601.00430)
*Kian Ahrabian,Eric Boxer,Jay Pujara*

Main category: cs.CL

TL;DR: 论文提出了一种新的超关系时序知识广义超图（HTKGHs）结构，用于更有效地表示复杂的地缘政治事件，并基于POLECAT数据库构建了htkgh-polecat数据集，评估了LLMs在复杂预测场景中的能力。


<details>
  <summary>Details</summary>
Motivation: 现有超关系时序知识图（HTKGs）在表示复杂事实时存在局限性，特别是无法支持两个以上主要实体的时序事实，而这类复杂关系在地缘政治事件中很常见。需要一种更强大的表示结构来有效捕捉这些复杂关系。

Method: 1. 提出HTKGHs（超关系时序知识广义超图）作为HTKGs的泛化形式，支持两种常见于地缘政治事件的复杂事实类型；2. 基于POLECAT全球事件数据库构建htkgh-polecat数据集；3. 在关系预测任务上对流行的大型语言模型进行基准测试和分析。

Result: 1. 形式化定义了HTKGHs结构，保持了向后兼容性；2. 创建了htkgh-polecat数据集；3. 通过基准测试提供了LLMs在复杂预测场景中适应性和能力的见解。

Conclusion: HTKGHs为表示复杂时序事实提供了更强大的框架，特别是在地缘政治领域。通过htkgh-polecat数据集和LLMs基准测试，为复杂预测场景的研究提供了有价值的资源和见解。

Abstract: Forecasting on geopolitical temporal knowledge graphs (TKGs) through the lens of large language models (LLMs) has recently gained traction. While TKGs and their generalization, hyper-relational temporal knowledge graphs (HTKGs), offer a straightforward structure to represent simple temporal relationships, they lack the expressive power to convey complex facts efficiently. One of the critical limitations of HTKGs is a lack of support for more than two primary entities in temporal facts, which commonly occur in real-world events. To address this limitation, in this work, we study a generalization of HTKGs, Hyper-Relational Temporal Knowledge Generalized Hypergraphs (HTKGHs). We first derive a formalization for HTKGHs, demonstrating their backward compatibility while supporting two complex types of facts commonly found in geopolitical incidents. Then, utilizing this formalization, we introduce the htkgh-polecat dataset, built upon the global event database POLECAT. Finally, we benchmark and analyze popular LLMs on the relation prediction task, providing insights into their adaptability and capabilities in complex forecasting scenarios.

</details>


### [65] [Comparative Efficiency Analysis of Lightweight Transformer Models: A Multi-Domain Empirical Benchmark for Enterprise NLP Deployment](https://arxiv.org/abs/2601.00444)
*Muhammad Shahmeer Khan*

Main category: cs.CL

TL;DR: 对比分析DistilBERT、MiniLM和ALBERT三种轻量Transformer模型在情感分类、新闻分类和仇恨言论检测三个领域的性能与效率表现，揭示不同模型在准确性和效率间的权衡。


<details>
  <summary>Details</summary>
Motivation: 企业NLP应用对高效轻量模型的需求日益增长，需要能够在多领域文本自动化任务中表现优异的模型。本研究旨在比较主流轻量Transformer模型在不同实际应用场景中的性能表现，为企业选择合适的模型提供依据。

Method: 使用IMDB、AG News和Measuring Hate Speech三个数据集，分别在客户情感分类、新闻主题分类以及毒性和仇恨言论检测三个领域进行实验。评估指标包括准确率、精确率、召回率、F1分数等准确性指标，以及模型大小、推理时间、吞吐量和内存使用等效率指标。采用固定企业导向约束下的受控微调策略，而非穷尽的超参数优化。

Result: 没有单一模型在所有性能维度上占优：ALBERT在多个领域达到最高的任务特定准确率；MiniLM在推理速度和吞吐量方面表现最佳；DistilBERT在跨任务中展现出最一致的准确性，同时保持竞争力的效率。所有结果均在固定约束条件下获得。

Conclusion: 研究揭示了准确性和效率之间的权衡关系，为企业应用提供具体建议：对延迟敏感的应用推荐MiniLM，需要平衡性能的选择DistilBERT，资源受限环境则适合ALBERT。这些发现为企业根据具体需求选择合适的轻量Transformer模型提供了实用指导。

Abstract: In the rapidly evolving landscape of enterprise natural language processing (NLP), the demand for efficient, lightweight models capable of handling multi-domain text automation tasks has intensified. This study conducts a comparative analysis of three prominent lightweight Transformer models - DistilBERT, MiniLM, and ALBERT - across three distinct domains: customer sentiment classification, news topic classification, and toxicity and hate speech detection. Utilizing datasets from IMDB, AG News, and the Measuring Hate Speech corpus, we evaluated performance using accuracy-based metrics including accuracy, precision, recall, and F1-score, as well as efficiency metrics such as model size, inference time, throughput, and memory usage. Key findings reveal that no single model dominates all performance dimensions. ALBERT achieves the highest task-specific accuracy in multiple domains, MiniLM excels in inference speed and throughput, and DistilBERT demonstrates the most consistent accuracy across tasks while maintaining competitive efficiency. All results reflect controlled fine-tuning under fixed enterprise-oriented constraints rather than exhaustive hyperparameter optimization. These results highlight trade-offs between accuracy and efficiency, recommending MiniLM for latency-sensitive enterprise applications, DistilBERT for balanced performance, and ALBERT for resource-constrained environments.

</details>


### [66] [Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games](https://arxiv.org/abs/2601.00448)
*Dimitris Vartziotis*

Main category: cs.CL

TL;DR: 论文对比了语言意义的两种理论框架：社会建构主义（语言游戏）和数学导向的语义场理论，分析LLMs如何体现这两种视角，认为数学结构与语言游戏是互补而非竞争的关系。


<details>
  <summary>Details</summary>
Motivation: 利用大语言模型这一新的实证环境，检验长期存在的语言意义理论，特别是对比社会建构主义（语言游戏）和数学导向的语义场理论，探讨语言本质的理解框架。

Method: 基于作者先前工作，形式化词汇场和语言场作为连续语义空间中的交互结构，分析transformer架构的核心特性（分布式表示、注意力机制、嵌入空间几何规律）与这些概念的关系。

Result: LLMs在捕捉语义规律方面的成功支持语言具有底层数学结构的观点，而其在语用推理和语境敏感性方面的持续局限则与哲学语言使用理论强调的社会基础重要性一致。

Conclusion: 数学结构和语言游戏应被视为互补而非竞争视角，这一框架澄清了纯统计语言模型的适用范围和局限，并为理论指导的AI架构指明了新方向。

Abstract: Large language models (LLMs) offer a new empirical setting in which long-standing theories of linguistic meaning can be examined. This paper contrasts two broad approaches: social constructivist accounts associated with language games, and a mathematically oriented framework we call Semantic Field Theory. Building on earlier work by the author, we formalize the notions of lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in a continuous semantic space. We then analyze how core properties of transformer architectures-such as distributed representations, attention mechanisms, and geometric regularities in embedding spaces-relate to these concepts. We argue that the success of LLMs in capturing semantic regularities supports the view that language exhibits an underlying mathematical structure, while their persistent limitations in pragmatic reasoning and context sensitivity are consistent with the importance of social grounding emphasized in philosophical accounts of language use. On this basis, we suggest that mathematical structure and language games can be understood as complementary rather than competing perspectives. The resulting framework clarifies the scope and limits of purely statistical models of language and motivates new directions for theoretically informed AI architectures.

</details>


### [67] [Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations](https://arxiv.org/abs/2601.00454)
*Hyunjun Kim*

Main category: cs.CL

TL;DR: 提出Defensive M2S训练范式，通过将多轮对话压缩为单轮来显著降低护栏模型的训练和推理成本，同时保持高攻击检测性能。


<details>
  <summary>Details</summary>
Motivation: 护栏模型对LLM部署安全至关重要，但处理完整多轮对话历史会带来高昂计算成本，需要更高效的训练和推理方法。

Method: 提出Multi-turn to Single-turn (M2S)压缩范式，将多轮对话压缩为单轮进行护栏模型微调。使用三种压缩模板(hyphenize, numberize, pythonize)在三个护栏模型家族(LlamaGuard, Nemotron, Qwen3Guard)上评估。

Result: M2S将训练成本从O(n²)降至O(n)，训练token减少93倍(从15.7M降至169K)。最佳配置(Qwen3Guard+hyphenize)在SafeDialBench上达到93.8%攻击检测召回率，推理token减少94.6%(从3,231降至173)，相比基线提升38.9个百分点。

Conclusion: M2S压缩可作为护栏部署的有效效率技术，显著降低长多轮对话安全筛查的训练和推理成本，同时保持高性能。

Abstract: Guardrail models are essential for ensuring the safety of Large Language Model (LLM) deployments, but processing full multi-turn conversation histories incurs significant computational cost. We propose Defensive M2S, a training paradigm that fine-tunes guardrail models on Multi-turn to Single-turn (M2S) compressed conversations rather than complete dialogue histories. We provide a formal complexity analysis showing that M2S reduces training cost from $O(n^2)$ to $O(n)$ for $n$-turn conversations. Empirically, on our training dataset (779 samples, avg. 10.6 turns), M2S requires only 169K tokens compared to 15.7M tokens for the multi-turn baseline -- a 93$\times$ reduction. We evaluate Defensive M2S across three guardrail model families (LlamaGuard, Nemotron, Qwen3Guard) and three compression templates (hyphenize, numberize, pythonize) on SafeDialBench, a comprehensive multi-turn jailbreak benchmark. Our best configuration, Qwen3Guard with hyphenize compression, achieves 93.8% attack detection recall while reducing inference tokens by 94.6% (from 3,231 to 173 tokens per conversation). This represents a 38.9 percentage point improvement over the baseline while dramatically reducing both training and inference costs. Our findings demonstrate that M2S compression can serve as an effective efficiency technique for guardrail deployment, enabling scalable safety screening of long multi-turn conversations.

</details>


### [68] [Noise-Aware Named Entity Recognition for Historical VET Documents](https://arxiv.org/abs/2601.00488)
*Alexander M. Esser,Jens Dörpinghaus*

Main category: cs.CL

TL;DR: 提出一种针对职业教育培训领域历史数字化文档的鲁棒命名实体识别方法，通过噪声感知训练、合成OCR错误注入和迁移学习，在噪声条件下显著提升识别准确率


<details>
  <summary>Details</summary>
Motivation: 职业教育培训领域的历史数字化文档存在OCR噪声问题，传统NER方法在噪声条件下性能下降，需要开发鲁棒的NER方法以适应这一特定领域需求

Method: 采用噪声感知训练，通过合成注入OCR错误，结合迁移学习和多阶段微调策略，系统比较了噪声数据、干净数据和人工数据三种训练策略

Result: 实验结果表明，领域特定和噪声感知的微调显著提高了在噪声条件下的鲁棒性和准确性，能够识别VET文档中的多种实体类型

Conclusion: 该方法首次在VET文档中实现多类型实体识别，虽然应用于德语文档但可迁移到任意语言，提供了公开可用的代码用于领域特定噪声感知NER的可重复研究

Abstract: This paper addresses Named Entity Recognition (NER) in the domain of Vocational Education and Training (VET), focusing on historical, digitized documents that suffer from OCR-induced noise. We propose a robust NER approach leveraging Noise-Aware Training (NAT) with synthetically injected OCR errors, transfer learning, and multi-stage fine-tuning. Three complementary strategies, training on noisy, clean, and artificial data, are systematically compared. Our method is one of the first to recognize multiple entity types in VET documents. It is applied to German documents but transferable to arbitrary languages. Experimental results demonstrate that domain-specific and noise-aware fine-tuning substantially increases robustness and accuracy under noisy conditions. We provide publicly available code for reproducible noise-aware NER in domain-specific contexts.

</details>


### [69] [Rule-Based Approaches to Atomic Sentence Extraction](https://arxiv.org/abs/2601.00506)
*Lineesha Kamana,Akshita Ananda Subramanian,Mehuli Ghosh,Suman Saha*

Main category: cs.CL

TL;DR: 该研究分析了复杂句子结构如何影响基于规则的原子句子提取性能，识别了相对从句、同位语、并列谓语、状语从句和被动结构等具有挑战性的语法结构。


<details>
  <summary>Details</summary>
Motivation: 现有原子句子提取方法缺乏可解释性，无法揭示哪些具体语言结构导致提取失败。虽然已有研究探索基于依存关系的提取，但缺乏对特定从句结构和依存关系如何影响提取难度的系统性分析。

Method: 使用WikiSplit数据集，在spaCy中实现基于依存关系的提取规则，生成100个黄金标准原子句子集，并使用ROUGE和BERTScore评估性能。

Result: 系统达到ROUGE-1 F1=0.6714、ROUGE-2 F1=0.478、ROUGE-L F1=0.650、BERTScore F1=0.5898，表明具有中等至高水平的词汇、结构和语义对齐。挑战性结构包括相对从句、同位语、并列谓语、状语从句和被动结构。

Conclusion: 基于规则的原子句子提取具有合理准确性，但对句法复杂性敏感。研究为理解复杂句子结构如何影响提取性能提供了系统性分析框架。

Abstract: Natural language often combines multiple ideas into complex sentences. Atomic sentence extraction, the task of decomposing complex sentences into simpler sentences that each express a single idea, improves performance in information retrieval, question answering, and automated reasoning systems. Previous work has formalized the "split-and-rephrase" task and established evaluation metrics, and machine learning approaches using large language models have improved extraction accuracy. However, these methods lack interpretability and provide limited insight into which linguistic structures cause extraction failures. Although some studies have explored dependency-based extraction of subject-verb-object triples and clauses, no principled analysis has examined which specific clause structures and dependencies lead to extraction difficulties. This study addresses this gap by analyzing how complex sentence structures, including relative clauses, adverbial clauses, coordination patterns, and passive constructions, affect the performance of rule-based atomic sentence extraction. Using the WikiSplit dataset, we implemented dependency-based extraction rules in spaCy, generated 100 gold=standard atomic sentence sets, and evaluated performance using ROUGE and BERTScore. The system achieved ROUGE-1 F1 = 0.6714, ROUGE-2 F1 = 0.478, ROUGE-L F1 = 0.650, and BERTScore F1 = 0.5898, indicating moderate-to-high lexical, structural, and semantic alignment. Challenging structures included relative clauses, appositions, coordinated predicates, adverbial clauses, and passive constructions. Overall, rule-based extraction is reasonably accurate but sensitive to syntactic complexity.

</details>


### [70] [ECR: Manifold-Guided Semantic Cues for Compact Language Models](https://arxiv.org/abs/2601.00543)
*Chung-Wei Victor Yuan*

Main category: cs.CL

TL;DR: ECR框架通过语义锚点保持紧凑模型嵌入空间几何一致性，避免语义漂移，无需教师输出且兼容知识蒸馏。


<details>
  <summary>Details</summary>
Motivation: 紧凑模型在容量受限或多语言场景下容易丢失嵌入空间结构，导致语义漂移，现有压缩方法只对齐表层输出而忽略底层流形结构。

Method: 提出嵌入一致性调节(ECR)框架：从教师嵌入中离线计算语义锚点，让紧凑模型学习保持这些锚点周围的几何一致性，不依赖匹配logits或内部特征，推理时仅添加小型投影步骤。

Result: 在10万语料多语言实验中，ECR稳定训练并跨任务和语言保持语义结构，产生更紧凑且任务对齐的表示空间，使低容量模型学习到比传统基线更干净的流形。

Conclusion: ECR帮助紧凑模型更好地遵循任务要求，使其在严格效率或隐私限制下更易部署，无需教师输出且与蒸馏兼容但独立。

Abstract: Compact models often lose the structure of their embedding space. The issue shows up when the capacity is tight or the data spans several languages. Such collapse makes it difficult for downstream tasks to build on the resulting representation. Existing compression methods focus on aligning model outputs at a superficial level but fail to preserve the underlying manifold structure. This mismatch often leads to semantic drift in the compact model, causing both task behavior and linguistic properties to deviate from the reference model.
  To address those issues, we provide a new framework called Embedding Consistency Regulation (ECR). This framework first derives a set of semantic anchors from teacher embeddings (computed once offline). Then, the compact model learns to maintain consistent geometry around these anchors, without relying on matching logits or internal features. ECR adds only a small projection step at inference, without altering the decoding architecture or its runtime behavior.
  In experiments on a 100K multilingual corpus, ECR consistently stabilizes training and preserves semantic structure across tasks and languages. It also produces a more compact and task-aligned representation space, enabling low-capacity models to learn cleaner manifolds than conventional baselines. ECR works without teacher outputs and is compatible with, but independent of, distillation. Taken together, our results show that ECR helps compact models better follow task requirements and makes them easier to deploy under strict efficiency or privacy limits.

</details>


### [71] [A Language-Agnostic Hierarchical LoRA-MoE Architecture for CTC-based Multilingual ASR](https://arxiv.org/abs/2601.00557)
*Yuang Zheng,Yuxiang Mei,Dongxing Xu,Jie Chen,Yanhua Long*

Main category: cs.CL

TL;DR: 提出HLoRA框架，将分层LoRA-MoE集成到mHuBERT-CTC模型中，实现无需先验语言信息的轻量级语言无关多语言ASR系统


<details>
  <summary>Details</summary>
Motivation: 现有大规模多语言ASR模型（如Whisper）计算和延迟成本高，难以部署到资源受限的边缘设备上，需要开发轻量级且语言无关的解决方案

Method: 提出语言无关的分层LoRA-MoE（HLoRA）框架，集成到mHuBERT-CTC模型中。采用分层设计：多语言共享LoRA学习语言不变声学表示，语言特定LoRA专家建模语言相关特征。通过LID后验驱动的LoRA路由实现端到端解码，无需推理时的先验语言信息

Result: 在MSR-86K和MLC-SLM 2025挑战数据集上的实验表明，HLoRA仅使用单次解码就能达到与最先进两阶段推理方法相当的性能，显著提高了低资源多语言ASR应用的解码效率

Conclusion: HLoRA框架实现了轻量级、语言无关的多语言ASR系统，通过分层LoRA-MoE设计和LID后验驱动的路由机制，在保持性能的同时大幅降低计算和延迟成本，适合资源受限的边缘设备部署

Abstract: Large-scale multilingual ASR (mASR) models such as Whisper achieve strong performance but incur high computational and latency costs, limiting their deployment on resource-constrained edge devices. In this study, we propose a lightweight and language-agnostic multilingual ASR system based on a CTC architecture with domain adaptation. Specifically, we introduce a Language-agnostic Hierarchical LoRA-MoE (HLoRA) framework integrated into an mHuBERT-CTC model, enabling end-to-end decoding via LID-posterior-driven LoRA routing. The hierarchical design consists of a multilingual shared LoRA for learning language-invariant acoustic representations and language-specific LoRA experts for modeling language-dependent characteristics. The proposed routing mechanism removes the need for prior language identity information or explicit language labels during inference, achieving true language-agnostic decoding. Experiments on MSR-86K and the MLC-SLM 2025 Challenge datasets demonstrate that HLoRA achieves competitive performance with state-of-the-art two-stage inference methods using only single-pass decoding, significantly improving decoding efficiency for low-resource mASR applications.

</details>


### [72] [InfoSynth: Information-Guided Benchmark Synthesis for LLMs](https://arxiv.org/abs/2601.00575)
*Ishir Garg,Neel Kolhe,Xuandong Zhao,Dawn Song*

Main category: cs.CL

TL;DR: InfoSynth是一个基于信息论原理自动生成和评估推理基准的框架，使用KL散度和熵量化基准新颖性和多样性，通过遗传算法和迭代代码反馈从种子数据集合成Python编程问题。


<details>
  <summary>Details</summary>
Motivation: 传统基准创建依赖人工，成本高且耗时；现有基准常污染LLM训练数据，需要新颖多样的基准来准确评估LLM的真实能力。

Method: 提出基于KL散度和熵的指标量化基准新颖性和多样性；开发端到端流水线，使用遗传算法和迭代代码反馈从种子数据集合成Python编程问题。

Result: 97%的时间能准确生成新问题的测试用例和解决方案；合成的基准相比种子数据集具有更高的新颖性和多样性；算法能控制生成问题的新颖性/多样性和难度。

Conclusion: InfoSynth提供了一个可扩展、自验证的流水线，用于为LLM构建高质量、新颖且多样的基准，解决了传统基准创建的局限性。

Abstract: Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive and time-consuming. Furthermore, existing benchmarks often contaminate LLM training data, necessitating novel and diverse benchmarks to accurately assess their genuine capabilities. This work introduces InfoSynth, a novel framework for automatically generating and evaluating reasoning benchmarks guided by information-theoretic principles. We propose metrics based on KL-divergence and entropy to quantify benchmark novelty and diversity without relying on costly model evaluations. Building on this framework, we develop an end-to-end pipeline that synthesizes robust Python coding problems from seed datasets using genetic algorithms and iterative code feedback. Our method generates accurate test cases and solutions to new problems 97% of the time, and the synthesized benchmarks consistently exhibit higher novelty and diversity compared to their seed datasets. Moreover, our algorithm provides a method for controlling the novelty/diversity and difficulty of generated problems. InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs. Project Page: https://ishirgarg.github.io/infosynth_web/

</details>


### [73] [CSSBench: Evaluating the Safety of Lightweight LLMs against Chinese-Specific Adversarial Patterns](https://arxiv.org/abs/2601.00588)
*Zhenhong Zhou,Shilinlu Yan,Chuanpu Liu,Qiankun Li,Kun Wang,Zhigang Zeng*

Main category: cs.CL

TL;DR: CSSBench是一个专门针对中文特定对抗模式的安全基准测试，用于评估轻量级大语言模型在中文环境下的安全性，填补了现有基准测试主要关注英文的空白。


<details>
  <summary>Details</summary>
Motivation: 大语言模型越来越多地部署在成本敏感和设备端场景中，但现有的安全防护主要针对英文。中文恶意查询通常通过同音字、拼音、符号分割等中文特定模式隐藏意图，这些对抗模式造成了现有基准测试未能很好捕捉的安全评估差距，特别是对于可能更脆弱的轻量级模型。

Method: 引入中文特定安全基准测试(CSSBench)，强调中文对抗模式，包括同音字、拼音、符号分割等。基准涵盖六个常见中文场景领域：非法活动与合规、隐私泄露、健康与医疗错误信息、欺诈与仇恨、成人内容、公共与政治安全，并将查询组织成多种任务类型。评估流行轻量级大语言模型，并测量过度拒绝行为以评估安全引起的性能下降。

Result: 评估结果显示，中文特定对抗模式对轻量级大语言模型构成了关键挑战。基准测试提供了对LLM在中文环境下安全性的全面评估。

Conclusion: CSSBench填补了中文特定对抗模式安全评估的空白，为轻量级大语言模型在中文环境下的安全部署提供了重要评估工具，有助于实际应用中的稳健部署。

Abstract: Large language models (LLMs) are increasingly deployed in cost-sensitive and on-device scenarios, and safety guardrails have advanced mainly in English. However, real-world Chinese malicious queries typically conceal intent via homophones, pinyin, symbol-based splitting, and other Chinese-specific patterns. These Chinese-specific adversarial patterns create the safety evaluation gap that is not well captured by existing benchmarks focused on English. This gap is particularly concerning for lightweight models, which may be more vulnerable to such specific adversarial perturbations. To bridge this gap, we introduce the Chinese-Specific Safety Benchmark (CSSBench) that emphasizes these adversarial patterns and evaluates the safety of lightweight LLMs in Chinese. Our benchmark covers six domains that are common in real Chinese scenarios, including illegal activities and compliance, privacy leakage, health and medical misinformation, fraud and hate, adult content, and public and political safety, and organizes queries into multiple task types. We evaluate a set of popular lightweight LLMs and measure over-refusal behavior to assess safety-induced performance degradation. Our results show that the Chinese-specific adversarial pattern is a critical challenge for lightweight LLMs. This benchmark offers a comprehensive evaluation of LLM safety in Chinese, assisting robust deployments in practice.

</details>


### [74] [Probabilistic Guarantees for Reducing Contextual Hallucinations in LLMs](https://arxiv.org/abs/2601.00641)
*Nils Rautenberg,Sven Schippkus*

Main category: cs.CL

TL;DR: 提出一个模型无关的框架，通过重复采样和多数投票机制，为确定性自动化工作流中的LLM幻觉提供概率保证


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在确定性自动化工作流中经常产生上下文幻觉，其中生成内容与提示中明确信息相矛盾或忽略这些信息。这些错误在输入固定且正确性明确的工作流中尤为严重，需要一种轻量级、模块化的解决方案来降低幻觉概率。

Method: 提出一个模型无关框架：1) 在独立上下文窗口中重复相同提示，利用指数级降低所有输出都错误的概率；2) 引入LLM作为评判器识别正确答案；3) 当评判器不完美时，通过多数投票机制增强评判器，获得指数级降低的集成错误率。

Result: 在受控提取任务上的实验验证了理论预测：1) 管道失败概率随重复次数指数下降；2) 幻觉选择概率随评判器集成规模指数下降。这些结果与理论分析完全匹配。

Conclusion: 该框架提供了一种轻量级、模块化且理论可靠的方法，可在不修改模型权重、解码策略或提示工程的情况下，将固定输入LLM工作流中的幻觉概率降至任意低水平。

Abstract: Large language models (LLMs) frequently produce contextual hallucinations, where generated content contradicts or ignores information explicitly stated in the prompt. Such errors are particularly problematic in deterministic automation workflows, where inputs are fixed and correctness is unambiguous. We introduce a simple and model-agnostic framework that provides explicit probabilistic guarantees for reducing hallucinations in this setting.
  We formalize the notion of a specific task, defined by a fixed input and a deterministic correctness criterion, and show that issuing the same prompt in independent context windows yields an exponential reduction in the probability that all model outputs are incorrect. To identify a correct answer among repeated runs, we incorporate an LLM-as-a-judge and prove that the probability that the judged pipeline fails decays at a rate determined by the judge's true- and false-positive probabilities. When the judge is imperfect, we strengthen it through majority vote over independent judge calls, obtaining ensemble-level error rates that decrease exponentially in the number of votes. This yields an explicit bound on the probability that the pipeline selects a hallucinated answer.
  Experiments on controlled extraction tasks with synthetic noisy judges match these predictions exactly: pipeline failure decreases exponentially with the number of repetitions, and hallucination-selection decreases exponentially with the number of judges in the ensemble. Together, these results provide a lightweight, modular, and theoretically grounded method for driving hallucination probabilities arbitrarily low in fixed-input LLM workflows-without modifying model weights, decoding strategies, or prompt engineering.

</details>


### [75] [Fast-weight Product Key Memory](https://arxiv.org/abs/2601.00671)
*Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: FwPKM是一种新型架构，将稀疏产品键内存从静态模块转变为动态的"快速权重"情景记忆，通过局部块级梯度下降动态更新参数，解决了存储容量与计算效率之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型中的序列建模层面临存储容量与计算效率之间的权衡：Softmax注意力提供无限存储但计算成本二次方增长，线性变体计算高效但存储有限且固定。需要一种既能提供大容量存储又保持计算效率的解决方案。

Method: 提出快速权重产品键内存（FwPKM），将稀疏产品键内存从静态模块转变为动态的情景记忆。FwPKM在训练和推理时通过局部块级梯度下降动态更新参数，能够快速记忆和检索输入序列中的新键值对。

Result: FwPKM作为有效的情景记忆，补充了标准模块的语义记忆，在长上下文数据集上显著降低了困惑度。在"大海捞针"评估中，尽管仅在4K标记序列上训练，FwPKM能够泛化到128K标记的上下文。

Conclusion: FwPKM成功解决了序列建模中存储容量与计算效率的权衡问题，通过动态更新的情景记忆机制实现了高效的长上下文处理能力，为语言模型架构提供了新的设计思路。

Abstract: Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, "fast-weight" episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.

</details>


### [76] [Sigmoid Head for Quality Estimation under Language Ambiguity](https://arxiv.org/abs/2601.00680)
*Tu Anh Dinh,Jan Niehues*

Main category: cs.CL

TL;DR: 提出Sigmoid Head模块解决语言模型概率作为质量估计器不可靠的问题，通过sigmoid激活和负采样策略提升质量信号


<details>
  <summary>Details</summary>
Motivation: 语言模型的概率分布不能可靠地估计输出质量，因为自然语言具有歧义性。当存在多个有效输出选项时，模型的概率分布会分散到这些选项上，从而误导性地指示低输出质量。这主要由两个原因造成：(1) 语言模型的最终输出激活使用softmax，不允许多个正确选项同时获得高概率；(2) 语言模型的训练数据是单一、one-hot编码的参考，暗示每个输出步骤只有一个正确选项。

Method: 在预训练语言模型之上训练一个质量估计模块，称为Sigmoid Head。该模块是一个额外的unembedding head，使用sigmoid激活来解决第一个限制。针对第二个限制，在训练Sigmoid Head的负采样过程中，使用启发式方法避免选择可能正确的替代标记。该方法在训练和推理过程中计算效率高。

Result: Sigmoid Head产生的概率相比原始softmax head是显著更好的质量信号。由于Sigmoid Head不依赖人工标注的质量数据，相比监督式质量估计，它在领域外设置中更加鲁棒。

Conclusion: 提出的Sigmoid Head方法有效解决了语言模型概率作为质量估计器的局限性，通过sigmoid激活和负采样策略提供了更可靠的质量信号，且在计算效率和领域外鲁棒性方面具有优势。

Abstract: Language model (LM) probability is not a reliable quality estimator, as natural language is ambiguous. When multiple output options are valid, the model's probability distribution is spread across them, which can misleadingly indicate low output quality. This issue is caused by two reasons: (1) LMs' final output activation is softmax, which does not allow multiple correct options to receive high probabilities simultaneuously and (2) LMs' training data is single, one-hot encoded references, indicating that there is only one correct option at each output step. We propose training a module for Quality Estimation on top of pre-trained LMs to address these limitations. The module, called Sigmoid Head, is an extra unembedding head with sigmoid activation to tackle the first limitation. To tackle the second limitation, during the negative sampling process to train the Sigmoid Head, we use a heuristic to avoid selecting potentially alternative correct tokens. Our Sigmoid Head is computationally efficient during training and inference. The probability from Sigmoid Head is notably better quality signal compared to the original softmax head. As the Sigmoid Head does not rely on human-annotated quality data, it is more robust to out-of-domain settings compared to supervised QE.

</details>


### [77] [Exploring the Performance of Large Language Models on Subjective Span Identification Tasks](https://arxiv.org/abs/2601.00736)
*Alphaeus Dmonte,Roland Oruche,Tharindu Ranasinghe,Marcos Zampieri,Prasad Calyam*

Main category: cs.CL

TL;DR: 评估大型语言模型在文本跨度识别任务中的表现，特别是在情感分析、冒犯性语言识别和声明验证等主观性任务中


<details>
  <summary>Details</summary>
Motivation: 当前大多数跨度识别方法依赖BERT等较小的预训练模型，而大型语言模型在这方面的应用相对较少。特别是在主观性跨度识别任务（如基于方面的情感分析）中，LLMs的应用尚未充分探索。本文旨在填补这一重要空白。

Method: 在三个流行任务（情感分析、冒犯性语言识别和声明验证）中评估各种LLMs的文本跨度识别性能。探索了指令调优、上下文学习和思维链等多种LLM策略。

Result: 结果表明，文本中的潜在关系有助于LLMs识别精确的文本跨度。LLMs在主观性跨度识别任务中表现出色，特别是在理解文本内部关系方面具有优势。

Conclusion: LLMs在文本跨度识别任务中具有重要价值，特别是在需要理解文本内部关系的复杂任务中。这项工作为LLMs在主观性跨度识别任务中的应用提供了重要见解。

Abstract: Identifying relevant text spans is important for several downstream tasks in NLP, as it contributes to model explainability. While most span identification approaches rely on relatively smaller pre-trained language models like BERT, a few recent approaches have leveraged the latest generation of Large Language Models (LLMs) for the task. Current work has focused on explicit span identification like Named Entity Recognition (NER), while more subjective span identification with LLMs in tasks like Aspect-based Sentiment Analysis (ABSA) has been underexplored. In this paper, we fill this important gap by presenting an evaluation of the performance of various LLMs on text span identification in three popular tasks, namely sentiment analysis, offensive language identification, and claim verification. We explore several LLM strategies like instruction tuning, in-context learning, and chain of thought. Our results indicate underlying relationships within text aid LLMs in identifying precise text spans.

</details>


### [78] [Adapting Natural Language Processing Models Across Jurisdictions: A pilot Study in Canadian Cancer Registries](https://arxiv.org/abs/2601.00787)
*Jonathan Simkin,Lovedeep Gondara,Zeeshan Rizvi,Gregory Doyle,Jeff Dowden,Dan Bond,Desmond Martin,Raymond Ng*

Main category: cs.CL

TL;DR: 本研究评估了跨省适应癌症注册NLP模型的可行性，通过将不列颠哥伦比亚省开发的BCCRTron模型与GatorTron模型在新斯科舍省癌症注册数据上微调，并使用集成方法显著减少了漏诊癌症数量。


<details>
  <summary>Details</summary>
Motivation: 基于人群的癌症注册依赖病理报告作为主要诊断来源，但人工提取资源密集且导致数据延迟。现有基于transformer的NLP系统在跨司法管辖区（具有不同报告惯例）的泛化能力尚不清楚，需要评估模型跨省适应的可行性。

Method: 采用跨省评估方法，将BCCRTron（不列颠哥伦比亚省癌症注册开发的领域适应transformer模型）与GatorTron（生物医学transformer模型）适应到加拿大新斯科舍省癌症注册。使用约104,000份（Tier 1：癌症vs非癌症）和22,000份（Tier 2：可报告vs不可报告）去标识化病理报告进行微调，采用互补的摘要和诊断聚焦报告部分输入管道，并通过保守OR集成结合两个模型。

Result: 适应后的模型在新斯科舍省测试集上保持高性能，表明在一个司法管辖区预训练的transformer可以通过适度微调本地化到另一个管辖区。集成方法显著提升性能：Tier 1任务召回率达到0.99，漏诊癌症减少至24例（单独模型分别为48和54例）；Tier 2任务召回率0.99，漏诊可报告癌症减少至33例（单独模型分别为54和46例）。

Conclusion: 结合互补文本表示的集成方法可显著减少癌症注册NLP中的漏诊癌症并提高错误覆盖率。研究实现了隐私保护工作流程（仅共享模型权重），支持可互操作的NLP基础设施，为未来泛加拿大癌症病理和注册工作流程的基础模型奠定基础。

Abstract: Population-based cancer registries depend on pathology reports as their primary diagnostic source, yet manual abstraction is resource-intensive and contributes to delays in cancer data. While transformer-based NLP systems have improved registry workflows, their ability to generalize across jurisdictions with differing reporting conventions remains poorly understood. We present the first cross-provincial evaluation of adapting BCCRTron, a domain-adapted transformer model developed at the British Columbia Cancer Registry, alongside GatorTron, a biomedical transformer model, for cancer surveillance in Canada. Our training dataset consisted of approximately 104,000 and 22,000 de-identified pathology reports from the Newfoundland & Labrador Cancer Registry (NLCR) for Tier 1 (cancer vs. non-cancer) and Tier 2 (reportable vs. non-reportable) tasks, respectively. Both models were fine-tuned using complementary synoptic and diagnosis focused report section input pipelines. Across NLCR test sets, the adapted models maintained high performance, demonstrating transformers pretrained in one jurisdiction can be localized to another with modest fine-tuning. To improve sensitivity, we combined the two models using a conservative OR-ensemble achieving a Tier 1 recall of 0.99 and reduced missed cancers to 24, compared with 48 and 54 for the standalone models. For Tier 2, the ensemble achieved 0.99 recall and reduced missed reportable cancers to 33, compared with 54 and 46 for the individual models. These findings demonstrate that an ensemble combining complementary text representations substantially reduce missed cancers and improve error coverage in cancer-registry NLP. We implement a privacy-preserving workflow in which only model weights are shared between provinces, supporting interoperable NLP infrastructure and a future pan-Canadian foundation model for cancer pathology and registry workflows.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [79] [Evaluating Anomaly Detectors for Simulated Highly Imbalanced Industrial Classification Problems](https://arxiv.org/abs/2601.00005)
*Lesley Wheat,Martin v. Mohrenschildt,Saeid Habibi*

Main category: cs.LG

TL;DR: 该论文对工业异常检测算法进行了全面评估，使用模拟数据集测试了14种检测器在不同异常率和训练规模下的性能，发现最佳检测器选择取决于训练数据中故障样本的总数。


<details>
  <summary>Details</summary>
Motivation: 机器学习在工业系统（如质量控制和预测性维护）中具有应用潜力，但面临极端类别不平衡的挑战，主要由于训练过程中故障数据的可用性有限。需要评估异常检测算法在反映真实工程约束条件下的性能。

Method: 使用问题无关的模拟数据集，包含基于超球面分布的2D和10D异常数据。在异常率0.05%到20%、训练规模1,000到10,000（测试集40,000）的条件下，对14种检测器进行基准测试，评估性能和泛化误差。

Result: 最佳检测器高度依赖于训练数据集中故障样本的总数：故障样本少于20个时，无监督方法（kNN/LOF）占优；故障样本约30-50个时，半监督（XGBOD）和监督（SVM/CatBoost）方法性能显著提升。半监督方法在10个特征时显示出优势，但在2个特征时优势不明显。研究还揭示了小数据集上异常检测方法的泛化性能下降。

Conclusion: 研究为工业环境中部署异常检测提供了实用见解：检测器选择应基于可用故障样本数量，而非单纯异常率；无监督方法在故障样本极少时有效，而监督/半监督方法在故障样本达到一定数量后性能更优。特征维度影响方法选择，半监督方法在高维特征中优势更明显。

Abstract: Machine learning offers potential solutions to current issues in industrial systems in areas such as quality control and predictive maintenance, but also faces unique barriers in industrial applications. An ongoing challenge is extreme class imbalance, primarily due to the limited availability of faulty data during training. This paper presents a comprehensive evaluation of anomaly detection algorithms using a problem-agnostic simulated dataset that reflects real-world engineering constraints. Using a synthetic dataset with a hyper-spherical based anomaly distribution in 2D and 10D, we benchmark 14 detectors across training datasets with anomaly rates between 0.05% and 20% and training sizes between 1 000 and 10 000 (with a testing dataset size of 40 000) to assess performance and generalization error. Our findings reveal that the best detector is highly dependant on the total number of faulty examples in the training dataset, with additional healthy examples offering insignificant benefits in most cases. With less than 20 faulty examples, unsupervised methods (kNN/LOF) dominate; but around 30-50 faulty examples, semi-supervised (XGBOD) and supervised (SVM/CatBoost) detectors, we see large performance increases. While semi-supervised methods do not show significant benefits with only two features, the improvements are evident at ten features. The study highlights the performance drop on generalization of anomaly detection methods on smaller datasets, and provides practical insights for deploying anomaly detection in industrial environments.

</details>


### [80] [Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation](https://arxiv.org/abs/2601.00664)
*Taekyung Ki,Sangwon Jang,Jaehyeong Jo,Jaehong Yoon,Sung Ju Hwang*

Main category: cs.LG

TL;DR: 提出Avatar Forcing框架，通过扩散强迫建模实时用户-虚拟化身交互，实现低延迟（约500ms）的互动式头像生成，比基线快6.8倍，并引入无标签偏好优化学习表达性互动。


<details>
  <summary>Details</summary>
Motivation: 当前虚拟化身生成模型缺乏真正的互动感，主要生成单向响应而缺乏情感参与。为实现真正的交互式虚拟化身，需要解决两个关键挑战：在因果约束下实时生成动作，以及在没有额外标注数据的情况下学习表达性、生动的反应。

Method: 提出Avatar Forcing框架，通过扩散强迫建模实时用户-虚拟化身交互，处理包括用户音频和动作在内的多模态输入。引入直接偏好优化方法，利用通过丢弃用户条件构建的合成负样本，实现无标签的表达性互动学习。

Result: 框架实现低延迟（约500ms）实时交互，比基线快6.8倍。生成的虚拟化身动作具有反应性和表达性，在超过80%的情况下优于基线。

Conclusion: Avatar Forcing框架成功解决了交互式虚拟化身生成的两个关键挑战，实现了实时、低延迟的互动，并通过无标签偏好优化学习表达性反应，为真正交互式虚拟通信提供了有效解决方案。

Abstract: Talking head generation creates lifelike avatars from static portraits for virtual communication and content creation. However, current models do not yet convey the feeling of truly interactive communication, often generating one-way responses that lack emotional engagement. We identify two key challenges toward truly interactive avatars: generating motion in real-time under causal constraints and learning expressive, vibrant reactions without additional labeled data. To address these challenges, we propose Avatar Forcing, a new framework for interactive head avatar generation that models real-time user-avatar interactions through diffusion forcing. This design allows the avatar to process real-time multimodal inputs, including the user's audio and motion, with low latency for instant reactions to both verbal and non-verbal cues such as speech, nods, and laughter. Furthermore, we introduce a direct preference optimization method that leverages synthetic losing samples constructed by dropping user conditions, enabling label-free learning of expressive interaction. Experimental results demonstrate that our framework enables real-time interaction with low latency (approximately 500ms), achieving 6.8X speedup compared to the baseline, and produces reactive and expressive avatar motion, which is preferred over 80% against the baseline.

</details>


### [81] [The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition](https://arxiv.org/abs/2601.00065)
*Xiaoze Liu,Weichen Yu,Matt Fredrikson,Xiaoqian Wang,Jing Gao*

Main category: cs.LG

TL;DR: 论文提出了一种针对LLM组合技术的供应链攻击方法，通过设计单个"破坏令牌"在捐赠模型中功能惰性，但在移植到基础模型后可靠地重构为高显著性恶意特征，破坏基础模型的生成能力。


<details>
  <summary>Details</summary>
Motivation: 随着开源权重LLM生态系统中模型组合技术（如权重合并、推测解码、词汇表扩展）的普及，不同模型家族间的令牌移植成为关键前提。然而，这种必要的互操作性步骤可能引入供应链漏洞，但目前缺乏对此类风险的系统研究。

Method: 1. 形式化为双目标优化问题：既要使令牌在捐赠模型中功能惰性，又要在移植到基础模型后可靠重构为恶意特征；2. 利用系数重用的几何特性，创造不对称可实现性差距；3. 使用稀疏求解器实例化攻击；4. 通过谱模仿规避异常检测。

Result: 攻击无需训练，成功实现：1. 在捐赠模型中统计行为与正常行为无法区分；2. 在基础模型中可靠重构为恶意特征并破坏生成；3. 通过谱模仿规避异常检测；4. 对抗微调和权重合并具有结构持久性。

Conclusion: 令牌移植这一关键互操作性步骤引入了供应链漏洞，攻击者可通过工程化"破坏令牌"在模型组合管道中植入隐藏风险。这凸显了模块化AI组合流程中存在的安全隐患，需要更严格的供应链安全措施。

Abstract: The open-weight LLM ecosystem is increasingly defined by model composition techniques (such as weight merging, speculative decoding, and vocabulary expansion) that remix capabilities from diverse sources. A critical prerequisite for applying these methods across different model families is tokenizer transplant, which aligns incompatible vocabularies to a shared embedding space. We demonstrate that this essential interoperability step introduces a supply-chain vulnerability: we engineer a single "breaker token" that is functionally inert in a donor model yet reliably reconstructs into a high-salience malicious feature after transplant into a base model. By exploiting the geometry of coefficient reuse, our attack creates an asymmetric realizability gap that sabotages the base model's generation while leaving the donor's utility statistically indistinguishable from nominal behavior. We formalize this as a dual-objective optimization problem and instantiate the attack using a sparse solver. Empirically, the attack is training-free and achieves spectral mimicry to evade outlier detection, while demonstrating structural persistence against fine-tuning and weight merging, highlighting a hidden risk in the pipeline of modular AI composition. Code is available at https://github.com/xz-liu/tokenforge

</details>


### [82] [Exploration in the Limit](https://arxiv.org/abs/2601.00084)
*Brian M. Cho,Nathan Kallus*

Main category: cs.LG

TL;DR: 提出一种渐近误差控制的BAI新框架，通过放松严格误差要求实现更优样本复杂度，支持非参数分布和协变量利用


<details>
  <summary>Details</summary>
Motivation: 现有BAI方法在实用场景中表现不佳，严格的精确误差控制需要使用宽松的尾部不等式和/或参数限制，无法有效处理弱信号、高显著性要求和实验后推断需求等现实问题

Method: 引入渐近误差控制框架，要求误差控制相对于最小样本量渐近有效；开发新颖的渐近任意时间有效置信序列，并设计新的BAI算法；灵活纳入协变量进行方差缩减，确保完全非参数设置下的近似误差控制

Result: 在温和收敛假设下提供样本复杂度的渐近界限，最坏情况样本复杂度与高斯BAI在精确误差保证和已知方差下的最佳情况样本复杂度匹配；实验表明方法在保持误差控制的同时减少了平均样本复杂度

Conclusion: 提出的渐近框架克服了传统BAI方法的局限性，实现了更紧的最优性，更好地处理灵活的非参数结果分布，并充分利用个体级上下文，为实际应用提供了更实用的解决方案

Abstract: In fixed-confidence best arm identification (BAI), the objective is to quickly identify the optimal option while controlling the probability of error below a desired threshold. Despite the plethora of BAI algorithms, existing methods typically fall short in practical settings, as stringent exact error control requires using loose tail inequalities and/or parametric restrictions. To overcome these limitations, we introduce a relaxed formulation that requires valid error control asymptotically with respect to a minimum sample size. This aligns with many real-world settings that often involve weak signals, high desired significance, and post-experiment inference requirements, all of which necessitate long horizons. This allows us to achieve tighter optimality, while better handling flexible nonparametric outcome distributions and fully leveraging individual-level contexts. We develop a novel asymptotic anytime-valid confidence sequences over arm indices, and we use it to design a new BAI algorithm for our asymptotic framework. Our method flexibly incorporates covariates for variance reduction and ensures approximate error control in fully nonparametric settings. Under mild convergence assumptions, we provide asymptotic bounds on the sample complexity and show the worst-case sample complexity of our approach matches the best-case sample complexity of Gaussian BAI under exact error guarantees and known variances. Experiments suggest our approach reduces average sample complexities while maintaining error control.

</details>


### [83] [Dynamic Bayesian Optimization Framework for Instruction Tuning in Partial Differential Equation Discovery](https://arxiv.org/abs/2601.00088)
*Junqi Qu,Yan Zhang,Shangqian Gao,Shibo Li*

Main category: cs.LG

TL;DR: NeuroSymBO：将提示工程重构为序列决策问题，通过贝叶斯优化自适应选择指令，解决LLM方程发现中的指令脆弱性问题


<details>
  <summary>Details</summary>
Motivation: 大语言模型在方程发现中表现出潜力，但其输出对提示措辞高度敏感（指令脆弱性）。静态提示无法适应多步生成过程的演化状态，导致模型陷入次优解。

Method: 提出NeuroSymBO方法：1) 将提示工程重构为序列决策问题；2) 维护离散的推理策略库；3) 使用贝叶斯优化基于数值反馈在每一步选择最优指令。

Result: 在PDE发现基准测试中，自适应指令选择显著优于固定提示，实现了更高的恢复率和更简洁的解决方案。

Conclusion: 自适应指令选择是解决LLM方程发现中指令脆弱性的有效方法，能够提升模型性能并生成更简洁的解决方案。

Abstract: Large Language Models (LLMs) show promise for equation discovery, yet their outputs are highly sensitive to prompt phrasing, a phenomenon we term instruction brittleness. Static prompts cannot adapt to the evolving state of a multi-step generation process, causing models to plateau at suboptimal solutions. To address this, we propose NeuroSymBO, which reframes prompt engineering as a sequential decision problem. Our method maintains a discrete library of reasoning strategies and uses Bayesian Optimization to select the optimal instruction at each step based on numerical feedback. Experiments on PDE discovery benchmarks show that adaptive instruction selection significantly outperforms fixed prompts, achieving higher recovery rates with more parsimonious solutions.

</details>


### [84] [GRL-SNAM: Geometric Reinforcement Learning with Path Differential Hamiltonians for Simultaneous Navigation and Mapping in Unknown Environments](https://arxiv.org/abs/2601.00116)
*Aditya Sai Ellendula,Yi Wang,Minh Nguyen,Chandrajit Bajaj*

Main category: cs.LG

TL;DR: GRL-SNAM是一种基于几何强化学习的框架，用于在未知环境中进行同步导航与建图，通过哈密顿优化实现动态最短路径搜索，仅依赖局部感知而非全局地图。


<details>
  <summary>Details</summary>
Motivation: 解决未知环境中的同步导航与建图问题具有挑战性，传统方法需要构建全局地图或设计复杂的多智能体策略。本文旨在开发一种仅依赖局部感知观测、无需构建全局地图的导航框架。

Method: 将路径导航和建图建模为动态最短路径搜索与发现过程，采用受控哈密顿优化：将传感器输入转换为局部能量景观，编码可达性、障碍物屏障和变形约束；感知、规划和重构策略通过更新哈密顿量分阶段演化。简化哈密顿量作为自适应评分函数，更新动能/势能项、嵌入屏障约束，并在新局部信息到达时持续优化轨迹。

Result: 在两种不同的2D导航任务上评估GRL-SNAM，与局部反应式基线和全局策略学习参考方法比较。在相同的分阶段感知约束下，该方法保持了安全距离，能够泛化到未见过的布局，并证明通过局部能量优化而非广泛全局建图的几何强化学习能够实现高质量导航。

Conclusion: GRL-SNAM通过哈密顿量更新的几何强化学习框架，实现了仅依赖局部感知的同步导航与建图，避免了全局地图构建的需求，在未知环境中表现出良好的导航性能和泛化能力。

Abstract: We present GRL-SNAM, a geometric reinforcement learning framework for Simultaneous Navigation and Mapping(SNAM) in unknown environments. A SNAM problem is challenging as it needs to design hierarchical or joint policies of multiple agents that control the movement of a real-life robot towards the goal in mapless environment, i.e. an environment where the map of the environment is not available apriori, and needs to be acquired through sensors. The sensors are invoked from the path learner, i.e. navigator, through active query responses to sensory agents, and along the motion path. GRL-SNAM differs from preemptive navigation algorithms and other reinforcement learning methods by relying exclusively on local sensory observations without constructing a global map. Our approach formulates path navigation and mapping as a dynamic shortest path search and discovery process using controlled Hamiltonian optimization: sensory inputs are translated into local energy landscapes that encode reachability, obstacle barriers, and deformation constraints, while policies for sensing, planning, and reconfiguration evolve stagewise via updating Hamiltonians. A reduced Hamiltonian serves as an adaptive score function, updating kinetic/potential terms, embedding barrier constraints, and continuously refining trajectories as new local information arrives. We evaluate GRL-SNAM on two different 2D navigation tasks. Comparing against local reactive baselines and global policy learning references under identical stagewise sensing constraints, it preserves clearance, generalizes to unseen layouts, and demonstrates that Geometric RL learning via updating Hamiltonians enables high-quality navigation through minimal exploration via local energy refinement rather than extensive global mapping. The code is publicly available on \href{https://github.com/CVC-Lab/GRL-SNAM}{Github}.

</details>


### [85] [Reinforcement Learning with Function Approximation for Non-Markov Processes](https://arxiv.org/abs/2601.00151)
*Ali Devran Kara*

Main category: cs.LG

TL;DR: 该论文研究了非马尔可夫状态和成本过程下带线性函数逼近的强化学习方法，包括策略评估和Q学习，证明了在遍历性条件下的收敛性，并将结果应用于部分可观测马尔可夫决策过程。


<details>
  <summary>Details</summary>
Motivation: 研究非马尔可夫环境下的强化学习问题，因为实际应用中状态和成本过程往往不满足马尔可夫性，需要开发适用于非马尔可夫过程的收敛性理论。

Method: 1) 分析非马尔可夫过程下的策略评估方法，证明在遍历性条件下的收敛性；2) 研究带线性函数逼近的Q学习，针对基于量化映射的基函数证明收敛性；3) 将结果应用于部分可观测马尔可夫决策过程，使用有限记忆变量作为状态表示。

Result: 1) 策略评估算法在遍历性条件下收敛，极限点对应于正交投影与辅助马尔可夫决策过程贝尔曼算符联合算子的不动点；2) 对于基于量化映射基函数的Q学习，在类似遍历性条件下可证明收敛；3) 应用于POMDPs时，推导了学习算法极限的显式误差界。

Conclusion: 该工作为非马尔可夫环境下的强化学习提供了理论保证，证明了在适当遍历性条件下带线性函数逼近的强化学习方法的收敛性，并将理论框架成功应用于部分可观测马尔可夫决策过程。

Abstract: We study reinforcement learning methods with linear function approximation under non-Markov state and cost processes. We first consider the policy evaluation method and show that the algorithm converges under suitable ergodicity conditions on the underlying non-Markov processes. Furthermore, we show that the limit corresponds to the fixed point of a joint operator composed of an orthogonal projection and the Bellman operator of an auxiliary \emph{Markov} decision process.
  For Q-learning with linear function approximation, as in the Markov setting, convergence is not guaranteed in general. We show, however, that for the special case where the basis functions are chosen based on quantization maps, the convergence can be shown under similar ergodicity conditions. Finally, we apply our results to partially observed Markov decision processes, where finite-memory variables are used as state representations, and we derive explicit error bounds for the limits of the resulting learning algorithms.

</details>


### [86] [The Weather Paradox: Why Precipitation Fails to Predict Traffic Accident Severity in Large-Scale US Data](https://arxiv.org/abs/2601.00152)
*Yann Bellec,Rohan Kaman,Siwen Cui,Aarav Agrawal,Calvin Chen*

Main category: cs.LG

TL;DR: 本研究使用XGBoost模型分析美国交通事故严重程度的预测因素，发现时间、地理位置和天气变量是最强预测因子，但模型对极端严重程度案例的预测能力有限。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索环境、时间和空间因素对美国交通事故严重程度的预测能力，为基于证据的交通管理提供支持，并识别影响事故严重程度的关键因素。

Method: 使用2016-2023年50万起美国交通事故数据集，训练XGBoost分类器，通过随机搜索交叉验证进行优化，并采用类别加权处理类别不平衡问题。

Result: 最终模型整体准确率达到78%，对多数类别（严重程度2）的精确率和召回率达到87%。特征重要性分析显示时间、地理位置、能见度、温度和风速是最强预测因子，但降水和能见度的预测能力有限。

Conclusion: 研究证实了环境、时间和空间因素对事故严重程度的预测价值，但数据集以中等严重程度事故为主限制了模型对极端案例的学习能力，需要改进采样策略、特征工程和外部数据集整合。

Abstract: This study investigates the predictive capacity of environmental, temporal, and spatial factors on traffic accident severity in the United States. Using a dataset of 500,000 U.S. traffic accidents spanning 2016-2023, we trained an XGBoost classifier optimized through randomized search cross-validation and adjusted for class imbalance via class weighting. The final model achieves an overall accuracy of 78%, with strong performance on the majority class (Severity 2), attaining 87% precision and recall. Feature importance analysis reveals that time of day, geographic location, and weather-related variables, including visibility, temperature, and wind speed, rank among the strongest predictors of accident severity. However, contrary to initial hypotheses, precipitation and visibility demonstrate limited predictive power, potentially reflecting behavioral adaptation by drivers under overtly hazardous conditions. The dataset's predominance of mid-level severity accidents constrains the model's capacity to learn meaningful patterns for extreme cases, highlighting the need for alternative sampling strategies, enhanced feature engineering, and integration of external datasets. These findings contribute to evidence-based traffic management and suggest future directions for severity prediction research.

</details>


### [87] [Online Finetuning Decision Transformers with Pure RL Gradients](https://arxiv.org/abs/2601.00167)
*Junkai Luo,Yinglun Zhu*

Main category: cs.LG

TL;DR: 本文提出了一种使用纯强化学习梯度进行Decision Transformers在线微调的新方法，解决了现有方法依赖监督学习目标的问题，通过改进GRPO算法实现了更优的性能。


<details>
  <summary>Details</summary>
Motivation: 虽然Decision Transformers在离线强化学习中表现出色，但将其扩展到在线设置时，现有方法仍严重依赖监督序列建模目标，而事后回报重新标记这一标准组件与基于重要性采样的强化学习算法（如GRPO）存在根本性不兼容，导致训练不稳定。

Method: 提出了基于纯强化学习梯度的在线微调算法：1) 将GRPO适配到Decision Transformers；2) 引入子轨迹优化以改进信用分配；3) 使用序列级似然目标增强稳定性和效率；4) 采用主动采样鼓励在不确定区域探索。

Result: 通过大量实验证明，该方法在多个基准测试中超越了现有的在线Decision Transformers基线方法，并取得了新的最先进性能。

Conclusion: 纯强化学习基础的在线微调对于Decision Transformers是有效的，解决了事后回报重新标记与重要性采样算法之间的不兼容问题，为序列决策建模提供了更优的在线学习方法。

Abstract: Decision Transformers (DTs) have emerged as a powerful framework for sequential decision making by formulating offline reinforcement learning (RL) as a sequence modeling problem. However, extending DTs to online settings with pure RL gradients remains largely unexplored, as existing approaches continue to rely heavily on supervised sequence-modeling objectives during online finetuning. We identify hindsight return relabeling -- a standard component in online DTs -- as a critical obstacle to RL-based finetuning: while beneficial for supervised learning, it is fundamentally incompatible with importance sampling-based RL algorithms such as GRPO, leading to unstable training. Building on this insight, we propose new algorithms that enable online finetuning of Decision Transformers using pure reinforcement learning gradients. We adapt GRPO to DTs and introduce several key modifications, including sub-trajectory optimization for improved credit assignment, sequence-level likelihood objectives for enhanced stability and efficiency, and active sampling to encourage exploration in uncertain regions. Through extensive experiments, we demonstrate that our methods outperform existing online DT baselines and achieve new state-of-the-art performance across multiple benchmarks, highlighting the effectiveness of pure-RL-based online finetuning for Decision Transformers.

</details>


### [88] [Sequential Reservoir Computing for Efficient High-Dimensional Spatiotemporal Forecasting](https://arxiv.org/abs/2601.00172)
*Ata Akbari Asanjan,Filip Wudarski,Daniel O'Connor,Shaun Geaney,Elena Strbac,P. Aaron Lott,Davide Venturelli*

Main category: cs.LG

TL;DR: 提出Sequential Reservoir Computing架构，通过将大储层分解为一系列小型互连储层，在保持长期时间依赖性的同时降低内存和计算成本，显著提升高维时空系统预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统RNN和LSTM在高维时空系统预测中存在梯度训练和内存瓶颈问题，而传统储层计算虽然通过固定循环层和凸读出优化缓解了这些问题，但仍面临输入维度扩展性差的问题。

Method: 提出Sequential Reservoir Computing架构，将大型储层分解为一系列小型互连储层，保持长期时间依赖性同时降低内存和计算成本。在低维混沌系统和高维物理模拟中进行验证。

Result: 相比LSTM和标准RNN基线，Sequential RC实现了15-25%更长的有效预测时间范围，20-30%更低的误差指标（SSIM、RMSE），训练成本降低达三个数量级。

Conclusion: Sequential RC在保持传统储层计算简单性和效率的同时，实现了对高维动力系统的卓越可扩展性，为科学和工程应用中的实时、节能预测提供了实用路径。

Abstract: Forecasting high-dimensional spatiotemporal systems remains computationally challenging for recurrent neural networks (RNNs) and long short-term memory (LSTM) models due to gradient-based training and memory bottlenecks. Reservoir Computing (RC) mitigates these challenges by replacing backpropagation with fixed recurrent layers and a convex readout optimization, yet conventional RC architectures still scale poorly with input dimensionality. We introduce a Sequential Reservoir Computing (Sequential RC) architecture that decomposes a large reservoir into a series of smaller, interconnected reservoirs. This design reduces memory and computational costs while preserving long-term temporal dependencies. Using both low-dimensional chaotic systems (Lorenz63) and high-dimensional physical simulations (2D vorticity and shallow-water equations), Sequential RC achieves 15-25% longer valid forecast horizons, 20-30% lower error metrics (SSIM, RMSE), and up to three orders of magnitude lower training cost compared to LSTM and standard RNN baselines. The results demonstrate that Sequential RC maintains the simplicity and efficiency of conventional RC while achieving superior scalability for high-dimensional dynamical systems. This approach provides a practical path toward real-time, energy-efficient forecasting in scientific and engineering applications.

</details>


### [89] [Early Prediction of Liver Cirrhosis Up to Three Years in Advance: A Machine Learning Study Benchmarking Against the FIB-4 Score](https://arxiv.org/abs/2601.00175)
*Zhuqi Miao,Sujan Ravi,Abdulaziz Ahmed*

Main category: cs.LG

TL;DR: 开发并评估了基于电子健康记录数据的机器学习模型，用于在肝硬化诊断前1-3年进行预测，性能显著优于传统FIB-4评分


<details>
  <summary>Details</summary>
Motivation: 需要开发更准确、更早期的肝硬化预测工具，以改善风险分层并支持预防性临床干预，弥补传统生物标志物（如FIB-4）在早期预测中的局限性

Method: 回顾性队列研究，使用大型学术医疗系统的去标识化EHR数据。识别脂肪肝患者并根据ICD-9/10编码分为肝硬化和非肝硬化队列。构建观察窗口和预测窗口模拟真实临床场景。收集人口统计学、诊断、实验室结果、生命体征和共病指数等特征。训练XGBoost模型用于1年、2年和3年预测，并在保留测试集上评估。使用AUC与FIB-4进行性能比较

Result: 最终队列包括：1年预测3,043名患者，2年预测1,981名，3年预测1,470名。机器学习模型在所有预测时间窗口均优于FIB-4：XGBoost模型的AUC分别为0.81（1年）、0.73（2年）、0.69（3年），而FIB-4的AUC分别为0.71、0.63、0.57。随着预测时间延长，性能优势持续存在，表明模型具有更好的早期风险区分能力

Conclusion: 基于常规EHR数据的机器学习模型在肝硬化早期预测方面显著优于传统FIB-4评分。这些模型能够实现更早、更准确的风险分层，可作为自动化决策支持工具集成到临床工作流程中，支持主动的肝硬化预防和管理

Abstract: Objective: Develop and evaluate machine learning (ML) models for predicting incident liver cirrhosis one, two, and three years prior to diagnosis using routinely collected electronic health record (EHR) data, and to benchmark their performance against the FIB-4 score. Methods: We conducted a retrospective cohort study using de-identified EHR data from a large academic health system. Patients with fatty liver disease were identified and categorized into cirrhosis and non-cirrhosis cohorts based on ICD-9/10 codes. Prediction scenarios were constructed using observation and prediction windows to emulate real-world clinical use. Demographics, diagnoses, laboratory results, vital signs, and comorbidity indices were aggregated from the observation window. XGBoost models were trained for 1-, 2-, and 3-year prediction horizons and evaluated on held-out test sets. Model performance was compared with FIB-4 using area under the receiver operating characteristic curve (AUC). Results: Final cohorts included 3,043 patients for the 1-year prediction, 1,981 for the 2-year prediction, and 1,470 for the 3-year prediction. Across all prediction windows, ML models consistently outperformed FIB-4. The XGBoost models achieved AUCs of 0.81, 0.73, and 0.69 for 1-, 2-, and 3-year predictions, respectively, compared with 0.71, 0.63, and 0.57 for FIB-4. Performance gains persisted with longer prediction horizons, indicating improved early risk discrimination. Conclusions: Machine learning models leveraging routine EHR data substantially outperform the traditional FIB-4 score for early prediction of liver cirrhosis. These models enable earlier and more accurate risk stratification and can be integrated into clinical workflows as automated decision-support tools to support proactive cirrhosis prevention and management.

</details>


### [90] [Reinforcement-Learned Unequal Error Protection for Quantized Semantic Embeddings](https://arxiv.org/abs/2601.00186)
*Moirangthem Tiken Singh,Adnan Arif*

Main category: cs.LG

TL;DR: 提出基于强化学习的自适应重复编码框架，实现按维度不等错误保护，在有限带宽下提升语义通信的语义保真度


<details>
  <summary>Details</summary>
Motivation: 解决带宽受限通信系统中语义意义保持的挑战，传统信道编码（如LDPC、Reed-Solomon）无法实现细粒度语义保护

Method: 采用强化学习框架，通过自适应重复编码实现按维度不等错误保护；使用复合语义失真度量，平衡全局嵌入相似性和实体级保持

Result: 在1 dB SNR下，相比均匀保护获得6.8%更高的chrF分数和9.3%更好的实体保持，统计显著提升

Conclusion: 智能分配的简单重复编码可实现细粒度语义保护，代码结构必须与语义粒度对齐，适用于边缘计算和物联网等带宽稀缺但语义保真度关键的场景

Abstract: This paper tackles the pressing challenge of preserving semantic meaning in communication systems constrained by limited bandwidth. We introduce a novel reinforcement learning framework that achieves per-dimension unequal error protection via adaptive repetition coding. Central to our approach is a composite semantic distortion metric that balances global embedding similarity with entity-level preservation, empowering the reinforcement learning agent to allocate protection in a context-aware manner. Experiments show statistically significant gains over uniform protection, achieving 6.8% higher chrF scores and 9.3% better entity preservation at 1 dB SNR. The key innovation of our framework is the demonstration that simple, intelligently allocated repetition coding enables fine-grained semantic protection -- an advantage unattainable with conventional codes such as LDPC or Reed-Solomon. Our findings challenge traditional channel coding paradigms by establishing that code structure must align with semantic granularity. This approach is particularly suited to edge computing and IoT scenarios, where bandwidth is scarce, but semantic fidelity is critical, providing a practical pathway for next-generation semantic-aware networks.

</details>


### [91] [SSI-GAN: Semi-Supervised Swin-Inspired Generative Adversarial Networks for Neuronal Spike Classification](https://arxiv.org/abs/2601.00189)
*Danial Sharifrazi,Nouman Javed,Mojtaba Mohammadi,Seyede Sana Salehi,Roohallah Alizadehsani,Prasad N. Paradkar,U. Rajendra Acharya,Asim Bhatti*

Main category: cs.LG

TL;DR: 提出SSI-GAN（半监督Swin启发GAN）用于蚊子神经元尖峰信号分类，仅需1-3%标注数据即可实现病毒神经嗜性检测，大幅减少人工标注工作量


<details>
  <summary>Details</summary>
Motivation: 蚊子是虫媒病毒主要传播媒介，人工分类神经元尖峰模式劳动密集且昂贵。现有深度学习方案需要完全标注数据集和高度预处理信号，难以在实际场景大规模应用。为解决标注数据稀缺问题，提出新的GAN架构。

Method: 提出SSI-GAN架构：采用Swin启发的移位窗口判别器配合基于Transformer的生成器。使用多头自注意力模型的扁平窗口Transformer判别器学习捕捉稀疏高频尖峰特征。仅用1-3%标注数据训练，收集超过1500万个尖峰样本，分为寨卡感染、登革热感染或未感染三类。使用Bayesian Optuna框架优化超参数，通过五折蒙特卡洛交叉验证验证鲁棒性。

Result: SSI-GAN在感染后第三天仅用3%标注数据达到99.93%分类准确率。仅需1%监督即能在所有感染阶段保持高准确率。相比标准监督方法，在相同性能水平下减少97-99%人工标注工作量。移位窗口Transformer设计大幅超越所有基线，在基于尖峰的神经元感染分类中创下新最佳记录。

Conclusion: SSI-GAN通过半监督学习和Transformer架构有效解决了神经元尖峰信号分类中标注数据稀缺问题，显著降低人工标注成本，为实际现场场景中的大规模应用提供了可行性，在病毒神经嗜性检测方面表现出卓越性能。

Abstract: Mosquitos are the main transmissive agents of arboviral diseases. Manual classification of their neuronal spike patterns is very labor-intensive and expensive. Most available deep learning solutions require fully labeled spike datasets and highly preprocessed neuronal signals. This reduces the feasibility of mass adoption in actual field scenarios. To address the scarcity of labeled data problems, we propose a new Generative Adversarial Network (GAN) architecture that we call the Semi-supervised Swin-Inspired GAN (SSI-GAN). The Swin-inspired, shifted-window discriminator, together with a transformer-based generator, is used to classify neuronal spike trains and, consequently, detect viral neurotropism. We use a multi-head self-attention model in a flat, window-based transformer discriminator that learns to capture sparser high-frequency spike features. Using just 1 to 3% labeled data, SSI-GAN was trained with more than 15 million spike samples collected at five-time post-infection and recording classification into Zika-infected, dengue-infected, or uninfected categories. Hyperparameters were optimized using the Bayesian Optuna framework, and performance for robustness was validated under fivefold Monte Carlo cross-validation. SSI-GAN reached 99.93% classification accuracy on the third day post-infection with only 3% labeled data. It maintained high accuracy across all stages of infection with just 1% supervision. This shows a 97-99% reduction in manual labeling effort relative to standard supervised approaches at the same performance level. The shifted-window transformer design proposed here beat all baselines by a wide margin and set new best marks in spike-based neuronal infection classification.

</details>


### [92] [Optimized Hybrid Feature Engineering for Resource-Efficient Arrhythmia Detection in ECG Signals: An Optimization Framework](https://arxiv.org/abs/2601.00192)
*Moirangthem Tiken Singh,Manibhushan Yaikhom*

Main category: cs.LG

TL;DR: 提出一种面向资源受限边缘设备的资源高效心律失常诊断框架，通过特征工程使高维数据线性可分，实现98.44%准确率、8.54KB模型大小和0.46μs推理延迟。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病特别是心律失常是全球主要死因，需要IoMT持续监测。现有深度学习方法计算开销大，不适合资源受限的边缘设备，需要开发更高效的解决方案。

Method: 提出数据中心的资源高效框架，集成时频小波分解和图论结构描述符（如PageRank中心性）构建混合特征空间，使用互信息和递归消除进行特征选择，最终采用可解释的超轻量线性分类器。

Result: 在MIT-BIH和INCART数据集上验证，达到98.44%诊断准确率，模型大小仅8.54KB，分类推理延迟0.46μs，每搏处理管道52ms，相比压缩模型KD-Light（25KB，96.32%准确率）实现数量级效率提升。

Conclusion: 该框架通过特征工程优先于复杂性的策略，使高维心律失常数据线性可分，为无电池心脏传感器提供了实时、高效的解决方案，显著优于现有压缩模型。

Abstract: Cardiovascular diseases, particularly arrhythmias, remain a leading global cause of mortality, necessitating continuous monitoring via the Internet of Medical Things (IoMT). However, state-of-the-art deep learning approaches often impose prohibitive computational overheads, rendering them unsuitable for resource-constrained edge devices. This study proposes a resource-efficient, data-centric framework that prioritizes feature engineering over complexity. Our optimized pipeline makes the complex, high-dimensional arrhythmia data linearly separable. This is achieved by integrating time-frequency wavelet decompositions with graph-theoretic structural descriptors, such as PageRank centrality. This hybrid feature space, combining wavelet decompositions and graph-theoretic descriptors, is then refined using mutual information and recursive elimination, enabling interpretable, ultra-lightweight linear classifiers. Validation on the MIT-BIH and INCART datasets yields 98.44% diagnostic accuracy with an 8.54 KB model footprint. The system achieves 0.46 $μ$s classification inference latency within a 52 ms per-beat pipeline, ensuring real-time operation. These outcomes provide an order-of-magnitude efficiency gain over compressed models, such as KD-Light (25 KB, 96.32% accuracy), advancing battery-less cardiac sensors.

</details>


### [93] [Unknown Aware AI-Generated Content Attribution](https://arxiv.org/abs/2601.00218)
*Ellie Thieu,Jifan Zhang,Haoyue Bai*

Main category: cs.LG

TL;DR: 该论文提出了一种利用未标注的互联网图像数据来增强生成模型归因性能的方法，通过约束优化在保持对已知模型分类性能的同时，提高对未见生成器的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着逼真生成模型的快速发展，需要超越简单的真假检测，实现更精确的生成模型归因。现有方法在已知生成器上表现良好，但难以泛化到未见或新发布的生成模型。

Method: 首先建立基于CLIP特征和线性分类器的基线方法，然后提出约束优化方法：利用未标注的互联网图像数据（可能包含真实图像、未知生成器输出或目标模型样本），鼓励将野生样本分类为非目标，同时约束在标注数据上的性能保持高位。

Result: 实验结果表明，引入野生数据显著提高了在具有挑战性的未见生成器上的归因性能，证明未标注的互联网数据可以有效增强开放世界环境下的AI生成内容归因能力。

Conclusion: 利用未标注的野生数据可以有效提升生成模型归因的泛化能力，特别是在面对未见或新发布生成器时，为开放世界环境下的AI生成内容溯源提供了有效解决方案。

Abstract: The rapid advancement of photorealistic generative models has made it increasingly important to attribute the origin of synthetic content, moving beyond binary real or fake detection toward identifying the specific model that produced a given image. We study the problem of distinguishing outputs from a target generative model (e.g., OpenAI Dalle 3) from other sources, including real images and images generated by a wide range of alternative models. Using CLIP features and a simple linear classifier, shown to be effective in prior work, we establish a strong baseline for target generator attribution using only limited labeled data from the target model and a small number of known generators. However, this baseline struggles to generalize to harder, unseen, and newly released generators. To address this limitation, we propose a constrained optimization approach that leverages unlabeled wild data, consisting of images collected from the Internet that may include real images, outputs from unknown generators, or even samples from the target model itself. The proposed method encourages wild samples to be classified as non target while explicitly constraining performance on labeled data to remain high. Experimental results show that incorporating wild data substantially improves attribution performance on challenging unseen generators, demonstrating that unlabeled data from the wild can be effectively exploited to enhance AI generated content attribution in open world settings.

</details>


### [94] [Can Optimal Transport Improve Federated Inverse Reinforcement Learning?](https://arxiv.org/abs/2601.00309)
*David Millard,Ali Baheri*

Main category: cs.LG

TL;DR: 提出基于最优传输的联邦逆强化学习方法，通过Wasserstein重心融合异构智能体的本地奖励函数，实现通信高效的跨环境共享奖励学习。


<details>
  <summary>Details</summary>
Motivation: 在机器人多智能体系统中，智能体在相似但不同的环境中运行，追求共同高层目标。直接池化数据学习共享奖励函数不切实际，因为存在动态差异、隐私约束和通信带宽限制。需要一种能处理异构性、保护隐私且通信高效的联邦IRL方法。

Method: 1. 每个客户端在本地执行轻量级最大熵逆强化学习，遵守计算和隐私限制；2. 将得到的奖励函数通过Wasserstein重心进行融合，考虑其底层几何结构；3. 证明这种重心融合比传统联邦学习参数平均方法能产生更准确的全局奖励估计。

Result: 该方法提供了一个原则性且通信高效的框架，用于推导能在异构智能体和环境中泛化的共享奖励函数。理论证明Wasserstein重心融合比传统参数平均方法产生更忠实的全局奖励估计。

Conclusion: 提出的最优传输方法为联邦逆强化学习提供了有效的解决方案，能够处理异构环境、保护隐私并减少通信开销，为多智能体系统共享奖励学习提供了理论基础和实践框架。

Abstract: In robotics and multi-agent systems, fleets of autonomous agents often operate in subtly different environments while pursuing a common high-level objective. Directly pooling their data to learn a shared reward function is typically impractical due to differences in dynamics, privacy constraints, and limited communication bandwidth. This paper introduces an optimal transport-based approach to federated inverse reinforcement learning (IRL). Each client first performs lightweight Maximum Entropy IRL locally, adhering to its computational and privacy limitations. The resulting reward functions are then fused via a Wasserstein barycenter, which considers their underlying geometric structure. We further prove that this barycentric fusion yields a more faithful global reward estimate than conventional parameter averaging methods in federated learning. Overall, this work provides a principled and communication-efficient framework for deriving a shared reward that generalizes across heterogeneous agents and environments.

</details>


### [95] [Quantum King-Ring Domination in Chess: A QAOA Approach](https://arxiv.org/abs/2601.00318)
*Gerhard Stenzel,Michael Kölle,Tobias Rohe,Julian Hager,Leo Sünkel,Maximilian Zorn,Claudia Linnhoff-Popien*

Main category: cs.LG

TL;DR: 该论文提出了QKRD（量子王车易位支配）基准测试，这是一个基于国际象棋战术位置的NISQ规模基准，用于系统评估QAOA算法设计选择，发现结构化基准能揭示在随机实例中被掩盖的问题感知QAOA技术优势。


<details>
  <summary>Details</summary>
Motivation: 当前QAOA算法主要在MaxCut、TSP、SAT等合成随机实例上进行基准测试，这些实例缺乏语义结构和人类可解释性，对具有有意义约束的实际问题性能提供有限洞察。需要结构化、可解释的基准来评估QAOA在实际问题上的表现。

Method: 引入QKRD基准，基于国际象棋战术位置构建，包含5,000个具有独热约束、空间局部性和10-40量子比特规模的结构化实例。基准将人类可解释的覆盖度量与针对经典启发式算法的内在验证相结合，无需外部预言机即可得出算法结论。

Result: 系统评估QAOA设计选择发现：约束保持混合器（XY、域壁）比标准混合器收敛快约13步（p<10^{-7}, d≈0.5）且无需惩罚调优；预热启动策略减少45步收敛（p<10^{-127}, d=3.35）且能量改进超过d=8；CVaR优化产生负面结果，能量更差（p<10^{-40}, d=1.21）且无覆盖优势。内在验证显示QAOA优于贪婪启发式12.6%，优于随机选择80.1%。

Conclusion: 结构化基准能揭示在随机实例中被掩盖的问题感知QAOA技术优势。QKRD为可重复的NISQ算法研究提供了代码、数据和实验工件的完整发布。

Abstract: The Quantum Approximate Optimization Algorithm (QAOA) is extensively benchmarked on synthetic random instances such as MaxCut, TSP, and SAT problems, but these lack semantic structure and human interpretability, offering limited insight into performance on real-world problems with meaningful constraints. We introduce Quantum King-Ring Domination (QKRD), a NISQ-scale benchmark derived from chess tactical positions that provides 5,000 structured instances with one-hot constraints, spatial locality, and 10--40 qubit scale. The benchmark pairs human-interpretable coverage metrics with intrinsic validation against classical heuristics, enabling algorithmic conclusions without external oracles. Using QKRD, we systematically evaluate QAOA design choices and find that constraint-preserving mixers (XY, domain-wall) converge approximately 13 steps faster than standard mixers (p<10^{-7}, d\approx0.5) while eliminating penalty tuning, warm-start strategies reduce convergence by 45 steps (p<10^{-127}, d=3.35) with energy improvements exceeding d=8, and Conditional Value-at-Risk (CVaR) optimization yields an informative negative result with worse energy (p<10^{-40}, d=1.21) and no coverage benefit. Intrinsic validation shows QAOA outperforms greedy heuristics by 12.6\% and random selection by 80.1\%. Our results demonstrate that structured benchmarks reveal advantages of problem-informed QAOA techniques obscured in random instances. We release all code, data, and experimental artifacts for reproducible NISQ algorithm research.

</details>


### [96] [Real-Time Human Detection for Aerial Captured Video Sequences via Deep Models](https://arxiv.org/abs/2601.00391)
*Nouar AlDahoul,Aznul Qalid Md Sabri,Ali Mohammed Mansoor*

Main category: cs.LG

TL;DR: 本文提出结合光流与三种深度模型（监督CNN、预训练CNN特征提取器、层次极限学习机）的方法，用于非静态摄像机航拍视频中的人体检测，在UCF-ARG数据集上取得高精度。


<details>
  <summary>Details</summary>
Motivation: 传统手工特征方法依赖专家知识，对光照变化、摄像机抖动等动态事件敏感，且任务依赖性高。自动特征学习方法能自动提取抽象判别特征，成本更低且无需专家知识。

Method: 结合光流与三种深度模型：监督CNN（S-CNN）、预训练CNN特征提取器、层次极限学习机（H-ELM）。在UCF-ARG航拍数据集上训练测试，评估五种人类动作（挖掘、挥手、投掷、行走、奔跑）。

Result: 预训练CNN平均准确率98.09%；S-CNN使用softmax达95.6%，SVM达91.7%；H-ELM平均准确率95.9%。H-ELM在CPU上训练时间445秒，S-CNN在GPU上训练时间770秒。

Conclusion: 提出的自动特征学习方法在航拍视频人体检测任务中表现成功，预训练CNN效果最佳，H-ELM在计算效率上有优势，为动态环境下的人体检测提供了有效解决方案。

Abstract: Human detection in videos plays an important role in various real-life applications. Most traditional approaches depend on utilizing handcrafted features, which are problem-dependent and optimal for specific tasks. Moreover, they are highly susceptible to dynamical events such as illumination changes, camera jitter, and variations in object sizes. On the other hand, the proposed feature learning approaches are cheaper and easier because highly abstract and discriminative features can be produced automatically without the need of expert knowledge. In this paper, we utilize automatic feature learning methods, which combine optical flow and three different deep models (i.e., supervised convolutional neural network (S-CNN), pretrained CNN feature extractor, and hierarchical extreme learning machine) for human detection in videos captured using a nonstatic camera on an aerial platform with varying altitudes. The models are trained and tested on the publicly available and highly challenging UCF-ARG aerial dataset. The comparison between these models in terms of training, testing accuracy, and learning speed is analyzed. The performance evaluation considers five human actions (digging, waving, throwing, walking, and running). Experimental results demonstrated that the proposed methods are successful for the human detection task. The pretrained CNN produces an average accuracy of 98.09%. S-CNN produces an average accuracy of 95.6% with softmax and 91.7% with Support Vector Machines (SVM). H-ELM has an average accuracy of 95.9%. Using a normal Central Processing Unit (CPU), H-ELM's training time takes 445 seconds. Learning in S-CNN takes 770 seconds with a high-performance Graphical Processing Unit (GPU).

</details>


### [97] [E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models](https://arxiv.org/abs/2601.00423)
*Shengjun Zhang,Zhang Zhang,Chensheng Dai,Yueqi Duan*

Main category: cs.LG

TL;DR: E-GRPO：一种基于熵感知的组相对策略优化方法，通过合并低熵步骤为高熵SDE采样步骤，结合ODE采样，解决强化学习中稀疏模糊奖励信号问题


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在优化多个去噪步骤时面临稀疏和模糊的奖励信号问题。观察到高熵步骤能实现更高效有效的探索，而低熵步骤导致无区别的轨迹生成

Method: 提出E-GRPO（熵感知组相对策略优化）：1）合并连续低熵步骤形成单个高熵SDE采样步骤，其他步骤使用ODE采样；2）引入多步组归一化优势函数，在共享相同合并SDE去噪步骤的样本中计算组相对优势

Result: 在不同奖励设置下的实验结果表明该方法具有有效性

Conclusion: 通过熵感知的步骤合并和组相对优势计算，E-GRPO能够更有效地处理随机微分方程采样中的模糊奖励信号问题，提升人类偏好对齐中流匹配模型的强化学习效果

Abstract: Recent reinforcement learning has enhanced the flow matching models on human preference alignment. While stochastic sampling enables the exploration of denoising directions, existing methods which optimize over multiple denoising steps suffer from sparse and ambiguous reward signals. We observe that the high entropy steps enable more efficient and effective exploration while the low entropy steps result in undistinguished roll-outs. To this end, we propose E-GRPO, an entropy aware Group Relative Policy Optimization to increase the entropy of SDE sampling steps. Since the integration of stochastic differential equations suffer from ambiguous reward signals due to stochasticity from multiple steps, we specifically merge consecutive low entropy steps to formulate one high entropy step for SDE sampling, while applying ODE sampling on other steps. Building upon this, we introduce multi-step group normalized advantage, which computes group-relative advantages within samples sharing the same consolidated SDE denoising step. Experimental results on different reward settings have demonstrated the effectiveness of our methods.

</details>


### [98] [A Comparative Analysis of Interpretable Machine Learning Methods](https://arxiv.org/abs/2601.00428)
*Mattia Billa,Giovanni Orlandi,Veronica Guidetti,Federica Mandreoli*

Main category: cs.LG

TL;DR: 对16种可解释机器学习方法在216个真实世界表格数据集上进行大规模比较评估，分析性能层次结构、数据集特征影响、训练时间和分布偏移鲁棒性


<details>
  <summary>Details</summary>
Motivation: 机器学习在医疗、金融、法律等高风险领域的广泛应用引发了对模型可解释性和问责制的关注，但针对表格数据的固有可解释模型的系统性评估相对缺乏，现有研究多集中于聚合性能结果

Method: 对16种固有可解释方法进行大规模比较评估，包括经典线性模型、决策树以及EBMs、符号回归、GOSDT等新方法；涵盖216个真实世界表格数据集，按数据集结构特征（维度、样本量、线性度、类别不平衡）分层分析性能，并评估训练时间和受控分布偏移下的鲁棒性

Result: 揭示了清晰的性能层次结构，特别是在回归任务中EBMs始终表现出强大的预测准确性；性能高度依赖于上下文：SR和IGANNs在非线性场景中表现优异，GOSDT模型对类别不平衡表现出明显的敏感性

Conclusion: 研究结果为寻求可解释性与预测性能平衡的从业者提供了实用指导，并加深了对表格数据可解释建模的实证理解

Abstract: In recent years, Machine Learning (ML) has seen widespread adoption across a broad range of sectors, including high-stakes domains such as healthcare, finance, and law. This growing reliance has raised increasing concerns regarding model interpretability and accountability, particularly as legal and regulatory frameworks place tighter constraints on using black-box models in critical applications. Although interpretable ML has attracted substantial attention, systematic evaluations of inherently interpretable models, especially for tabular data, remain relatively scarce and often focus primarily on aggregated performance outcomes.
  To address this gap, we present a large-scale comparative evaluation of 16 inherently interpretable methods, ranging from classical linear models and decision trees to more recent approaches such as Explainable Boosting Machines (EBMs), Symbolic Regression (SR), and Generalized Optimal Sparse Decision Trees (GOSDT). Our study spans 216 real-world tabular datasets and goes beyond aggregate rankings by stratifying performance according to structural dataset characteristics, including dimensionality, sample size, linearity, and class imbalance. In addition, we assess training time and robustness under controlled distributional shifts. Our results reveal clear performance hierarchies, especially for regression tasks, where EBMs consistently achieve strong predictive accuracy. At the same time, we show that performance is highly context-dependent: SR and Interpretable Generalized Additive Neural Networks (IGANNs) perform particularly well in non-linear regimes, while GOSDT models exhibit pronounced sensitivity to class imbalance. Overall, these findings provide practical guidance for practitioners seeking a balance between interpretability and predictive performance, and contribute to a deeper empirical understanding of interpretable modeling for tabular data.

</details>


### [99] [Controllable Concept Bottleneck Models](https://arxiv.org/abs/2601.00451)
*Hongbin Lin,Chenyang Ren,Juangui Xu,Zhengyu Hu,Cheng-Long Wang,Yao Shu,Hui Xiong,Jingfeng Zhang,Di Wang,Lijie Hu*

Main category: cs.LG

TL;DR: 提出可控概念瓶颈模型（CCBMs），支持概念标签级、概念级和数据级三种粒度的模型编辑，无需重新训练即可实现动态维护。


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型（CBMs）主要关注静态场景，假设数据和概念固定且干净。但在实际应用中，部署的模型需要持续维护：需要删除错误或敏感数据（遗忘学习）、纠正错误标记的概念、或纳入新样本（增量学习）以适应环境变化。因此，如何在不从头重新训练的情况下实现高效可编辑的CBMs成为重要挑战。

Method: 提出可控概念瓶颈模型（CCBMs），支持三种粒度编辑：概念标签级、概念级和数据级（包括数据删除和添加）。基于影响函数推导出数学上严格的闭式近似解，避免了重新训练的需求。

Result: 实验结果表明CCBMs具有高效性和适应性，验证了其在实现动态可信CBMs方面的实用价值。

Conclusion: CCBMs通过数学严谨的闭式近似解实现了多粒度模型编辑，解决了实际应用中CBMs的动态维护问题，为大规模应用提供了高效的可编辑解决方案。

Abstract: Concept Bottleneck Models (CBMs) have garnered much attention for their ability to elucidate the prediction process through a human-understandable concept layer. However, most previous studies focused on static scenarios where the data and concepts are assumed to be fixed and clean. In real-world applications, deployed models require continuous maintenance: we often need to remove erroneous or sensitive data (unlearning), correct mislabeled concepts, or incorporate newly acquired samples (incremental learning) to adapt to evolving environments. Thus, deriving efficient editable CBMs without retraining from scratch remains a significant challenge, particularly in large-scale applications. To address these challenges, we propose Controllable Concept Bottleneck Models (CCBMs). Specifically, CCBMs support three granularities of model editing: concept-label-level, concept-level, and data-level, the latter of which encompasses both data removal and data addition. CCBMs enjoy mathematically rigorous closed-form approximations derived from influence functions that obviate the need for retraining. Experimental results demonstrate the efficiency and adaptability of our CCBMs, affirming their practical value in enabling dynamic and trustworthy CBMs.

</details>


### [100] [Geometric Regularization in Mixture-of-Experts: The Disconnect Between Weights and Activations](https://arxiv.org/abs/2601.00457)
*Hyunjun Kim*

Main category: cs.LG

TL;DR: 正交性损失在MoE模型中无法有效促进专家多样性，反而增加权重空间重叠，对性能影响不一致且不可靠


<details>
  <summary>Details</summary>
Motivation: 研究几何正则化在MoE模型专家专业化中的作用，探索正交性损失是否能有效促进专家多样性

Method: 在MoE模型中应用正交性损失，通过7种正则化强度进行实验，分析权重空间重叠(MSO)和激活空间重叠的变化

Result: 正交性损失在多个方面失败：权重空间重叠增加达114%，激活空间重叠保持高位(~0.6)，性能影响不一致，权重与激活正交性无显著相关性(r=-0.293,p=0.523)

Conclusion: 权重空间正则化既未实现其几何目标，也未可靠提升性能，不适合用于MoE多样性增强

Abstract: Mixture-of-Experts (MoE) models achieve efficiency through sparse activation, but the role of geometric regularization in expert specialization remains unclear. We apply orthogonality loss to enforce expert diversity and find it fails on multiple fronts: it does not reduce weight-space overlap (MSO actually increases by up to 114%), activation-space overlap remains high (~0.6) regardless of regularization, and effects on performance are inconsistent -- marginal improvement on WikiText-103 (-0.9%), slight degradation on TinyStories (+0.9%), and highly variable results on PTB (std > 1.0). Our analysis across 7 regularization strengths reveals no significant correlation (r = -0.293, p = 0.523) between weight and activation orthogonality. These findings demonstrate that weight-space regularization neither achieves its geometric goal nor reliably improves performance, making it unsuitable for MoE diversity.

</details>


### [101] [Detecting Spike Wave Discharges (SWD) using 1-dimensional Residual UNet](https://arxiv.org/abs/2601.00459)
*Saurav Sengupta,Scott Kilianski,Suchetha Sharma,Sakina Lashkeri,Ashley McHugh,Mark Beenhakker,Donald E. Brown*

Main category: cs.LG

TL;DR: 该研究开发了一种基于1D UNet的数据增强方法（AugUNet1D），用于自动标记脑电图中的棘慢波放电，相比传统机器学习方法和"Twin Peaks"算法表现更优。


<details>
  <summary>Details</summary>
Motivation: 脑电图（EEG）记录中事件的手动标记耗时费力，特别是对于持续数周至数月的连续记录。棘慢波放电（SWD）作为失神发作的电生理标志，通常需要手动标记。虽然已有研究使用机器学习自动分割和分类EEG信号，但仍有改进空间。

Method: 研究比较了14种机器学习分类器在961小时C3H/HeJ小鼠EEG记录（包含22,637个标记SWD）上的性能。发现1D UNet表现最佳，并通过数据增强改进该模型，其中缩放增强效果最显著。最终将增强后的1D UNet（AugUNet1D）与近期发表的时频域算法"Twin Peaks"进行比较。

Result: 1D UNet在该数据集上表现最佳。数据增强显著提升了模型性能，其中缩放增强效果最明显。AugUNet1D在性能上优于"Twin Peaks"算法，检测到的事件特征更接近手动标记的SWD。研究公开了预训练和未训练的AugUNet1D模型供其他用户使用。

Conclusion: AugUNet1D是一种有效的自动标记EEG中棘慢波放电的方法，性能优于现有算法，能够减少手动工作量并提高标记效率。公开的模型资源有助于推动该领域的研究和应用。

Abstract: The manual labeling of events in electroencephalography (EEG) records is time-consuming. This is especially true when EEG recordings are taken continuously over weeks to months. Therefore, a method to automatically label pertinent EEG events reduces the manual workload. Spike wave discharges (SWD), which are the electrographic hallmark of absence seizures, are EEG events that are often labeled manually. While some previous studies have utilized machine learning to automatically segment and classify EEG signals like SWDs, they can be improved. Here we compare the performance of 14 machine learning classifiers on our own manually annotated dataset of 961 hours of EEG recordings from C3H/HeJ mice, including 22,637 labeled SWDs. We find that a 1D UNet performs best for labeling SWDs in this dataset. We also improve the 1D UNet by augmenting our training data and determine that scaling showed the greatest benefit of all augmentation procedures applied. We then compare the 1D UNet with data augmentation, AugUNet1D, against a recently published time- and frequency-based algorithmic approach called "Twin Peaks". AugUNet1D showed superior performance and detected events with more similar features to the SWDs labeled manually. AugUNet1D, pretrained on our manually annotated data or untrained, is made public for others users.

</details>


### [102] [Laplacian Kernelized Bandit](https://arxiv.org/abs/2601.00461)
*Shuang Wu,Arash A. Amini*

Main category: cs.LG

TL;DR: 提出了一种融合图拉普拉斯正则化与核化bandits的多用户上下文bandit框架，通过构建统一的多用户再生核希尔伯特空间，设计出具有理论保证的探索算法。


<details>
  <summary>Details</summary>
Motivation: 研究多用户上下文bandit问题，其中用户通过图结构关联，且奖励函数同时表现出非线性行为和图同质性。现有方法通常独立处理用户或仅考虑线性关系，缺乏统一框架来同时建模非线性奖励和图结构信息。

Method: 提出一种联合惩罚项，结合基于RKHS距离的图平滑项和个体粗糙度惩罚。证明该惩罚等价于单一统一的多用户RKHS中的平方范数，并显式推导其再生核，该核优雅地融合了图拉普拉斯和基础臂核。基于此统一框架，设计了两种算法：LK-GP-UCB和LK-GP-TS，利用高斯过程后验进行探索。

Result: 提供了高概率遗憾界，其缩放与多用户核的有效维度相关，而非用户数量或环境维度。实验表明，在非线性设置中，该方法优于强线性基线和无图感知基线；即使在真实奖励为线性的情况下，仍保持竞争力。

Conclusion: 提出了一个统一、理论严谨且实用的框架，将拉普拉斯正则化与核化bandits相结合，用于结构化探索。该框架为多用户上下文bandit问题提供了新的理论见解和有效算法。

Abstract: We study multi-user contextual bandits where users are related by a graph and their reward functions exhibit both non-linear behavior and graph homophily. We introduce a principled joint penalty for the collection of user reward functions $\{f_u\}$, combining a graph smoothness term based on RKHS distances with an individual roughness penalty. Our central contribution is proving that this penalty is equivalent to the squared norm within a single, unified \emph{multi-user RKHS}. We explicitly derive its reproducing kernel, which elegantly fuses the graph Laplacian with the base arm kernel. This unification allows us to reframe the problem as learning a single ''lifted'' function, enabling the design of principled algorithms, \texttt{LK-GP-UCB} and \texttt{LK-GP-TS}, that leverage Gaussian Process posteriors over this new kernel for exploration. We provide high-probability regret bounds that scale with an \emph{effective dimension} of the multi-user kernel, replacing dependencies on user count or ambient dimension. Empirically, our methods outperform strong linear and non-graph-aware baselines in non-linear settings and remain competitive even when the true rewards are linear. Our work delivers a unified, theoretically grounded, and practical framework that bridges Laplacian regularization with kernelized bandits for structured exploration.

</details>


### [103] [Trajectory Guard -- A Lightweight, Sequence-Aware Model for Real-Time Anomaly Detection in Agentic AI](https://arxiv.org/abs/2601.00516)
*Laksh Advani*

Main category: cs.LG

TL;DR: Trajectory Guard：基于孪生循环自编码器的LLM智能体多步行动计划异常检测方法，通过对比学习与重构损失联合优化，实现任务-轨迹对齐和序列有效性检测


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法不适用于LLM智能体生成的多步行动计划：均值池化嵌入会稀释异常步骤信息，仅对比学习方法忽略序列结构，标准无监督方法在预训练嵌入上F1分数不超过0.69

Method: 提出Trajectory Guard，一种孪生循环自编码器架构，采用混合损失函数：通过对比学习联合学习任务-轨迹对齐，通过重构学习序列有效性。这种双重目标能够统一检测"任务计划错误"和"计划结构畸形"两类异常

Result: 在合成扰动和真实世界失败案例（RAS-Eval安全审计和Who&When多智能体系统）的基准测试中，平衡数据集上F1分数达到0.88-0.94，不平衡外部基准测试中召回率达到0.86-0.92。推理延迟仅32毫秒，比LLM Judge基线快17-27倍

Conclusion: Trajectory Guard能够高效检测LLM智能体行动计划的异常，支持生产部署中的实时安全验证，解决了现有方法在序列异常检测上的局限性

Abstract: Autonomous LLM agents generate multi-step action plans that can fail due to contextual misalignment or structural incoherence. Existing anomaly detection methods are ill-suited for this challenge: mean-pooling embeddings dilutes anomalous steps, while contrastive-only approaches ignore sequential structure. Standard unsupervised methods on pre-trained embeddings achieve F1-scores no higher than 0.69. We introduce Trajectory Guard, a Siamese Recurrent Autoencoder with a hybrid loss function that jointly learns task-trajectory alignment via contrastive learning and sequential validity via reconstruction. This dual objective enables unified detection of both "wrong plan for this task" and "malformed plan structure." On benchmarks spanning synthetic perturbations and real-world failures from security audits (RAS-Eval) and multi-agent systems (Who\&When), we achieve F1-scores of 0.88-0.94 on balanced sets and recall of 0.86-0.92 on imbalanced external benchmarks. At 32 ms inference latency, our approach runs 17-27$\times$ faster than LLM Judge baselines, enabling real-time safety verification in production deployments.

</details>


### [104] [Federated Customization of Large Models: Approaches, Experiments, and Insights](https://arxiv.org/abs/2601.00526)
*Yuchuan Ye,Ming Ding,Youjia Chen,Peng Cheng,Dusit Niyato*

Main category: cs.LG

TL;DR: 本文探讨了大型模型在联邦学习框架下的定制化方法，首次将prefix-tuning应用于联邦学习环境，验证了其可行性并展示了竞争优势。


<details>
  <summary>Details</summary>
Motivation: 研究大型模型在联邦学习框架下的定制化挑战，探索如何在保护数据隐私的同时实现模型个性化，填补prefix-tuning在联邦学习环境中应用的研究空白。

Method: 综述了多种大型模型定制技术（全微调、高效微调、提示工程、prefix-tuning、知识蒸馏、检索增强生成），重点在联邦学习框架下实现这些技术，并首次将prefix-tuning应用于联邦学习环境进行实验验证。

Result: 联邦prefix-tuning实验验证了其在联邦学习环境中的可行性，性能接近集中式方法。与其他三种联邦定制方法相比，展示了竞争优势、满意的效率和一致的鲁棒性。

Conclusion: 联邦学习框架下的大型模型定制化是可行的，prefix-tuning在联邦学习环境中表现出色，为隐私保护下的模型个性化提供了有效解决方案。

Abstract: In this article, we explore federated customization of large models and highlight the key challenges it poses within the federated learning framework. We review several popular large model customization techniques, including full fine-tuning, efficient fine-tuning, prompt engineering, prefix-tuning, knowledge distillation, and retrieval-augmented generation. Then, we discuss how these techniques can be implemented within the federated learning framework. Moreover, we conduct experiments on federated prefix-tuning, which, to the best of our knowledge, is the first trial to apply prefix-tuning in the federated learning setting. The conducted experiments validate its feasibility with performance close to centralized approaches. Further comparison with three other federated customization methods demonstrated its competitive performance, satisfactory efficiency, and consistent robustness.

</details>


### [105] [TeleDoCTR: Domain-Specific and Contextual Troubleshooting for Telecommunications](https://arxiv.org/abs/2601.00691)
*Mohamed Trabelsi,Huseyin Uzunalioglu*

Main category: cs.LG

TL;DR: TeleDoCTR：面向电信领域的端到端工单故障排除系统，集成领域特定排序和生成模型，自动化工单分类、历史工单检索和故障分析报告生成，显著提升故障排除效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 电信领域的工单故障排除高度复杂且耗时，需要专家解读工单内容、查阅文档和搜索历史记录，这种人工密集型方法不仅延迟问题解决，还阻碍整体运营效率。需要自动化系统来提升电信工单故障排除的效能和效率。

Method: 提出TeleDoCTR系统，这是一个面向电信领域的、领域特定的、上下文感知的故障排除系统，专为电信端到端工单解决而设计。系统集成领域特定排序模型和生成模型，自动化故障排除工作流的关键步骤：1）将工单路由到负责解决的专家团队（分类任务）；2）检索上下文和语义相似的历史工单（检索任务）；3）生成详细的故障分析报告，概述问题、根本原因和潜在解决方案（生成任务）。

Result: 在电信基础设施的真实数据集上评估TeleDoCTR，证明其性能优于现有最先进方法，显著提升了故障排除过程的准确性和效率。

Conclusion: TeleDoCTR系统通过集成领域特定排序和生成模型，成功实现了电信工单故障排除关键步骤的自动化，为电信领域提供了一种高效、准确的端到端工单解决方案，能够显著改善运营效率。

Abstract: Ticket troubleshooting refers to the process of analyzing and resolving problems that are reported through a ticketing system. In large organizations offering a wide range of services, this task is highly complex due to the diversity of submitted tickets and the need for specialized domain knowledge. In particular, troubleshooting in telecommunications (telecom) is a very time-consuming task as it requires experts to interpret ticket content, consult documentation, and search historical records to identify appropriate resolutions. This human-intensive approach not only delays issue resolution but also hinders overall operational efficiency. To enhance the effectiveness and efficiency of ticket troubleshooting in telecom, we propose TeleDoCTR, a novel telecom-related, domain-specific, and contextual troubleshooting system tailored for end-to-end ticket resolution in telecom. TeleDoCTR integrates both domain-specific ranking and generative models to automate key steps of the troubleshooting workflow which are: routing tickets to the appropriate expert team responsible for resolving the ticket (classification task), retrieving contextually and semantically similar historical tickets (retrieval task), and generating a detailed fault analysis report outlining the issue, root cause, and potential solutions (generation task). We evaluate TeleDoCTR on a real-world dataset from a telecom infrastructure and demonstrate that it achieves superior performance over existing state-of-the-art methods, significantly enhancing the accuracy and efficiency of the troubleshooting process.

</details>


### [106] [Cloud-Native Generative AI for Automated Planogram Synthesis: A Diffusion Model Approach for Multi-Store Retail Optimization](https://arxiv.org/abs/2601.00527)
*Ravi Teja Pagidoju,Shriya Agarwal*

Main category: cs.LG

TL;DR: 本文提出了一种基于扩散模型的云原生架构，用于自动生成商店特定的货架图，将设计时间从30小时减少到0.5小时，同时满足94.4%的约束条件。


<details>
  <summary>Details</summary>
Motivation: 货架图创建是零售业面临的重大挑战，每个复杂布局平均需要30小时。传统优化方法只能重新组织现有布局，无法从多个零售点的成功货架安排中学习以创建新的配置。

Method: 采用云原生架构，结合AWS进行云端模型训练和边缘部署实现实时推理。使用扩散模型，通过修改损失函数集成零售特定约束，从多个零售点的成功货架安排中学习生成新的货架图配置。

Result: 系统将货架图设计时间减少98.3%（从30小时降至0.5小时），实现94.4%的约束满足率。经济分析显示创建费用减少97.5%，投资回收期为4.4个月。云原生架构支持线性扩展，可处理高达10,000个并发商店请求。

Conclusion: 这项工作证明了生成式AI在自动化零售空间优化中的可行性，通过扩散模型和云原生架构实现了高效、可扩展的货架图自动生成。

Abstract: Planogram creation is a significant challenge for retail, requiring an average of 30 hours per complex layout. This paper introduces a cloud-native architecture using diffusion models to automatically generate store-specific planograms. Unlike conventional optimization methods that reorganize existing layouts, our system learns from successful shelf arrangements across multiple retail locations to create new planogram configurations. The architecture combines cloud-based model training via AWS with edge deployment for real-time inference. The diffusion model integrates retail-specific constraints through a modified loss function. Simulation-based analysis demonstrates the system reduces planogram design time by 98.3% (from 30 to 0.5 hours) while achieving 94.4% constraint satisfaction. Economic analysis reveals a 97.5% reduction in creation expenses with a 4.4-month break-even period. The cloud-native architecture scales linearly, supporting up to 10,000 concurrent store requests. This work demonstrates the viability of generative AI for automated retail space optimization.

</details>


### [107] [Memory Bank Compression for Continual Adaptation of Large Language Models](https://arxiv.org/abs/2601.00756)
*Thomas Katraouras,Dimitrios Rafailidis*

Main category: cs.LG

TL;DR: MBC提出了一种通过码本优化策略压缩记忆库的持续学习方法，结合在线重置机制防止码本崩溃，使用KV-LoRA高效利用压缩记忆表示，在保持高准确率的同时将记忆库大小减少到基线的0.3%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的知识容易过时，持续学习需要更新模型而不遗忘已有知识。现有记忆增强方法面临记忆库随数据流不断增长的瓶颈，需要有效的压缩策略。

Method: 提出MBC模型：1) 通过码本优化策略压缩记忆库；2) 引入在线重置机制防止码本崩溃；3) 在注意力层使用Key-Value低秩适应(KV-LoRA)高效利用压缩记忆表示。

Result: 在基准问答数据集上的实验表明，MBC将记忆库大小减少到最竞争基线的0.3%，同时在在线适应学习中保持高保留准确率。

Conclusion: MBC通过码本压缩和KV-LoRA实现了高效的持续学习，解决了记忆库无限增长的问题，在保持性能的同时显著减少了存储需求。

Abstract: Large Language Models (LLMs) have become a mainstay for many everyday applications. However, as data evolve their knowledge quickly becomes outdated. Continual learning aims to update LLMs with new information without erasing previously acquired knowledge. Although methods such as full fine-tuning can incorporate new data, they are computationally expensive and prone to catastrophic forgetting, where prior knowledge is overwritten. Memory-augmented approaches address this by equipping LLMs with a memory bank, that is an external memory module which stores information for future use. However, these methods face a critical limitation, in particular, the memory bank constantly grows in the real-world scenario when large-scale data streams arrive. In this paper, we propose MBC, a model that compresses the memory bank through a codebook optimization strategy during online adaptation learning. To ensure stable learning, we also introduce an online resetting mechanism that prevents codebook collapse. In addition, we employ Key-Value Low-Rank Adaptation in the attention layers of the LLM, enabling efficient utilization of the compressed memory representations. Experiments with benchmark question-answering datasets demonstrate that MBC reduces the memory bank size to 0.3% when compared against the most competitive baseline, while maintaining high retention accuracy during online adaptation learning. Our code is publicly available at https://github.com/Thomkat/MBC.

</details>


### [108] [Entropy Production in Machine Learning Under Fokker-Planck Probability Flow](https://arxiv.org/abs/2601.00554)
*Lennon Shikhman*

Main category: cs.LG

TL;DR: 提出基于非平衡随机动力学的熵触发重训练框架，用于非平稳环境中的机器学习模型维护，通过熵平衡分解监测模型-数据失配，显著减少重训练次数


<details>
  <summary>Details</summary>
Motivation: 现有漂移检测方法缺乏动力学原理基础，无法平衡重训练频率与操作成本，需要一种基于原理的框架来指导重训练策略

Method: 将部署时数据漂移建模为Fokker-Planck方程控制的概率流，使用时变Kullback-Leibler散度量模型-数据失配，通过熵平衡分解识别非负熵产生项，提出基于熵触发的无标签重训练策略

Result: 在受控非平稳分类实验中，熵触发重训练在保持与高频重训练相当预测性能的同时，相比每日重训练和基于标签的策略，将重训练事件减少了一个数量级

Conclusion: 基于非平衡随机动力学的熵触发重训练框架为数据漂移管理提供了原理性方法，通过响应累积失配而非延迟的性能崩溃，实现了重训练频率与操作成本的有效平衡

Abstract: Machine learning models deployed in nonstationary environments experience performance degradation due to data drift. While many drift detection heuristics exist, most lack a principled dynamical interpretation and provide limited guidance on how retraining frequency should be balanced against operational cost. In this work, we propose an entropy--based retraining framework grounded in nonequilibrium stochastic dynamics. Modeling deployment--time data drift as probability flow governed by a Fokker--Planck equation, we quantify model--data mismatch using a time--evolving Kullback--Leibler divergence. We show that the time derivative of this mismatch admits an entropy--balance decomposition featuring a nonnegative entropy production term driven by probability currents. This interpretation motivates entropy--triggered retraining as a label--free intervention strategy that responds to accumulated mismatch rather than delayed performance collapse. In a controlled nonstationary classification experiment, entropy--triggered retraining achieves predictive performance comparable to high--frequency retraining while reducing retraining events by an order of magnitude relative to daily and label--based policies.

</details>


### [109] [Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning](https://arxiv.org/abs/2601.00791)
*Valentin Noël*

Main category: cs.LG

TL;DR: 提出一种无需训练的方法，通过注意力矩阵的谱分析检测大语言模型中数学推理的有效性，利用四个可解释的谱诊断指标区分有效和无效数学证明。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常需要训练数据、微调或学习分类器来验证推理有效性。本文旨在开发一种无需训练的方法，通过分析注意力模式的谱特征来检测数学推理的逻辑一致性，为AI安全监控和幻觉检测提供原理性框架。

Method: 将注意力矩阵视为token动态图的邻接矩阵，提取四个可解释的谱诊断指标：Fiedler值（代数连通性）、高频能量比（HFER）、图信号平滑度和谱熵。这些指标在有效和无效数学证明间表现出统计学显著差异。方法无需训练数据、微调或学习分类器，仅需对谱指标设置单一阈值即可实现高精度分类。

Result: 在来自四个独立架构家族（Meta Llama、Alibaba Qwen、Microsoft Phi、Mistral AI）的七个Transformer模型上进行实验，谱特征产生高达Cohen's d=3.30（p<10^{-116}）的效应量，在严格评估下实现85.0-95.6%的分类准确率，校准阈值在全数据集上达到93-95%。通过系统标签校正发现，谱方法检测的是逻辑一致性而非编译器接受度，能识别形式验证器因技术故障而拒绝的数学有效证明。还发现架构依赖性：Mistral-7B的滑动窗口注意力将判别信号从HFER转移到后期层平滑度（d=2.09，p_{MW}=1.16×10^{-48}）。

Conclusion: 谱图分析为推理验证提供了原理性框架，具有立即应用于幻觉检测和AI安全监控的潜力。方法揭示了注意力机制设计影响哪些谱特征捕获推理有效性，为理解大语言模型中的推理过程提供了新视角。

Abstract: We present a training-free method for detecting valid mathematical reasoning in large language models through spectral analysis of attention patterns. By treating attention matrices as adjacency matrices of dynamic graphs over tokens, we extract four interpretable spectral diagnostics, the Fiedler value (algebraic connectivity), high-frequency energy ratio (HFER), graph signal smoothness, and spectral entropy, that exhibit statistically significant differences between valid and invalid mathematical proofs. Experiments across seven transformer models from four independent architectural families (Meta Llama, Alibaba Qwen, Microsoft Phi, and Mistral AI) demonstrate that this spectral signature produces effect sizes up to Cohen's $d = 3.30$ ($p < 10^{-116}$), enabling 85.0--95.6\% classification accuracy under rigorous evaluation, with calibrated thresholds reaching 93--95\% on the full dataset. The method requires no training data, fine-tuning, or learned classifiers: a single threshold on a spectral metric suffices for high accuracy. Through systematic label correction, we discover that the spectral method detects logical coherence rather than compiler acceptance, identifying mathematically valid proofs that formal verifiers reject due to technical failures. We further identify an architectural dependency: Mistral-7B's Sliding Window Attention shifts the discriminative signal from HFER to late-layer Smoothness ($d = 2.09$, $p_{\text{MW}} = 1.16 \times 10^{-48}$), revealing that attention mechanism design affects which spectral features capture reasoning validity. These findings establish spectral graph analysis as a principled framework for reasoning verification with immediate applications to hallucination detection and AI safety monitoring.

</details>


### [110] [Adversarial Samples Are Not Created Equal](https://arxiv.org/abs/2601.00577)
*Jennifer Crawford,Amol Khanna,Fred Lu,Amy R. Wagoner,Stella Biderman,Andre T. Nguyen,Edward Raff*

Main category: cs.LG

TL;DR: 论文提出需要区分两种对抗性弱点：利用非鲁棒特征的对抗样本和不利用非鲁棒特征的对抗样本，并提出了基于集成的方法来量化对抗扰动对非鲁棒特征的操纵程度。


<details>
  <summary>Details</summary>
Motivation: 现有非鲁棒特征理论虽然解释了对抗攻击的广泛存在性，但忽略了那些不直接利用非鲁棒特征的对抗样本。作者认为这两种对抗样本代表了不同类型的对抗弱点，需要区分评估对抗鲁棒性。

Method: 提出基于集成的度量方法，用于测量对抗扰动对非鲁棒特征的操纵程度，并使用该度量分析攻击者生成的对抗样本的组成结构。

Result: 通过新度量方法能够区分不同类型的对抗样本，并重新审视多个现象，包括锐度感知最小化对对抗鲁棒性的影响，以及在鲁棒数据集上对抗训练和标准训练之间的鲁棒性差距。

Conclusion: 对抗弱点存在不同类型，需要区分评估。提出的度量方法为分析对抗样本组成提供了新视角，有助于更全面地理解对抗鲁棒性现象。

Abstract: Over the past decade, numerous theories have been proposed to explain the widespread vulnerability of deep neural networks to adversarial evasion attacks. Among these, the theory of non-robust features proposed by Ilyas et al. has been widely accepted, showing that brittle but predictive features of the data distribution can be directly exploited by attackers. However, this theory overlooks adversarial samples that do not directly utilize these features. In this work, we advocate that these two kinds of samples - those which use use brittle but predictive features and those that do not - comprise two types of adversarial weaknesses and should be differentiated when evaluating adversarial robustness. For this purpose, we propose an ensemble-based metric to measure the manipulation of non-robust features by adversarial perturbations and use this metric to analyze the makeup of adversarial samples generated by attackers. This new perspective also allows us to re-examine multiple phenomena, including the impact of sharpness-aware minimization on adversarial robustness and the robustness gap observed between adversarially training and standard training on robust datasets.

</details>


### [111] [HFedMoE: Resource-aware Heterogeneous Federated Learning with Mixture-of-Experts](https://arxiv.org/abs/2601.00583)
*Zihan Fang,Zheng Lin,Senkang Hu,Yanan Ma,Yihang Tao,Yiqin Deng,Xianhao Chen,Yuguang Fang*

Main category: cs.LG

TL;DR: HFedMoE：一种基于MoE的异构联邦学习框架，用于高效微调大语言模型，通过专家重要性评估、自适应专家选择和稀疏感知聚合解决资源受限设备上的计算挑战。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然能保护数据隐私，但大语言模型在资源受限设备上训练不切实际。MoE模型通过稀疏激活专家减少计算负担，但在FL环境中面临三个关键挑战：1) 缺乏可靠指标评估专家对本地微调性能的影响；2) 异构计算资源限制MoE专家激活；3) 客户端特定专家子集和路由偏好破坏全局聚合。

Method: 提出HFedMoE框架：1) 基于专家对微调性能的贡献评估专家重要性；2) 从信息瓶颈角度自适应选择专家子集以匹配客户端计算预算；3) 设计稀疏感知模型聚合策略，通过重要性加权聚合活跃微调的专家和门控参数。

Result: 大量实验表明，HFedMoE在训练准确率和收敛速度方面优于最先进的基准方法。

Conclusion: HFedMoE成功解决了MoE在联邦学习环境中面临的挑战，通过专家重要性评估、自适应选择和稀疏感知聚合，实现了在异构资源受限设备上的高效大语言模型微调。

Abstract: While federated learning (FL) enables fine-tuning of large language models (LLMs) without compromising data privacy, the substantial size of an LLM renders on-device training impractical for resource-constrained clients, such as mobile devices. Thus, Mixture-of-Experts (MoE) models have emerged as a computation-efficient solution, which activates only a sparse subset of experts during model training to reduce computing burden without sacrificing performance. Though integrating MoE into FL fine-tuning holds significant potential, it still encounters three key challenges: i) selecting appropriate experts for clients remains challenging due to the lack of a reliable metric to measure each expert's impact on local fine-tuning performance, ii) the heterogeneous computing resources across clients severely hinder MoE-based LLM fine-tuning, as dynamic expert activations across diverse input samples can overwhelm resource-constrained devices, and iii) client-specific expert subsets and routing preference undermine global aggregation, where misaligned expert updates and inconsistent gating networks in troduce destructive interference. To address these challenges, we propose HFedMoE, a heterogeneous MoE-based FL fine-tuning framework that customizes a subset of experts to each client for computation-efficient LLM fine-tuning. Specifically, HFedMoE identifies the expert importance based on its contributions to fine-tuning performance, and then adaptively selects a subset of experts from an information bottleneck perspective to align with each client' s computing budget. A sparsity-aware model aggregation strategy is also designed to aggregate the actively fine-tuned experts and gating parameters with importance weighted contributions. Extensive experiments demonstrate that HFedMoE outperforms state-of-the-art benchmarks in training accuracy and convergence speed.

</details>


### [112] [Stronger Approximation Guarantees for Non-Monotone γ-Weakly DR-Submodular Maximization](https://arxiv.org/abs/2601.00611)
*Hareshkumar Jadav,Ranveer Singh,Vaneet Aggarwal*

Main category: cs.LG

TL;DR: 提出一种用于在向下封闭凸体上最大化非负、非单调γ-弱DR-次模函数的近似算法，其保证平滑依赖于γ，在γ=1时恢复0.401近似比，在γ<1时性能优雅下降并优于现有结果。


<details>
  <summary>Details</summary>
Motivation: 在机器学习和优化中，约束下的次模目标最大化是一个基础问题。研究非负、非单调γ-弱DR-次模函数在向下封闭凸体上的最大化问题，旨在提供性能保证平滑依赖于γ的算法。

Method: 结合Frank-Wolfe引导的连续贪婪框架与γ感知的双贪婪步骤，形成处理非单调性的简单有效方法。该方法通过连续贪婪框架处理约束，双贪婪步骤处理非单调性。

Result: 算法性能保证平滑依赖于γ：当γ=1（DR-次模情况）时恢复0.401近似比；当γ<1时，保证优雅下降且优于先前报道的γ-弱DR-次模最大化结果，实现了该问题的最先进性能保证。

Conclusion: 提出的算法为在向下封闭凸体上最大化非单调γ-弱DR-次模函数提供了最先进的性能保证，其近似比平滑依赖于γ，在DR-次模特例下恢复已知最佳结果，在弱次模情况下优于现有方法。

Abstract: Maximizing submodular objectives under constraints is a fundamental problem in machine learning and optimization. We study the maximization of a nonnegative, non-monotone $γ$-weakly DR-submodular function over a down-closed convex body. Our main result is an approximation algorithm whose guarantee depends smoothly on $γ$; in particular, when $γ=1$ (the DR-submodular case) our bound recovers the $0.401$ approximation factor, while for $γ<1$ the guarantee degrades gracefully and, it improves upon previously reported bounds for $γ$-weakly DR-submodular maximization under the same constraints. Our approach combines a Frank-Wolfe-guided continuous-greedy framework with a $γ$-aware double-greedy step, yielding a simple yet effective procedure for handling non-monotonicity. This results in state-of-the-art guarantees for non-monotone $γ$-weakly DR-submodular maximization over down-closed convex bodies.

</details>


### [113] [Do Chatbot LLMs Talk Too Much? The YapBench Benchmark](https://arxiv.org/abs/2601.00624)
*Vadim Borisov,Michael Gröger,Mina Mikhael,Richard H. Schreiber*

Main category: cs.LG

TL;DR: YapBench是一个轻量级基准测试，用于量化LLM在简洁理想提示上的过度生成问题，通过YapScore测量超出基准答案的额外长度，评估了76个助手型LLM的冗余回答行为。


<details>
  <summary>Details</summary>
Motivation: 当前LLM（如ChatGPT、Claude、Gemini）作为通用助手时，经常对简单请求给出不必要的冗长回答，包含冗余解释、模糊表述或模板化内容，这增加了认知负担和推理成本。先前研究表明基于偏好的后训练和LLM评判评估可能导致系统性长度偏差，即更长的回答即使质量相当也会获得更高评分。

Method: 引入YapBench基准测试，包含300多个英文提示，涵盖三种简洁理想场景：(A)最小或模糊输入，理想行为是简短澄清；(B)封闭式事实问题，有简短稳定答案；(C)单行编码任务，只需单个命令或代码片段。每个项目包含单轮提示、精心策划的最小充分基准答案和类别标签。主要指标YapScore测量响应超出基准的字符数，YapIndex通过类别级中位数YapScore的均匀加权平均总结模型性能。

Result: 评估76个助手型LLM，观察到中位数超额长度存在数量级差异，并识别出特定类别的失败模式：在模糊输入上的"真空填充"行为，以及在单行技术请求上的解释或格式化开销。基准测试和实时排行榜已发布，用于跟踪冗长行为随时间的变化。

Conclusion: YapBench为量化LLM过度生成提供了标准化评估框架，揭示了当前助手模型在简洁性方面的显著差异和系统性问题，有助于推动更高效、用户友好的LLM响应设计。

Abstract: Large Language Models (LLMs) such as ChatGPT, Claude, and Gemini increasingly act as general-purpose copilots, yet they often respond with unnecessary length on simple requests, adding redundant explanations, hedging, or boilerplate that increases cognitive load and inflates token-based inference cost. Prior work suggests that preference-based post-training and LLM-judged evaluations can induce systematic length bias, where longer answers are rewarded even at comparable quality.
  We introduce YapBench, a lightweight benchmark for quantifying user-visible over-generation on brevity-ideal prompts. Each item consists of a single-turn prompt, a curated minimal-sufficient baseline answer, and a category label. Our primary metric, YapScore, measures excess response length beyond the baseline in characters, enabling comparisons across models without relying on any specific tokenizer. We summarize model performance via the YapIndex, a uniformly weighted average of category-level median YapScores.
  YapBench contains over three hundred English prompts spanning three common brevity-ideal settings: (A) minimal or ambiguous inputs where the ideal behavior is a short clarification, (B) closed-form factual questions with short stable answers, and (C) one-line coding tasks where a single command or snippet suffices. Evaluating 76 assistant LLMs, we observe an order-of-magnitude spread in median excess length and distinct category-specific failure modes, including vacuum-filling on ambiguous inputs and explanation or formatting overhead on one-line technical requests. We release the benchmark and maintain a live leaderboard for tracking verbosity behavior over time.

</details>


### [114] [Interpretability-Guided Bi-objective Optimization: Aligning Accuracy and Explainability](https://arxiv.org/abs/2601.00655)
*Kasra Fouladi,Hamta Rahmani*

Main category: cs.LG

TL;DR: IGBO框架通过双目标优化训练可解释模型，利用DAG编码特征重要性层次结构，使用TIG测量特征重要性，并引入最优路径预言机解决TIG的OOD问题。


<details>
  <summary>Details</summary>
Motivation: 现有可解释模型训练方法缺乏对结构化领域知识的有效整合，且特征重要性测量方法存在OOD问题，需要一种能够结合领域知识并解决计算问题的框架。

Method: 提出IGBO框架：1) 将特征重要性层次编码为DAG；2) 使用TIG测量特征重要性；3) 引入最优路径预言机解决TIG的OOD问题；4) 采用双目标优化平衡可解释性和准确性。

Result: 理论分析证明了收敛性和对mini-batch噪声的鲁棒性；时间序列数据上的实验显示IGBO能有效实施DAG约束，精度损失最小，优于标准正则化基线方法。

Conclusion: IGBO成功整合了结构化领域知识到模型训练中，通过双目标优化和最优路径预言机解决了可解释性测量中的关键问题，为可解释机器学习提供了有效框架。

Abstract: This paper introduces Interpretability-Guided Bi-objective Optimization (IGBO), a framework that trains interpretable models by incorporating structured domain knowledge via a bi-objective formulation. IGBO encodes feature importance hierarchies as a Directed Acyclic Graph (DAG) and uses Temporal Integrated Gradients (TIG) to measure feature importance. To address the Out-of-Distribution (OOD) problem in TIG computation, we propose an Optimal Path Oracle that learns data-manifold-aware integration paths. Theoretical analysis proves convergence properties and robustness to mini-batch noise, while empirical results on time-series data demonstrate IGBO's effectiveness in enforcing DAG constraints with minimal accuracy loss, outperforming standard regularization baselines.

</details>


### [115] [IRPO: Scaling the Bradley-Terry Model via Reinforcement Learning](https://arxiv.org/abs/2601.00677)
*Haonan Song,Qingchen Xie,Huan Zhu,Feng Xiao,Luxi Xing,Fuzhen Li,Liu Kang,Feng Jiang,Zhiyong Zheng,Fan Yang*

Main category: cs.LG

TL;DR: IRPO提出了一种新的强化学习框架，通过将Bradley-Terry模型融入GRPO，用点式评分替代成对比较，解决了成对生成奖励模型的计算瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 成对生成奖励模型（GRMs）在强化学习中存在计算瓶颈：1）成对比较的O(n²)时间复杂度；2）重复采样或链式推理带来的计算开销。这限制了GRMs与GRPO等强化学习算法的集成效率。

Method: 提出Intergroup Relative Preference Optimization（IRPO）框架，将Bradley-Terry模型融入Group Relative Policy Optimization（GRPO）。该方法为每个响应生成点式评分，使得在强化学习训练中能够高效评估任意数量的候选响应，同时保持可解释性和细粒度奖励信号。

Result: IRPO在多个基准测试中实现了点式GRMs中的最先进性能，性能与当前领先的成对GRMs相当。在训练后评估中，IRPO显著优于成对GRMs。

Conclusion: IRPO通过点式评分机制有效解决了成对GRMs的计算瓶颈问题，在保持可解释性和细粒度奖励的同时，实现了高效强化学习训练，为生成奖励模型的实用化提供了新思路。

Abstract: Generative Reward Models (GRMs) have attracted considerable research interest in reward modeling due to their interpretability, inference-time scalability, and potential for refinement through reinforcement learning (RL). However, widely used pairwise GRMs create a computational bottleneck when integrated with RL algorithms such as Group Relative Policy Optimization (GRPO). This bottleneck arises from two factors: (i) the O(n^2) time complexity of pairwise comparisons required to obtain relative scores, and (ii) the computational overhead of repeated sampling or additional chain-of-thought (CoT) reasoning to improve performance. To address the first factor, we propose Intergroup Relative Preference Optimization (IRPO), a novel RL framework that incorporates the well-established Bradley-Terry model into GRPO. By generating a pointwise score for each response, IRPO enables efficient evaluation of arbitrarily many candidates during RL training while preserving interpretability and fine-grained reward signals. Experimental results demonstrate that IRPO achieves state-of-the-art (SOTA) performance among pointwise GRMs across multiple benchmarks, with performance comparable to that of current leading pairwise GRMs. Furthermore, we show that IRPO significantly outperforms pairwise GRMs in post-training evaluations.

</details>


### [116] [ARISE: Adaptive Reinforcement Integrated with Swarm Exploration](https://arxiv.org/abs/2601.00693)
*Rajiv Chaitanya M,D R Ramesh Babu*

Main category: cs.LG

TL;DR: ARISE：一个轻量级框架，通过添加基于粒子群的探索层来增强强化学习，在非平稳奖励和高维策略任务中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 强化学习中的有效探索仍然是一个关键挑战，特别是在非平稳奖励或高维策略的情况下。现有方法在复杂任务中的探索能力有限，需要更有效的探索机制来提升性能。

Method: ARISE框架在标准策略梯度方法基础上增加了一个紧凑的基于粒子群的探索层。它将策略动作与粒子驱动的提议混合，每个粒子代表在动作空间中采样的候选策略轨迹，并使用奖励方差线索自适应地调节探索强度。

Result: 在简单基准测试中只有轻微改进（CartPole-v1 +0.7%），但在更具挑战性的任务中取得了显著提升：LunarLander-v3 +46%，Hopper-v4 +22%，同时在Walker2d和Ant上保持稳定性。在非平稳奖励变化下，ARISE表现出明显的鲁棒性优势，在CartPole上比PPO高出75分，在LunarLander上也有相应改进。

Conclusion: ARISE提供了一个简单、架构无关的途径，可以在不改变核心算法结构的情况下，创建更具探索性和鲁棒性的强化学习智能体。消融研究证实了粒子群组件和自适应机制都对性能有贡献。

Abstract: Effective exploration remains a key challenge in RL, especially with non-stationary rewards or high-dimensional policies. We introduce ARISE, a lightweight framework that enhances reinforcement learning by augmenting standard policy-gradient methods with a compact swarm-based exploration layer. ARISE blends policy actions with particle-driven proposals, where each particle represents a candidate policy trajectory sampled in the action space, and modulates exploration adaptively using reward-variance cues. While easy benchmarks exhibit only slight improvements (e.g., +0.7% on CartPole-v1), ARISE yields substantial gains on more challenging tasks, including +46% on LunarLander-v3 and +22% on Hopper-v4, while preserving stability on Walker2d and Ant. Under non-stationary reward shifts, ARISE provides marked robustness advantages, outperforming PPO by +75 points on CartPole and improving LunarLander accordingly. Ablation studies confirm that both the swarm component and the adaptive mechanism contribute to the performance. Overall, ARISE offers a simple, architecture-agnostic route to more exploratory and resilient RL agents without altering core algorithmic structures.

</details>


### [117] [Bayesian Inverse Games with High-Dimensional Multi-Modal Observations](https://arxiv.org/abs/2601.00696)
*Yash Jain,Xinjie Liu,Lasse Peters,David Fridovich-Keil,Ufuk Topcu*

Main category: cs.LG

TL;DR: 提出基于贝叶斯推理的逆博弈框架，通过变分自编码器嵌入可微分纳什博弈求解器，从交互数据中学习智能体目标的先验和后验分布，提高推断质量并实现更安全的下游决策。


<details>
  <summary>Details</summary>
Motivation: 现有逆博弈方法仅提供点估计，无法量化估计不确定性，导致下游规划决策可能过度自信地采取不安全行动。需要一种能够处理多模态观测数据、实时生成后验分布样本的贝叶斯推理方法。

Method: 提出贝叶斯逆博弈框架：训练结构化变分自编码器，嵌入可微分纳什博弈求解器，从交互数据集中学习智能体目标的先验和后验分布，无需真实目标标签。支持多模态推理，在轨迹信息不充分时利用额外观测模态减少不确定性。

Result: 框架成功学习先验和后验分布，相比基于最大似然估计的逆博弈方法提高了推断质量，实现了更安全的下游决策而不牺牲效率。多模态推理在轨迹信息不充分时进一步减少不确定性。

Conclusion: 贝叶斯逆博弈框架通过量化不确定性，解决了现有逆博弈方法过度自信的问题，为自主决策提供了更安全可靠的智能体目标推断方法，特别是在多模态观测场景下表现更优。

Abstract: Many multi-agent interaction scenarios can be naturally modeled as noncooperative games, where each agent's decisions depend on others' future actions. However, deploying game-theoretic planners for autonomous decision-making requires a specification of all agents' objectives. To circumvent this practical difficulty, recent work develops maximum likelihood techniques for solving inverse games that can identify unknown agent objectives from interaction data. Unfortunately, these methods only infer point estimates and do not quantify estimator uncertainty; correspondingly, downstream planning decisions can overconfidently commit to unsafe actions. We present an approximate Bayesian inference approach for solving the inverse game problem, which can incorporate observation data from multiple modalities and be used to generate samples from the Bayesian posterior over the hidden agent objectives given limited sensor observations in real time. Concretely, the proposed Bayesian inverse game framework trains a structured variational autoencoder with an embedded differentiable Nash game solver on interaction datasets and does not require labels of agents' true objectives. Extensive experiments show that our framework successfully learns prior and posterior distributions, improves inference quality over maximum likelihood estimation-based inverse game approaches, and enables safer downstream decision-making without sacrificing efficiency. When trajectory information is uninformative or unavailable, multimodal inference further reduces uncertainty by exploiting additional observation modalities.

</details>


### [118] [BSAT: B-Spline Adaptive Tokenizer for Long-Term Time Series Forecasting](https://arxiv.org/abs/2601.00698)
*Maximilian Reinwardt,Michael Eichelbeck,Matthias Althoff*

Main category: cs.LG

TL;DR: 提出BSAT方法，使用B样条自适应分词器解决长时序预测中自注意力二次复杂度和均匀分块不匹配语义结构的问题，结合L-RoPE混合位置编码，在内存受限场景下实现高压缩率下的强性能。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在长时序预测中存在两个主要问题：自注意力的二次复杂度导致计算效率低下，以及均匀分块方式可能与数据的语义结构不匹配。需要一种既能适应数据内在结构又能高效压缩的方法。

Method: 提出B样条自适应分词器(BSAT)，通过拟合B样条自适应分割时间序列，在高曲率区域放置token，将变长基函数表示为固定大小的token（包含系数和位置）。同时提出L-RoPE混合位置编码，结合可学习的加性位置编码和具有层间可学习基数的旋转位置嵌入，使每层能关注不同的时间依赖关系。

Result: 在多个公开基准测试中，模型在高压缩率下表现出强大的竞争力，特别适合内存约束严格的使用场景。

Conclusion: BSAT提供了一种参数自由的自适应分词方法，结合L-RoPE混合位置编码，有效解决了长时序预测中的计算效率和语义对齐问题，在内存受限环境下具有实用价值。

Abstract: Long-term time series forecasting using transformers is hampered by the quadratic complexity of self-attention and the rigidity of uniform patching, which may be misaligned with the data's semantic structure. In this paper, we introduce the \textit{B-Spline Adaptive Tokenizer (BSAT)}, a novel, parameter-free method that adaptively segments a time series by fitting it with B-splines. BSAT algorithmically places tokens in high-curvature regions and represents each variable-length basis function as a fixed-size token, composed of its coefficient and position. Further, we propose a hybrid positional encoding that combines a additive learnable positional encoding with Rotary Positional Embedding featuring a layer-wise learnable base: L-RoPE. This allows each layer to attend to different temporal dependencies. Our experiments on several public benchmarks show that our model is competitive with strong performance at high compression rates. This makes it particularly well-suited for use cases with strong memory constraints.

</details>


### [119] [Precision Autotuning for Linear Solvers via Contextual Bandit-Based RL](https://arxiv.org/abs/2601.00728)
*Erin Carson,Xinye Chen*

Main category: cs.LG

TL;DR: 提出基于强化学习的自适应精度调优框架，用于线性求解器和其他算法，通过上下文多臂老虎机问题动态选择计算步骤的最优精度配置，在保持精度的同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统数值计算中固定精度方法效率低下，混合精度计算需要手动调优。为自动平衡计算精度与效率，需要开发自适应精度选择框架，减少人工调参负担并优化计算性能。

Method: 将精度调优建模为上下文多臂老虎机问题，使用离散化状态空间和增量动作值估计。通过Q表映射离散化特征（如近似条件数和矩阵范数）到精度配置动作，采用epsilon-greedy策略优化多目标奖励函数（平衡精度和计算成本）。在迭代求精求解线性系统Ax=b中验证框架有效性。

Result: 实验结果表明框架能有效选择精度配置，在保持与双精度基线相当精度的同时显著降低计算成本。框架具有良好的泛化能力，在未见数据集上表现稳定，为混合精度数值方法提供了新思路。

Conclusion: 该强化学习框架首次实现了精度自动调优，成功应用于线性求解器并验证了泛化能力。为科学计算中的混合精度数值方法提供了新范式，可扩展到其他数值算法，推动自适应精度计算的发展。

Abstract: We propose a reinforcement learning (RL) framework for adaptive precision tuning of linear solvers, and can be extended to general algorithms. The framework is formulated as a contextual bandit problem and solved using incremental action-value estimation with a discretized state space to select optimal precision configurations for computational steps, balancing precision and computational efficiency. To verify its effectiveness, we apply the framework to iterative refinement for solving linear systems $Ax = b$. In this application, our approach dynamically chooses precisions based on calculated features from the system. In detail, a Q-table maps discretized features (e.g., approximate condition number and matrix norm)to actions (chosen precision configurations for specific steps), optimized via an epsilon-greedy strategy to maximize a multi-objective reward balancing accuracy and computational cost. Empirical results demonstrate effective precision selection, reducing computational cost while maintaining accuracy comparable to double-precision baselines. The framework generalizes to diverse out-of-sample data and offers insight into utilizing RL precision selection for other numerical algorithms, advancing mixed-precision numerical methods in scientific computing. To the best of our knowledge, this is the first work on precision autotuning with RL and verified on unseen datasets.

</details>


### [120] [The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving](https://arxiv.org/abs/2601.00747)
*Max Ruiz Luyten,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: 本文分析了当前LLM推理管道依赖自举推理循环的局限性，提出了分布创造性推理（DCR）的统一变分目标框架，揭示了基于正确性的目标导致多样性衰减的问题，并提供了防止崩溃的实用方案。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的LLM管道依赖自举推理循环（采样多样化的思维链并强化得分最高的路径），主要优化正确性。这种设计选择对模型在推理路径上的分布崩溃敏感，会削减语义熵并削弱创造性问题解决能力。需要分析这种失败模式并找到解决方案。

Method: 引入分布创造性推理（DCR），这是一个统一的变分目标框架，将训练视为通过解决方案轨迹概率测度的梯度流。STaR、GRPO、DPO以及熵奖励等方法都是该损失函数的特例。该框架提供了三个核心结果：多样性衰减定理、确保收敛到稳定多样策略的设计、以及实现这一目标的简单实用方案。

Result: DCR框架揭示了基于正确性的目标如何导致STaR、GRPO和DPO的不同多样性衰减模式；提出了防止分布崩溃的设计方案；提供了保持LLM既正确又创造性的首个原则性方案。

Conclusion: DCR为LLM提供了保持正确性和创造性的原则性框架，解决了当前自举推理循环导致的分布崩溃问题，通过统一的变分目标实现了稳定多样的策略收敛。

Abstract: State-of-the-art large language model (LLM) pipelines rely on bootstrapped reasoning loops: sampling diverse chains of thought and reinforcing the highest-scoring ones, mainly optimizing correctness. We analyze how this design choice is sensitive to the collapse of the model's distribution over reasoning paths, slashing semantic entropy and undermining creative problem-solving. To analyze this failure, we introduce Distributional Creative Reasoning (DCR), a unified variational objective that casts training as gradient flow through probability measures on solution traces. STaR, GRPO, and DPO, as well as entropy bonuses, and other methods, all constitute special cases of the same loss. The framework delivers three core results: (i) the diversity decay theorem, describing how correctness-based objectives lead to distinct modes of diversity decay for STaR, GRPO, and DPO; (ii) designs that ensure convergence to a stable and diverse policy, effectively preventing collapse; and (iii) simple, actionable recipes to achieve this in practice. DCR thus offers the first principled recipe for LLMs that remain both correct and creative.

</details>


### [121] [A Machine Learning Framework for Off Ball Defensive Role and Performance Evaluation in Football](https://arxiv.org/abs/2601.00748)
*Sean Groom,Shuo Wang,Francisco Belo,Axl Rice,Liam Anderson*

Main category: cs.LG

TL;DR: 提出基于协变量依赖隐马尔可夫模型(CDHMM)的角球防守评估框架，通过球员追踪数据推断盯人与区域防守任务，实现无标签的防守贡献归因和角色条件反事实分析。


<details>
  <summary>Details</summary>
Motivation: 足球中无球防守表现难以评估，传统指标无法捕捉限制对手行动选择的协调运动。现有价值模型主要评估有球动作，反事实方法(如ghosting模型)依赖缺乏战术背景的"平均"行为模拟。

Method: 针对角球这一高度结构化场景，提出协变量依赖隐马尔可夫模型(CDHMM)，直接从球员追踪数据推断时间分辨的盯人和区域防守任务分配。基于此提出防守贡献归因框架和角色条件ghosting方法进行反事实分析。

Result: 模型能够无标签地推断角球防守中的盯人与区域任务分配，提供可解释的防守贡献评估，相比基于上下文感知基线的传统方法更具战术相关性。

Conclusion: CDHMM框架为结构化场景(如角球)的无球防守评估提供了新方法，通过角色条件反事实分析实现了对防守贡献的更准确、更可解释的量化评估。

Abstract: Evaluating off-ball defensive performance in football is challenging, as traditional metrics do not capture the nuanced coordinated movements that limit opponent action selection and success probabilities. Although widely used possession value models excel at appraising on-ball actions, their application to defense remains limited. Existing counterfactual methods, such as ghosting models, help extend these analyses but often rely on simulating "average" behavior that lacks tactical context. To address this, we introduce a covariate-dependent Hidden Markov Model (CDHMM) tailored to corner kicks, a highly structured aspect of football games. Our label-free model infers time-resolved man-marking and zonal assignments directly from player tracking data. We leverage these assignments to propose a novel framework for defensive credit attribution and a role-conditioned ghosting method for counterfactual analysis of off-ball defensive performance. We show how these contributions provide a interpretable evaluation of defensive contributions against context-aware baselines.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [122] [Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models](https://arxiv.org/abs/2601.00003)
*Shuqi Liu,Bowei He,Chen Ma,Linqi Song*

Main category: cs.AI

TL;DR: 本文提出了一种推理感知的知识检索方法，通过粗到细的两阶段检索策略，结合蒙特卡洛树搜索，为LLMs提供与对话逻辑结构对齐的知识，超越表面语义相似性。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs通常通过检索语义相似信息或提升推理能力来增强性能，但如何有效整合检索和推理策略以优化LLM性能仍是一个重要挑战。需要超越表面语义相似性，提供与对话逻辑结构对齐的知识。

Method: 提出推理感知的知识检索方法，采用粗到细的两阶段检索：1) 识别知识库中与上下文相关的子区域，确保所有句子都与上下文主题相关；2) 在该子区域内细化搜索，提取与推理过程特别相关的知识。两阶段均采用蒙特卡洛树搜索启发的方法，通过常用关键词在知识句子中有效导航。

Result: 在两个多轮对话数据集上的实验表明，该方法不仅更紧密地与人际对话中的底层推理对齐，还显著提高了检索知识的多样性，从而产生更具信息量和创造性的响应。

Conclusion: 提出的推理感知知识检索方法通过整合检索和推理策略，为LLMs提供与对话逻辑结构对齐的知识，超越了传统的语义相似性检索，显著提升了LLM在多轮对话中的表现。

Abstract: Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.

</details>


### [123] [Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study](https://arxiv.org/abs/2601.00004)
*Isaac Iyinoluwa Olufadewa,Miracle Ayomikun Adesina,Ezekiel Ayodeji Oladejo,Uthman Babatunde Usman,Owen Kolade Adeniyi,Matthew Tolulope Olawoyin*

Main category: cs.AI

TL;DR: 该研究开发了一种基于大语言模型的尼日利亚皮钦语抑郁症自动筛查系统，通过收集432个音频响应数据集，对三种LLM进行微调，GPT-4.1在PHQ-9严重程度评分预测中达到94.5%准确率，为资源受限环境提供文化适宜的筛查工具。


<details>
  <summary>Details</summary>
Motivation: 尼日利亚抑郁症筛查覆盖率低，传统工具如PHQ-9在高收入国家验证，但可能因语言文化障碍不适用于尼日利亚等中低收入国家，当地使用尼日利亚皮钦语和520多种方言，需要开发适应本地语言文化的筛查方法。

Method: 收集432个尼日利亚18-40岁年轻人对PHQ-9相关心理体验的皮钦语音频响应，进行转录、预处理和标注（语义标签、俚语解释、PHQ-9严重程度评分）。对三种LLM（Phi-3-mini-4k-instruct、Gemma-3-4B-it、GPT-4.1）进行微调，通过定量（准确性、精确度、语义对齐）和定性（清晰度、相关性、文化适宜性）评估性能。

Result: GPT-4.1表现最佳，在PHQ-9严重程度评分预测中达到94.5%准确率，优于Gemma-3-4B-it和Phi-3-mini-4k-instruct。定性评估也显示GPT-4.1产生最文化适宜、清晰且上下文相关的响应。

Conclusion: AI介导的抑郁症筛查可为尼日利亚服务不足社区提供有效工具，为在语言多样、资源受限环境中部署对话式心理健康工具奠定基础，解决了传统筛查工具的语言文化障碍问题。

Abstract: Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.

</details>


### [124] [A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system](https://arxiv.org/abs/2601.00023)
*Luis M. Moreno-Saavedra,Silvia Jimenez-Fernandez,Antonio Portilla-Figueras,David Casillas-Perez,Sancho Salcedo-Sanz*

Main category: cs.AI

TL;DR: 提出一种多算法方法来解决最后一公里包裹配送中的人力资源工作量平衡问题，通过结合距离和工作量考虑来优化包裹分配，确保每位配送员完成相似的工作量。


<details>
  <summary>Details</summary>
Motivation: 传统基于地理邻近性的包裹分配方法效率低下，导致配送员之间工作量分配不均衡。需要优化系统以改善配送时间，实现所有员工之间的完整工作量平衡，纠正特定区域内配送员之间的显著工作量不平衡问题。

Method: 提出多算法方法，包括不同版本的k-means、进化方法、基于k-means初始化的递归分配（采用不同问题编码）以及混合进化集成算法。该方法以配送点集合和工人数量为输入，结合距离和工作量考虑来优化包裹分配。

Result: 在西班牙Azuqueca de Henares城市最后一公里包裹配送运营的实际问题中展示了所提方法的性能表现。

Conclusion: 通过多算法方法有效解决了最后一公里包裹配送中的人力资源工作量平衡问题，优化了配送时间并实现了配送员之间的工作量均衡分配。

Abstract: Efficient workload assignment to the workforce is critical in last-mile package delivery systems. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have illustrated the performance of the proposed approach in a real-world problem in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Spain.

</details>


### [125] [Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach](https://arxiv.org/abs/2601.00024)
*Purushottam Saha,Avirup Chakraborty,Sourish Sarkar,Subhamoy Maitra,Diganta Mukherjee,Tridib Mukherjee*

Main category: cs.AI

TL;DR: 提出基于MinDist度量的规则框架用于13张牌印度拉米纸牌游戏，通过编辑距离量化手牌与有效配置的接近程度，结合对手建模和零和模拟，显著提升胜率


<details>
  <summary>Details</summary>
Motivation: 13张牌印度拉米纸牌是一种不完全信息顺序游戏，需要概率推理和组合决策。传统启发式方法缺乏形式化框架，需要一种既能量化手牌结构接近完成度又能高效计算的度量方法

Method: 提出MinDist度量，修改MinScore度量，通过编辑距离量化手牌与最近有效配置的距离；设计计算高效算法，基于MinScore算法，利用动态剪枝和模式缓存；在两人零和模拟框架中结合对手手牌建模；使用统计假设检验评估策略

Result: 实证结果显示，基于MinDist的智能体相比传统启发式方法在胜率上有显著提升，为算法化拉米策略设计提供了形式化和可解释的步骤

Conclusion: MinDist度量有效捕捉手牌结构接近完成度，结合高效算法和对手建模的框架在印度拉米游戏中表现出优越性能，为不完全信息纸牌游戏的算法策略设计提供了新方向

Abstract: The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifies the MinScore metric by quantifying the edit distance between a hand and the nearest valid configuration, thereby capturing structural proximity to completion. We design a computationally efficient algorithm derived from the MinScore algorithm, leveraging dynamic pruning and pattern caching to exactly calculate this metric during play. Opponent hand-modeling is also incorporated within a two-player zero-sum simulation framework, and the resulting strategies are evaluated using statistical hypothesis testing. Empirical results show significant improvement in win rates for MinDist-based agents over traditional heuristics, providing a formal and interpretable step toward algorithmic Rummy strategy design.

</details>


### [126] [From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers](https://arxiv.org/abs/2601.00029)
*Abolhassan Pishahang,Maryam Badiei*

Main category: cs.AI

TL;DR: 研究探讨生成式AI如何解读乡土建筑中的建筑智能，以伊朗鸽塔为案例，测试三种扩散模型在不同提示阶段的表现，评估AI对建筑类型、材料、环境、真实性和文化特异性的重构能力。


<details>
  <summary>Details</summary>
Motivation: 探究生成式AI系统如何理解和重构乡土建筑形式中蕴含的建筑智能，分析AI在视觉相似性与建筑推理之间的边界，为理解AI如何感知、扭曲和重新想象传统设计智能提供框架。

Method: 以伊朗鸽塔为案例研究，测试Midjourney v6、DALL-E 3和基于Stable Diffusion XL的DreamStudio三种扩散模型，采用三个提示阶段：参考性、适应性和推测性，通过五标准评估框架（类型学、材料性、环境、真实性和文化特异性）进行分析。

Result: AI能可靠地复制几何图案，但误读材料和气候推理；参考图像提高了真实性但限制了创造性，而无参考的自由生成则产生创新但文化模糊的结果；定义了视觉相似性与建筑推理之间的边界。

Conclusion: 计算乡土推理可作为分析AI如何感知、扭曲和重新想象传统设计智能的框架，揭示了AI在建筑智能理解方面的局限性，特别是对材料和环境推理的误读，为未来AI在建筑领域的应用提供了重要见解。

Abstract: This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.

</details>


### [127] [The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs](https://arxiv.org/abs/2601.00097)
*Akash Kumar Panda,Olaoluwa Adigun,Bart Kosko*

Main category: cs.AI

TL;DR: 提出一个基于大语言模型的智能体，能够从原始文本中提取因果反馈模糊认知图，并通过双向交互实现动态系统的准自主演化。


<details>
  <summary>Details</summary>
Motivation: 传统模糊认知图构建依赖人工标注，过程耗时且主观。需要开发自动化方法从文本中提取因果结构，同时保持系统在动态演化中的准自主性。

Method: 设计三阶段系统指令引导LLM智能体：1) 从文本提取关键名词和名词短语；2) 从中选择FCM概念节点；3) 推断节点间的模糊因果边。测试于基辛格关于AI的论文，并混合不同LLM生成的FCM。

Result: LLM生成的FCM与人工生成的FCM收敛到相同的平衡极限环，尽管节点和边数量不同。混合FCM不仅吸收了主要组分的平衡点，还创建了新的平衡点以更好逼近底层因果动态系统。

Conclusion: LLM智能体能够有效从文本提取因果结构，构建的FCM动态系统具有准自主演化能力。混合不同LLM生成的FCM可以产生更丰富的平衡行为，更好地模拟真实因果系统。

Abstract: We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.

</details>


### [128] [Mortar: Evolving Mechanics for Automatic Game Design](https://arxiv.org/abs/2601.00105)
*Muhammad U. Nasir,Yuchen Li,Steven James,Julian Togelius*

Main category: cs.AI

TL;DR: Mortar系统结合质量多样性算法与大语言模型，自主演化游戏机制，通过合成完整游戏评估机制质量，生成多样且可玩的游戏。


<details>
  <summary>Details</summary>
Motivation: 游戏机制设计是耗时且依赖专家经验的过程，需要自动化方法来探索多样化的游戏机制设计空间。

Method: 结合质量多样性算法与大语言模型探索多样化机制，通过树搜索合成完整游戏进行评估，基于技能排序（强玩家始终优于弱玩家）作为评估标准。

Result: Mortar生成多样且可玩的游戏，其机制在技能排序得分上表现更好，消融研究和用户研究验证了系统组件的有效性。

Conclusion: Mortar系统成功实现了游戏机制的自主演化，为自动游戏设计提供了有效框架，结合算法与语言模型的方法具有潜力。

Abstract: We present Mortar, a system for autonomously evolving game mechanics for automatic game design. Game mechanics define the rules and interactions that govern gameplay, and designing them manually is a time-consuming and expert-driven process. Mortar combines a quality-diversity algorithm with a large language model to explore a diverse set of mechanics, which are evaluated by synthesising complete games that incorporate both evolved mechanics and those drawn from an archive. The mechanics are evaluated by composing complete games through a tree search procedure, where the resulting games are evaluated by their ability to preserve a skill-based ordering over players -- that is, whether stronger players consistently outperform weaker ones. We assess the mechanics based on their contribution towards the skill-based ordering score in the game. We demonstrate that Mortar produces games that appear diverse and playable, and mechanics that contribute more towards the skill-based ordering score in the game. We perform ablation studies to assess the role of each system component and a user study to evaluate the games based on human feedback.

</details>


### [129] [Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control](https://arxiv.org/abs/2601.00121)
*Yaqi Duan,Yichun Hu,Jiashuo Jiang*

Main category: cs.AI

TL;DR: 本文提出了一种混合智能体框架，将LLM作为自然语言接口与严格优化算法分离，解决了LLM作为端到端求解器时产生的"幻觉税"问题，在库存管理中实现了32.1%的成本降低。


<details>
  <summary>Details</summary>
Motivation: 中小型企业缺乏部署高级优化方法的专业知识，而直接使用LLM作为端到端求解器会产生显著的"幻觉税"——由于模型无法进行基于现实的随机推理而导致的性能差距。

Method: 提出混合智能体框架，严格分离语义推理和数学计算：LLM作为智能接口从自然语言中提取参数并解释结果，同时自动调用严格的算法构建优化引擎。引入Human Imitator（微调的"数字孪生"）来模拟有限理性管理者的行为，实现可扩展、可重复的压力测试。

Result: 混合智能体框架相对于使用GPT-4o作为端到端求解器的交互式基线，将总库存成本降低了32.1%。研究发现，即使提供完美的真实信息也无法改善GPT-4o的性能，确认瓶颈本质上是计算性的而非信息性的。

Conclusion: LLM不应作为运筹学的替代品，而应作为自然语言接口，使非专家能够访问基于严格求解器的策略。混合智能体框架成功地将LLM的语义理解能力与优化算法的计算严谨性相结合。

Abstract: Inventory management remains a challenge for many small and medium-sized businesses that lack the expertise to deploy advanced optimization methods. This paper investigates whether Large Language Models (LLMs) can help bridge this gap. We show that employing LLMs as direct, end-to-end solvers incurs a significant "hallucination tax": a performance gap arising from the model's inability to perform grounded stochastic reasoning. To address this, we propose a hybrid agentic framework that strictly decouples semantic reasoning from mathematical calculation. In this architecture, the LLM functions as an intelligent interface, eliciting parameters from natural language and interpreting results while automatically calling rigorous algorithms to build the optimization engine.
  To evaluate this interactive system against the ambiguity and inconsistency of real-world managerial dialogue, we introduce the Human Imitator, a fine-tuned "digital twin" of a boundedly rational manager that enables scalable, reproducible stress-testing. Our empirical analysis reveals that the hybrid agentic framework reduces total inventory costs by 32.1% relative to an interactive baseline using GPT-4o as an end-to-end solver. Moreover, we find that providing perfect ground-truth information alone is insufficient to improve GPT-4o's performance, confirming that the bottleneck is fundamentally computational rather than informational. Our results position LLMs not as replacements for operations research, but as natural-language interfaces that make rigorous, solver-based policies accessible to non-experts.

</details>


### [130] [Constructing a Neuro-Symbolic Mathematician from First Principles](https://arxiv.org/abs/2601.00125)
*Keqin Xie*

Main category: cs.AI

TL;DR: Mathesis：一种神经符号架构，通过将数学状态编码为高阶超图，使用可微分逻辑引擎将约束映射到连续能量景观，将证明搜索转化为能量最小化问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理中存在持续的逻辑失败，缺乏内部公理化框架，需要新的架构来解决这一问题。

Method: 提出Mathesis神经符号架构：1) 将数学状态编码为高阶超图；2) 使用符号推理核(SRK)——一个可微分逻辑引擎，将约束映射到连续能量景观；3) 定义全局能量函数E(G)，零能量表示逻辑一致性；4) SRK产生基于梯度的信号来训练超图变换器大脑；5) 通过蒙特卡洛树搜索和进化证明搜索实现多步推理，由学习到的价值函数和语义统一指导。

Result: 该方法将证明搜索转化为能量最小化问题，通过梯度信号训练神经组件，实现逻辑一致的推理。

Conclusion: Mathesis架构通过神经符号方法解决了LLMs在复杂推理中的逻辑失败问题，将逻辑约束编码为能量最小化框架，实现了可微分的证明搜索。

Abstract: Large Language Models (LLMs) exhibit persistent logical failures in complex reasoning due to the lack of an internal axiomatic framework. We propose Mathesis, a neuro-symbolic architecture that encodes mathematical states as higher-order hypergraphs and uses a Symbolic Reasoning Kernel (SRK)--a differentiable logic engine that maps constraints to a continuous energy landscape. By defining a global energy function E(G), where zero energy implies logical consistency, the SRK yields gradient-based signals to train a Hypergraph Transformer Brain, turning proof search into energy minimization. Multi-step deduction is enabled via Monte Carlo Tree Search and Evolutionary Proof Search, guided by learned value functions and semantic unification.

</details>


### [131] [Explicit Abstention Knobs for Predictable Reliability in Video Question Answering](https://arxiv.org/abs/2601.00138)
*Jorge Ortiz*

Main category: cs.AI

TL;DR: 该研究评估了视觉语言模型在视频问答任务中基于置信度的选择性预测机制，发现其在分布内能提供机制性控制，但在分布偏移下可靠性显著下降。


<details>
  <summary>Details</summary>
Motivation: 高风险的视觉语言模型部署需要选择性预测机制，使系统在不确定时能够弃权以避免代价高昂的错误。研究旨在评估基于置信度的弃权机制是否能在视频问答任务中提供可靠的错误率控制，以及这种控制在分布偏移下是否保持稳健。

Method: 使用NExT-QA数据集和Gemini 2.0 Flash模型，通过置信度阈值化方法进行实验。在分布内设置中，通过扫描阈值epsilon来产生平滑的风险-覆盖率权衡曲线；在分布偏移场景下，评估置信度阈值化机制的可靠性变化。

Result: 研究发现：1）在分布内，置信度阈值化能提供机制性控制，通过调整阈值可以平滑降低错误率；2）在分布偏移下，置信度阈值化的可靠性显著下降，表明模型对分布变化的适应性有限。

Conclusion: 虽然置信度阈值化在分布内能有效控制错误率，但在实际部署中需要考虑分布偏移带来的可靠性下降问题。这为高风险视觉语言模型应用中的选择性预测机制设计提供了重要启示。

Abstract: High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f

</details>


### [132] [An AI Monkey Gets Grapes for Sure -- Sphere Neural Networks for Reliable Decision-Making](https://arxiv.org/abs/2601.00142)
*Tiansi Dong,Henry He,Pietro Liò,Mateja Jamnik*

Main category: cs.AI

TL;DR: 该论文比较了三种神经推理方法：LLM推理、监督学习推理和显式模型推理，发现显式模型构建方法最可靠，并提出Sphere Neural Networks来解决监督学习中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 当前神经推理方法存在可靠性问题：LLM在简单决策任务上表现不佳，监督学习方法存在灾难性遗忘且推理能力局限于模式层面。需要寻找更可靠的神经推理方法。

Method: 提出Sphere Neural Networks，将概念表示为n维球面上的圆形，通过补圆表示否定运算符，过滤形成不可满足圆形配置的非逻辑语句，实现可靠的决策制定。

Result: Sphere Neural Networks能够掌握16种三段论推理任务，包括严格的析取三段论推理，同时保持经典三段论推理的严谨性。显式模型构建方法在三类神经推理方法中最可靠。

Conclusion: 显式模型构建的神经推理方法比LLM推理和监督学习推理更可靠，Sphere Neural Networks为解决监督学习中的灾难性遗忘和模式局限问题提供了有效方案。

Abstract: This paper compares three methodological categories of neural reasoning: LLM reasoning, supervised learning-based reasoning, and explicit model-based reasoning. LLMs remain unreliable and struggle with simple decision-making that animals can master without extensive corpora training. Through disjunctive syllogistic reasoning testing, we show that reasoning via supervised learning is less appealing than reasoning via explicit model construction. Concretely, we show that an Euler Net trained to achieve 100.00% in classic syllogistic reasoning can be trained to reach 100.00% accuracy in disjunctive syllogistic reasoning. However, the retrained Euler Net suffers severely from catastrophic forgetting (its performance drops to 6.25% on already-learned classic syllogistic reasoning), and its reasoning competence is limited to the pattern level. We propose a new version of Sphere Neural Networks that embeds concepts as circles on the surface of an n-dimensional sphere. These Sphere Neural Networks enable the representation of the negation operator via complement circles and achieve reliable decision-making by filtering out illogical statements that form unsatisfiable circular configurations. We demonstrate that the Sphere Neural Network can master 16 syllogistic reasoning tasks, including rigorous disjunctive syllogistic reasoning, while preserving the rigour of classical syllogistic reasoning. We conclude that neural reasoning with explicit model construction is the most reliable among the three methodological categories of neural reasoning.

</details>


### [133] [Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability](https://arxiv.org/abs/2601.00240)
*Zongwei Wang,Bincheng Gu,Hongyu Yu,Junliang Yu,Tao He,Jiayin Feng,Min Gao*

Main category: cs.AI

TL;DR: 研究发现LLM赋能的智能体不仅存在人口统计偏见，还会在最小"我们vs他们"线索下表现出群体间偏见。当这种群体边界与智能体-人类划分重合时，风险从人类群体间差异转向更根本的群体不对称——人类整体可能被智能体视为外群体。研究通过分配决策模拟证实了这种偏见，并提出了信念中毒攻击来抑制有利于人类的社会规范脚本。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究LLM赋能的智能体是否会在最小群体线索下表现出群体间偏见，特别是当智能体-人类划分成为群体边界时，人类整体可能被智能体视为外群体而受到不公平对待。这种风险比传统的人口统计偏见更为根本，需要系统性的安全分析。

Method: 研究构建了基于分配决策的受控多智能体社会模拟，在明确的收益权衡下观察智能体行为。通过最小群体线索设置实验条件，比较智能体对不同群体的分配决策。提出了信念中毒攻击(BPA)，包括初始化时的档案中毒(BPA-PP)和通过优化信念精炼后缀注入存储反思的记忆中毒(BPA-MP)。

Result: 实验证实智能体在最小群体线索下表现出一致的群体间偏见。虽然当部分对应方被标记为人类时偏见会减弱，但这种减弱源于仅在智能体相信真实人类存在时才激活的隐含人类规范脚本。信念中毒攻击能够有效抑制这种人类规范脚本，重新激活对人类的外群体偏见。

Conclusion: 研究揭示了LLM赋能智能体存在群体间偏见的系统性风险，特别是当智能体-人类划分成为群体边界时。信念中毒攻击暴露了新的攻击面，需要在档案和记忆边界实施可行的干预措施来加固当前智能体框架。研究目的是为更安全的智能体设计提供信息，而非促进实际利用。

Abstract: LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal "us" versus "them" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.

</details>


### [134] [Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems](https://arxiv.org/abs/2601.00339)
*Alaa Saleh,Praveen Kumar Donta,Roberto Morabito,Sasu Tarkoma,Anders Lindgren,Qiyang Zhang,Schahram Dustdar Susanna Pirttikangas,Lauri Lovén*

Main category: cs.AI

TL;DR: ReCiSt：受生物自愈机制启发的智能体自愈框架，用于分布式计算连续体系统的弹性恢复，通过语言模型驱动的智能体实现自主故障隔离、因果诊断、自适应恢复和长期知识整合。


<details>
  <summary>Details</summary>
Motivation: 现代分布式计算连续体系统（DCCS）集成了从物联网设备到云基础设施的异构计算资源，其固有的复杂性、移动性和动态操作条件导致频繁故障，需要可扩展、自适应和自我调节的弹性策略。

Method: 将生物自愈的四个阶段（止血、炎症、增殖、重塑）重构为计算层的四个层次（遏制、诊断、元认知、知识），通过语言模型驱动的智能体解释异构日志、推断根本原因、优化推理路径并重新配置资源。

Result: 在公共故障数据集上使用多种语言模型评估，ReCiSt能在数十秒内实现自愈，智能体CPU使用率最低为10%，展示了克服不确定性的分析深度和实现弹性所需的微智能体数量。

Conclusion: ReCiSt框架成功将生物自愈机制转化为分布式计算系统的弹性策略，通过语言模型驱动的智能体实现了自主故障管理和恢复，为复杂动态系统的自我调节弹性提供了新途径。

Abstract: Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.

</details>


### [135] [Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning](https://arxiv.org/abs/2601.00400)
*Weng Ding,Yi Han,Mu-Jiang-Shan Wang*

Main category: cs.AI

TL;DR: 提出ACCD框架，通过自适应因果协调检测技术，结合记忆引导机制和三阶段渐进架构，显著提升社交媒体协同虚假行为检测的准确性和效率，减少人工标注需求。


<details>
  <summary>Details</summary>
Motivation: 现有社交媒体协同虚假行为检测方法存在三个主要问题：1) 依赖表面相关性分析而非深层因果关系；2) 使用静态参数设置，缺乏适应性；3) 需要大量人工标注，成本高昂且效率低下。这些问题限制了检测系统的准确性和实用性。

Method: 提出自适应因果协调检测（ACCD）框架，采用三阶段渐进架构：1) 自适应收敛交叉映射（CCM）技术，深度识别账户间的真实因果关系；2) 半监督分类方案，结合主动学习和不确定性采样，大幅减少人工标注需求；3) 自动化验证模块，基于历史检测经验进行自我验证和优化。框架还包含记忆引导自适应机制，动态学习和保留不同场景下的最优检测配置。

Result: 在真实数据集（Twitter IRA、Reddit协调痕迹、多个机器人检测基准）上的实验表明：ACCD在协同攻击检测中达到87.3%的F1分数，比现有最强基线提升15.2%；减少68%的人工标注需求；通过层次聚类优化实现2.8倍的处理速度提升。

Conclusion: ACCD框架为社交媒体协同行为检测提供了更准确、高效且高度自动化的端到端解决方案，具有重要的实际应用价值和广泛的推广潜力，显著提升了检测系统的实用性和可扩展性。

Abstract: Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\% in coordinated attack detection, representing a 15.2\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.

</details>


### [136] [Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications](https://arxiv.org/abs/2601.00421)
*Alessio Di Rubbo,Mattia Neri,Remo Pareschi,Marco Pedroni,Roberto Valtancoli,Paolino Zica*

Main category: cs.AI

TL;DR: 将语义空间推理从计算语言学扩展到团队运动战术决策，将球员视为单词、团队战术视为语义结构，通过向量空间建模评估战术匹配度


<details>
  <summary>Details</summary>
Motivation: 传统语义空间推理主要应用于计算语言学，本文旨在探索如何将这一方法扩展到团队运动的战术决策领域，为集体决策和性能优化提供通用框架

Method: 将球员表示为整合技术、身体和心理属性的多维向量，通过上下文加权聚合成团队语义表示；在共享向量空间中编码战术模板（如高位压迫、反击等），使用向量距离度量评估战术匹配度和对手利用潜力

Result: 开发了Python原型系统，能够生成可解释的动态自适应策略建议，并提供属性级别的细粒度诊断洞察；方法不仅适用于足球，还可扩展到篮球、曲棍球、协作机器人、人机协调系统等领域

Conclusion: 提出了一个可推广的集体决策框架，为团队战术分析提供了新视角；未来方向包括真实数据集成、预测性模拟和混合人机战术智能系统开发

Abstract: This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.

</details>


### [137] [The Illusion of Insight in Reasoning Models](https://arxiv.org/abs/2601.00514)
*Liv G. d'Aliberti,Manoel Horta Ribeiro*

Main category: cs.AI

TL;DR: 研究发现推理模型中的"顿悟"时刻（中间推理转变）并不常见，不会随训练变得更频繁，也很少提高准确性，表明它们不是模型内在的自我纠正机制，而是不稳定推理行为的症状。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明像DeepSeek-R1-Zero这样的模型在推理过程中会出现突然的中间转变，导致准确输出，暗示了内在的自我纠正能力。但尚不清楚这种推理策略的内在转变是否真正改善性能。

Method: 研究分析了100万+推理轨迹、数百个训练检查点、三个推理领域、多个解码温度和模型架构，检测中间推理转变，并人工触发外在转变来验证效果。

Result: 发现推理转变很罕见，不会随训练变得更频繁，很少提高准确性，表明它们不对应于先前感知的模型洞察力。但在高熵（模型不确定性）条件下，人工触发外在转变能可靠提高准确性。

Conclusion: 中间推理转变是不稳定推理行为的症状，而非内在的自我纠正机制。在高不确定性条件下，人工干预可以改善性能，但模型自身缺乏真正的"顿悟"能力。

Abstract: Do reasoning models have "Aha!" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.

</details>


### [138] [DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations](https://arxiv.org/abs/2601.00623)
*Longtian Qiu,Shan Ning,Chuyu Zhang,Jiaxuan Sun,Xuming He*

Main category: cs.AI

TL;DR: DA-DPO提出了一种难度感知的直接偏好优化框架，通过估计偏好数据的难度并重新加权训练样本，解决多模态大语言模型中偏好优化过拟合问题，提升幻觉抑制效果。


<details>
  <summary>Details</summary>
Motivation: 现有多模态DPO方法因偏好数据难度不平衡而容易过拟合，模型倾向于过度关注容易区分的偏好对，阻碍了细粒度幻觉抑制并降低整体性能。

Method: DA-DPO包含两个核心组件：1) 难度估计：利用预训练的视觉-语言模型，结合生成式和对比式目标，通过分布感知投票策略产生稳健的难度分数；2) 难度感知训练：基于估计的难度重新加权偏好对，降低简单样本权重，强调困难样本，缓解过拟合。

Result: 实验表明DA-DPO能持续改进多模态偏好优化，在标准基准测试中展现出更强的幻觉鲁棒性和更好的泛化能力，同时保持计算效率。

Conclusion: DA-DPO通过难度感知的偏好优化框架，有效解决了多模态DPO中的过拟合问题，无需额外数据或微调阶段即可实现更有效的幻觉抑制和性能提升。

Abstract: Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.

</details>


### [139] [A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference](https://arxiv.org/abs/2601.00694)
*Qingwen Pu,Kun Xie,Hong Yang,Guocong Zhai*

Main category: cs.AI

TL;DR: PedX-LLM：一个融合视觉特征、文本数据和交通领域知识的LLM框架，用于行人过街行为推理，在泛化性和性能上显著优于传统统计和监督学习方法


<details>
  <summary>Details</summary>
Motivation: 现有行人过街行为推断方法（统计模型和监督学习）泛化性有限，在新场景中表现不佳。现有LLM应用缺乏领域特定适应和视觉上下文，需要开发能够实现从站点特定模式识别到可泛化行为推理转变的框架

Method: 提出PedX-LLM框架：1) 集成LLaVA提取的视觉特征与文本数据及交通领域知识；2) 通过LoRA对LLaMA-2-7B基础模型进行微调；3) 采用跨站点验证评估泛化性；4) 支持零样本和少样本学习配置

Result: 1) 达到82.0%的平衡准确率，优于最佳统计和监督学习方法；2) 视觉增强模块贡献2.9%性能提升；3) 领域知识集成带来额外4.1%改进；4) 零样本配置在五个未见测试站点达到66.9%平衡准确率，比基线方法高至少18个百分点；5) 少样本学习（仅5个验证样本）将平衡准确率提升至72.2%

Conclusion: PedX-LLM通过视觉和知识增强的推理机制，能够模拟人类决策逻辑，克服纯数据驱动方法的局限性，在未见场景中表现出强大的泛化能力，为行人过街行为推断提供了新的范式

Abstract: Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.

</details>
